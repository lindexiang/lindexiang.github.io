<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[高性能mysql知识点]]></title>
    <url>%2F2018%2F10%2F25%2Fmysql-optimization-1%2F</url>
    <content type="text"><![CDATA[高性能mysql事务相关事务的含义事务就是一组原子性的SQL查询。事务必须满足ACID特性。 原子性 atomicity事务全部提交成功，或者全部回滚 一个事务不能执行一部分 一致性 consistency数据库从一个状态转换到另一个状态，不会存在中间状态 在事务执行期间系统崩溃了，事务能回滚，数据不会丢失 隔离性 isolation一个事务所做的操作在没有提交之前对其他的事务都是不可见的。隔离性有4个等级。 持久性事务一旦提交，会永久保存在磁盘中，即使系统崩溃，修改的数据也不会丢失。 事务的隔离级别 未提交读 READ UNCOMMITTED事务中修改的内容在没有提交时其他事务就能看见，称为脏读。 提交读 READ COMMITTED事务在提交了才能被读取，其他的事务修改行会加锁。又称为不可重复读。 可重复读 REPEATABLE READ可重复读解决了脏读的问题，该级别保证了在一个事务中多次读取同样的记录结果是一致的。但是无法解决幻读的问题。幻读指的是事务在读取一个范围的记录时，另外的事务又在该范围内插入新的数据，之前的事务再次读取范围记录时，出现幻行。MYSQL采用了MVCC多版本控制和间隙锁解决了幻读的问题。在快照读时采用的是MVCC既可以解决幻读。在当前读时读取的是最新的数据，采用的是间隙锁来解决。 串行化多个事务串行运行 效率较低 MYSQL的加锁机制InnoDB采用的是二阶段锁定协议 在事务的执行过程中，随之都会执行锁定记录。锁只有在提交事务或者回滚ROLLBACK才会释放。并且所有的锁都是同时释放的。 事务的死锁多个事务在统一资源上相互占用，并请求对方的占用的资源，从而导致恶性循环的现象。多个事务采用不同的顺序锁定资源时就可能会产生死锁。 解决办法InnoDB的方法是将持有最少行级锁的事务进行回滚。 事务在update，insert，delete时候会加锁。 事务日志采用事务日志可以提高效率。在使用事务日志，修改表时先修改内存中的数据(加锁)，再将该修改行为记录到持久在硬盘中的事务日志中。而不用每次都修改磁盘中的数据，提高速度。 事务日志采用追加的方式，(因为写日志只要修改某个文件，而修改mysql记录需要寻找每条记录的位置，效率低),事务持久化后再将内存的数据慢慢同步到磁盘中。如果数据没有写回到磁盘，那系统奔溃，重启后自动恢复这部分的修改。 redo日志和undo日志事务日志包括重做日志redo日志和回滚undo日志， redo日志存储最新的值，undo日志存储的是老的值，是数据的快照。undo指的是已经全部完成的事务，就是commit的事务。redo记录的是完成并且部分写入磁盘的已经提交的事务，记录在共享表空间中。一般情况下，mysql奔溃后重启服务，InnoDB通过回滚日志undo将所有已经写入磁盘的未完成的日志回滚，并重新执行redo日志的事务即可恢复数据。但是如果redo的量增加，全部执行redo需要很多时间，则引入了checkpoint机制。即先将数据回滚到undo里面的初始值，如果redo事务提交了，就重新执行redo的日志，否则执行到事务提交之前undo+redo事务的简化过程 12345678910假设有A、B两个数据，值分别为1,2.A.事务开始.B.记录A=1到undo log.C.修改A=3.D.记录A=3到redo log.E.记录B=2到undo log.F.修改B=4.G.记录B=4到redo log.H.将redo log写入磁盘。I.事务提交 事务管理机制 脏页当业务需要对某张表格的数据修改时候，innodb会先将数据从磁盘中读取到内存中，然后在缓存中修改数据，这时候缓存中的数据就称为dirty数据，要将脏页统一刷新到磁盘中。checkpoint 在某个时间点，将脏页的数据刷新到磁盘中，系统将这个刷新的时间点记录到redo log的结尾位置，进行数据恢复时候，checkpoint之前的数据不需要进行恢复 管理机制事务会先修改内存中的数据，InnoDB事务日志有4个步骤创建阶段 事务先创建一条日志 日志刷盘：日志将会写入磁盘中的日志文件 数据刷盘:将脏页的数据写入到磁盘中数据文件 写checkpoint:将数据刷盘的点的信息记录到redo日志中，下次从这里开始恢复多版本并发控制(MVCC) MVCC在很多时候避免了加锁，主要是实现了非阻塞的读操作，写操作也只是锁定必要的行。MVCC和concurrentHashMap有些类似，采用非阻塞的读取操作，写操作只是锁定必要的行。InnoDB是加行级锁。 InnoDB的MVCC通过在每个行后面记录两个隐藏的列来实现 不是存储实际的时间至 保存行的创建时间(系统版本号) 行的过期时间(系统版本号) 如何实现MVCCSELECT操作 行的系统版号小于等于当前的系统版本号，保证数据行是系统事务开始前存在或者是当前事务修改或者插入的 行的删除版本未定义，或者大于当前版本号的数据行。因为之后的事务删除的行记录也要被选到。保证读取到的行在事务开始前未被删除。 INSERT操作当前的的事务版本号最为新插入行的行版本号。 DELETE操作保存当前的事务版本号作为被删除行的行删除版本号。 UPDATE操作插入一行新数据，当前的事务版本号作为行版本号，并将原来的行的删除版本号设为当前的系统版本号。使原来的行无法被select到，而新插入的行能被选到。 MVCC加锁机制在MVCC并发控制中，读操作可以分成2类， 快照读快照读是读取记录的可见版本(就是事务开始前的快照，后面的事务的操作不会影响)，不用加锁。简单的select操作，属于快照读，不加锁。 select * from table where ？ 当前读读取的是记录的最新版本，并且当前读返回的记录，都会加上锁，保证其他事务不会并发的修改这个记录。特殊的读操作，INSERT/UPDATE/DELETE都是当前读，要加锁。 12345select * from table where ? lock in share mode;select * from table where ? for update;insert into table values (…);update table set ? where ?;delete from table where ?; 这些都是当前读，第一个加的是共享锁，其他的都是加排他锁。 MYSQL的加锁分析12SQL1：select * from t1 where id = 10; SQL2：delete from t1 where id = 10; 分析MYSQL的加锁情况时需要考虑前提条件 id是不是主键 系统的隔离级别 id不是主键， 是否存在索引 id列上存在二级索引，那这个索引是唯一索引么 SQL的执行计划，索引扫描和全表扫描 select * from t1 where id = 10; 这句话都是走的MVCC机制，均不加锁 delete from t1 where id = 10; 情况1 id是主键，RC(提交读) 加独占锁 情况2 id唯一索引+RCid是二级索引，主键是name。首先是在id上加X锁，然后在主键上也要加锁。因为是根据主键来更新的索引的。全表扫描也是走主键索引的。 情况3 id非唯一索引+RC在id = 10全部加上X锁，在主键上将对应的列都加锁。（InnoDB是行锁，指每次只加锁一行数据） 情况4 id无索引+RC没有索引，只能走主键索引，则将主键上的索引都加上X锁 情况5 id非唯一索引+RR因为RR是可重复读，则要解决幻读的问题。所以要加上GAP锁。间隙锁不是加在主键索引上 情况6 id无索引+RR走主键索引，全部加上间隙锁 MYSQL的死锁分析这个比较好理解。在事务开始后，每个事务都会持有修改数据的行锁。直到事务结束后才会释放锁。那么两个事务分别持有id=1和id=5的锁，再去求对方的锁造成死锁 第一句话走name的索引，是先锁1，再锁2. 第二句话走pubtime的索引，根据pubtime的排序加锁。则可能语句1和语句2的加锁顺序会相反造成死锁。两次查询都会走主键索引。 乐观锁和悲观锁数据库的并发控制主要解决多个事务同时读取数据库中的数据要解决的问题。乐观锁并发控制和悲观锁并发控制是并发控制的主要手段 悲观锁在对任意记录进行修改前，先尝试为该记录加上排他锁（exclusive locking）。如果加锁失败，说明该记录正在被修改，那么当前查询可能要等待或者抛出异常。具体响应方式由开发者根据实际需要决定。如果成功加锁，那么就可以对记录做修改，事务完成后就会解锁了。其间如果有其他对该记录做修改或加排他锁的操作，都会等待我们解锁或直接抛出异常。 12345678910//0.开始事务begin;/begin work;/start transaction; (三者选一就可以)//1.查询出商品信息select status from t_goods where id=1 for update;//2.根据商品信息生成订单insert into t_orders (id,goods_id) values (null,1);//3.修改商品status为2update t_goods set status=2;//4.提交事务commit;/commit work; 在上面的语句中，我们使用了select for update 实现了悲观锁。t_goods的id=1的行的数据被锁定了。其他的事务要等这个事务提交完了才能执行。可以保证数据不会被其他事务修改。 乐观锁乐观并发控制假设多个事务的处理不会彼此造成影响。各事务在不加锁的情况下能处理各自部分的数据。在提交数据更新之前，每个事务都会检查在改事务读取数据后有没有其他事务又修改了这部分的数据。如果其他事务也有更新的话，就回滚重试。 12345671.查询出商品信息select (status,status,version) from t_goods where id=#&#123;id&#125;2.根据商品信息生成订单3.修改商品status为2update t_goods set status=2,version=version+1where id=#&#123;id&#125; and version=#&#123;version&#125;; //在修改的这段时间内没有其他的事务修改这条数据 乐观并发控制是相信事务之间的数据竞争的概率比较小，因此尽可能直接做下去，直到提交的时候才去锁定，所以不会出现锁和死锁。但是如果两个事务同时读取了数据库的某一行，经过修改后在写回数据库，就会造成问题。 InnoDB和MyISAM的区别InnoDB和MyISAM在并发性上有点类似于ConcurrentHashMap和HashTable的区别。 InnoDB的特性 采用MVCC(多版本并发控制)实现高并发，实现了4个隔离级别，默认为可重复读(加间隙锁来避免幻读) 采用了簇族索引，对主键查询有很好的性能。二级索引必须包含主键 采用行级锁 事务管理，支持崩溃后的安全恢复 MyISAM 不支持事务和行级锁，在数据库奔溃后无法安全恢复 保存了表的行数 加锁和并发 加的是表锁，在读取时会对所有的表加共享锁，写入时加入拍他锁。但是在表有插入时，也可以往表中插入记录。 索引特性 支持全文索引，或者对TEXT前500个词加索引 可以压缩表 MySQL的基准测试基准测试是唯一方便有效的测试系统在给定的工作负载下的性能，评估系统的容量等。 基准测试指标 吞吐量单位时间内的事务处理量 响应时间测试任务的整体时间 可以做多次任务，取百分比 并发性测试的同时工作的线程数或者连接数，当并发性增加时，系统的吞吐量是否会下降。 可扩展性给系统增加一倍的工作量，理想的情况下吞吐量变成2倍。或者给系统增加一倍的资源，可以获得两倍的结果。 设计基准测试首先要获得生产数据的快照，并且该快照容易还原。建立一个单元测试集，并运行多遍，每次运行完后要还原数据。基准测试要运行时间时间为读IO操作要3个小时，写IO要8个小时才区域稳定，之前是系统预热时间。 服务器性能查询优化服务器性能优化主要有 如何确认服务器达到了性能最佳的状态 如何查出某条语句为啥执行不够快 诊断被用户描述成“停顿”、“卡死”等状态。 MySQl中的慢查询日志和查询日志 慢查询日志是记录每个查询语句的执行时间 查询日志是记录每个语句请求到服务器的时间 使用慢查询日志来优化那些效率低下的查询语句 MYSQL的数据类型和范式数据类型 整数类型TINYINT，SMALLINT，等等 8位，16位，4位 实数类型DECIMAL 是带有小数部分的数字 字符串CHAR(定长)和VARCHAR(不定长)CHAR根据定义的字符串长度来分配空间,VARCHAR是可以存储变长度的字符串，末尾要记录字符串长度。多申请空间末尾补空格更加节省空间，根据字符串长度使用必要的空间 末尾要多两个字节保存长度。varchar（1000） 要1002个字节长度 三大范式 第一范式数据库的字段都是单一属性，不能再分 第二范式非主键列的字段必须完全依赖于主键列， 第三范式字段属性不依赖于非主键列的其他列 使用数据库表设计的三大范式可以消除数据冗余、删除异常等问题。 创建高性能的索引创建索引是查询优化性能的最有效的手段。在一次查询中，无论你创建了多少索引，最终只会使用其中的一个索引。其他的是走内存筛选或者文件排序 使用索引的优点 索引可以减少服务器扫描数据行的数量 索引可以避免排序和创建临时表 索引将随机IO变成了顺序IO mysql存储的基础知识页的概念数据库文件以页为存储单位，一个页(8K)可以存放N行数据。常用的页类型为索引页和数据页。一个页中存放数据外还要存放页的信息和偏移量等 树的概念二叉树这个就是二叉搜索树，树的深度太深，需要多次IO操作 B-树B-树是一个m阶的多叉搜索树 阶数(M)大于2，孩子个数大于2 每个节点存放[M/2 -1] 到M-1个关键字 非叶子节点的关键字是按顺序排列的 K[1],K[2],…K[n],其中K[i]&lt;K[i+1] 叶子节点都在同一层，所以叶子节点的深度相同 非叶子节点的关键字的个数=指向儿子的指针个数-1 非叶子节点的指针P[1],P[2],P[3],P[M]其中P[1]为关键字小于K[1]的子树，P[M]为大于K[M-1]的子树，其他P[i]为K[I-beam]到K[i] B+树非叶子节点的子节点和关键字相同，即节点有三个元素。叶子节点有一个指向相邻叶节点的指针。 聚簇索引和非聚簇索引聚簇索引指的是数据行存放在索引的叶子页。索引列中包含了聚簇索引列。当表中有聚簇索引时，数据行是按照顺序排列的，否则数据行是存放在无序堆结构中。 聚族索引和查询操作在查询时，会先对索引表查询，如果索引在缓存表中可以找到，那么可以避免IO查询。在索引中找到索引值，就可以找到数据行 聚族索引和删除操作插入数据时，会先根据索引找到对应的数据页，再挪动已有的数据 所以最好是按照主键自增来增加数据，避免不必要的移动。并且主键列不要修改，修改会造成大量的数据移动。 删除数据会将下面的数据往上移动 聚族索引会降低数据的插入和删除效果，在update其他非主键列没有影响 辅助索引InnoDB的辅助索引的叶子结点都是保存主键索引的值。所以在查找的时候需要2次查找。如果主键索引定义的比较大，其他索引也会非常的大。所以要在表上定义很多的索引，要争取把主键定义的小一点。聚簇索引对主键的查询非常高效，但是使用辅助索引必须检索2遍的索引。 非聚簇索引非聚族索引不是物理上排列顺序，而是通过指针来定位数据非聚族索引数据存储没有顺序，则指针包含的是数据页+偏移量 这里需要访问一次随机IO B-Tree树索引B-Tree索引是用多叉树的原理来存储索引，叶子结点存的是数据行所在页和在页中的偏移 使用多插树可以减少IO访问的次数。提高速度 logm(n)的时间复杂度吧。B-Tree索引的叶子结点到根结点的距离都是相同的，使用索引能提高数据的查询速度。因为不需要全表查询所需要的数据 B-Tree树索引的查找过程如果要查找数据项29，那么先把磁盘块1加载到内存中，此时发生一次IO读取，然后在内存中二分查找确定在17和35之间，锁定了磁盘快3，然后加载磁盘块3发生第二次IO读取，在找到磁盘块8，第三次IO。结束查询。 B-Tree树的性质树的高度计算二插树为h = log(2)N 以2为底。如果是m叉树，就是h = log(m)N m为数据页里面的key的个数。假设当前的数据表的数据为N，每个磁盘块的数据项的数目为m，则有h = log(m)N。则m越大，N越小。m = 磁盘块的大小／数据项的大小。 所以索引要小一些，这样子树的高度就会小一些。当B-Tree树的数据项是复合的数据结构，比如(name, age，sex)的时候，b+树按照从左到右的顺序建立搜索树。则B-Tree树会先按照左边的来查找。即索引的最左匹配原则。 使用多级索引 在多个列上建单独的索引在大部分的情况下并不能提高MYSQL的查询能力。在早期的MYSQL中，只能使用单独的一列索引。现在的MYSQL可以采用索引合并的策略，不过还是复合索引效果更好。 使用多级索引注意 全值匹配 匹配索引的全部列 匹配最左前缀 索引是从左往右开始存储 使用多级索引的限制 不是按照索引的最左列开始查找，无法使用索引。 因为多级索引是先按照最左边的索引开始排序，对于第一个索引相同的按照第二个索引开始排序，以此类推 不能跳过索引的列 有3个索引，不能只使用1，3索引，2不使用 那么系统只使用1索引，3不使用 使用某个列的范围查询 该范围的右边的索引不再使用 索引失效 where条件出来的数据很多，大于15% 。导致索引实效 索引本身实效，索引参与计算了，SELECT * FROM t_user where id-1=9 比如like %_ like函数%在前面 和not in not exist 使用索引扫描来排序在explain时，可以看到extra列中有使用using index和using filesort，即索引排序和文件排序 文件排序文件排序是通过相应的排序算法，将取出的数据在内存中进行排序。使用的内存区域是sort_buffer_size的排序区域。这部分是thread独享的。所以在同一时间，mysql可以存在多个sort buffer在内存中。 只有当索引的的列顺序和order by子列的顺序完全一致，并且所有列的排序方向一样(正序或者倒序)，mysql才会使用索引扫描对结果排序。即order by字句必须满足索引的最左前缀原则，如果前缀列是常数，则可以按照下一列排序。 例子 12345678910111213141516171819202122create table test( a int, b int, c int, KEY a(a,b,c));//这个语句可以走索引，因为在a固定时b和c时按照顺序排列的select * from test where a = 10 order by b, c// 可以走索引排序select * from test where a = 10 order by a, b// 不能走索引排序，select * from test where a = 10 order by b desc , c asc//文件排序，不能构成最左前缀原则select * from test where a = 10 order by c// 下面都不能使用索引排序，因为a是范围值时，b和c的顺序是打乱的，必须全表扫描，索引会走文件排序select * from test where a &gt; 10 and b = 3 and c = 4select * from test where a &gt; 10 order by b, c 慢查询优化MySQL的执行计划是专门针对SELECT语句设计的，因为使用UPDATE，DELETE也是要先用SELECT读取当前的数据行。MYSQL提供了EXPLAIN语法来进行查询分析，在SQL语句前加“EXPLAIN”就可以了。 id是数字越大越先执行，针对存在子查询的情况 select_type 查询的类型 table 查询的表 如果是别名，就显示别名 type查询中使用的模式 all是走全表，在缓存中过滤出符合的行 index是走索引查询 key查询中走的索引名字 row 在查询中一共走了多少行数据 extra order by 字句是走文件排序还是索引排序 Mysql复制原理主从库的逻辑。读写分离，写在主库，读分到其他裤。 每次写主库，要都写到其他的备库中才算完成写操作。备库不应该有主动的写操作，因为备库无法通知主库去进行数据同步，会造成数据不一致。MySQL的内置复制功能是构建基于MySQL的大规模、高性能应用的基础。可以为服务器配置多个备库的方式来数据同步主从复制是基于binlog(二进制文件)来实现的。在执行过程中会出现复制数据不一致的情况。需要定期开展复制数据一致性的检验和修复工作。 主从数据检查 数据一致性检验使用的是pt-table-checksum工具，用来实现主从数据一致性的校验工作。原理：通过SQL在主库中执行数据库的校验，然后再将SQL语句传输到从库中，并在从库中计算校验块的检验，然后比对主库和从库的结果。 主从数据一致性修复使用的是pt-table-sync工具，用来修复主从复制数据不一致，最终修复到一致。其中，在sync工具中还有checksum，可以一边修复一边校验数据一致性。 主从复制原理 主库把数据更改记录到二进制日志中 备库将主库中的日志复制到中继日志(relay log)中 开启IO线程 备库读取中继日志的时间，将其重放到备库数据中 开启SQL线程 master将事务串行写到binlog中。日志写入完成后，master通知存储引擎提交事务。在slave中的IO线程将收取binlog，写到自己的relay log中，最后slave中的SQL线程执行binlog，从而使主从数据一致。 复制的原理基于语句的复制在早期的mysql版本中只支持语句的复制(逻辑复制)。主库会记录造成语句修改的查询，当备库读取并重放时是重新执行了一遍SQL语句。实现简单，主库的修改好几十w条数据的语句在二进制文件中可能只是几条语句。但是因为主库和从库的时间戳不一样，导致一些操作出现问题。并且更新必须串行化，需要更多的锁。 基于行的复制将实际的数据记录到二进制日志中，再跟其他的数据库比较优点:减少锁的使用，基于行的复制可以解决数据不一致的问题。比如备库更新不存在的记录不会报错，但是基于行的复制模式就会报错。缺点:全表修改会造成二进制日志过大 SQL可以在这两个之间切换，先使用语句复制，无法实现使用基于行的复制 复制拓扑 一主库多备库少量写和大量读时候，可以将读操作分摊到多个备用服务器中（只读） 主动-主动模式下的主主复制两台服务器均配置成主库和对方的备库优点：两台服务器均可写缺点:很有可能在同步时候发生冲突 主动-被动模式下的主-主复制反复切换主动和被动服务器很方便当一台服务器要修改数据，可以先停止主库中的复制线程，在被动服务器中执行修改数据库操作，交换主库和备库的角色，最后在先前的主库中启动复制线程。 常见的问题 测量备库延迟普遍的问题是测量备库落后主库的延迟有多大使用heartbeat record。主库中每秒更新一次时间戳，从库中用当前时间减去传过来的时间戳就是延时的时间。 pt-heartbeat脚本可以检测。 确定主备库是否一致理想情况下，主备库的数据应该一致。但是可能备库的数据库崩溃等问题导致数据不一致。pt-table-checksum方法可以解决这个问题在主库中执行INSERT—SELECT查询，这些查询对数据校验并将结果插入到一个表中。然后将语句和表复制到备库中。在备库中也执行一样的操作，看结果是否一致。将会检查所有的表，在备库中执行完毕后就可以得到答案。 主从延时过大怎么办首先，先使用pt-heartbeat来检测主从延时究竟有多大。然后再查看是因为主库中的事务过大提交慢还是因为从库SQL线程的复制慢。使用show slave status看binlog apply position是不是不动1.不断增大，那么说明是主库中提交的事务过多，主库是并发的，从库是串行化的，需要时间同步。2.不动， 说明是主库提交了一个大事务，找到这个事务将事务改小。 主从延迟导致数据延迟问题解决在主库写操作的同时，可以先在redis等里面写缓存，在读取的时候先读取缓存内的数据，缓存内的数据没有再去从库中读取。]]></content>
      <categories>
        <category>数据库相关</category>
      </categories>
      <tags>
        <tag>MYSQL</tag>
        <tag>事务</tag>
        <tag>主从复制</tag>
        <tag>索引优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Thread知识点]]></title>
    <url>%2F2018%2F10%2F24%2FThread%2F</url>
    <content type="text"><![CDATA[java线程介绍线程的状态 New创建后未启动的线程 Runnable包括Running 和 Ready 运行和就绪 Waiting不会被分配CPU时间，等待被其他线程显式唤醒 以下会被无限期等待Object.wait() 没有设置Timeout没有设置Timeout的thread.join()LockSupport.park()方法 和这个lock.await()方法 比较类似 Timed Waiting不会被分配cpu时间，被其他线程显示唤醒或者时间到了自动唤醒Thread.sleeping()Object.wait() 设置了时间Thread.join() 设置了时间LockSupport.parkNanos() 设置了时间 lock.await(Time)LockSupport.parkutil() 就是trylock blockedblocked和waiting的区别是blocked是等待获取一个排它锁，这个事件在另一个线程放弃这个锁的时候发生。Waiting是在等待唤醒动作的发生 Terminated终止线程或者结束线程 wait和block的区别Wait状态是线程主动放弃了锁，进入等待状态，需要其他线程去主动notify和notifyall唤醒blocked是线程获取锁失败而进入阻塞状态，无需唤醒，当锁空闲时，由JVM从blocked队列唤醒这个线程 123synchonorized(obj) &#123; Obj.wait();&#125; T1和T2两个线程分别进入这段代码，T1获取了obj的锁，然后wait放弃了锁并进入等待状态接着T2想获取obj的锁，失败进入blocked阻塞状态，当T1线程wait后得到锁被JVM唤醒 线程中断每个线程都有一个boolean类型的变量来标志该线程的中断状态，Thread类中包含三个与中断状态相关的方法： 12345678910Public void Thread&#123; // 中断一个线程，将其中断标识位置为true public void interrupt() &#123;&#125; // 返回目标线程的当前中断标识 不清除标志位 Public void isInterrupted()&#123;&#125; //清除线程的中断状态，返回之前的值 Public static boolean interrupted()&#123;&#125; //私有方法 返回中断表示，并且设置是否清除 private native boolean isInterrupted(boolean ClearInterrupted) &#125; 如何处理线程中断线程不会被挂起，使用volatile来代替在任务内没有阻塞的情况下可以使用，但是当任务存在wait()方法时，它不能响应，会无限阻塞下去12345678910111213public class MyTask implements Runnable&#123; private volatile running = true; public void run() &#123; while(running)&#123; //...操作 &#125; &#125; public void stop() &#123; running = false; &#125;&#125; 线程挂起与线程中断阻塞方法会使线程进入阻塞的状态，例如：等待获得一个锁、Thread.sleep方法、BlockingQueue的put、take方法等。大部分的阻塞方法都是响应中断的，即这些方法在线程中执行时如果发现线程被中断，会清除线程的中断状态，并抛出InterruptedException表示该方法的执行过程被从外部中断。响应中断的阻塞方法通常会在入口处先检查线程的中断状态，线程不是中断状态时，才会继续执行在下面这个例子中，包含了阻塞方法sleep，在线程外部通过interrupt方法请求结束线程，sleep会清除中断标识位并抛出InterruptedException阻塞方法抛出的异常有两种解决的办法 第一种是重新抛出InterruptedException，将该异常的处理权交给方法调用者，这样该方法也成为了阻塞方法（调用了阻塞方法并且抛出InterruptedException） 第二种是通过interrupt方法恢复线程的中断状态，这样可以使得处理该线程的其他代码能够检测到线程的中断状态；使用该方法后，处理该线程的其他方法可以检测到线程中断 。比如有两个任务被阻塞了 123456789101112131415161718192021public MyTask implements Runnable&#123; public void run() &#123; try &#123; while(!Thread.currentThread().isInterrupted()) &#123; Thread.sleep(3000); //阻塞方法 会抛出中断异常 //...其他操作 return; &#125; &#125; catch(InterruptedException ex) &#123; Thread.currentThread().interrupt(); //恢复中断状态 &#125; &#125;&#125;public class Test&#123; public void method()&#123; Thread thread = new Thread(new MyTask()).start(); //.... thread.interrupt(); //通过中断机制请求结束线程的执行 &#125;&#125; 不支持中断并且相应中断的任务对于不支持任务取消操作但是仍然响应中断的阻塞方法应该在本地先保存中断标识位，等任务结束了恢复中断，而不是在捕获InterrptedException的时候中断 1234567891011121314151617181920212223242526public class MyTask implements Runnable &#123; boolean interrupted = false; public void run()&#123; try&#123; //不支持取消操作 while(true) &#123; try&#123; Thread.sleep(3000); //...其他操作 return; &#125; catch(InterruptedException ex) &#123; //在本地保存中断状态 interrupted = true; //Thread.currentThread().interrupt(); //不要在这儿立即恢复中断 //在这个地方中断，任务将无法完成，无限循环 &#125; &#125; &#125; finally &#123; if(interrupted) Thread.currentThread().interrupt(); //恢复中断 &#125; &#125;&#125; 不会抛出中断异常的方法 有些方法阻塞方法不响应中断的，即在收到中断请求时不会抛出InterruptedException，如：java.io包中的Socket I/O方法、java.nio.channels包中的InterruptibleChannel类的相关阻塞方法、java.nio.channels包中的Selector类的select方法等。 可以使用其他方法来中断 对于java.io包的Socket I/O方法，可以通过关闭套接字，从而使得read或者write方法抛出SocketException而跳出阻塞 java.nio.channels包中的InterruptibleChannel类的方法其实是响应线程的interrupt方法的，只是抛出的不是InterruptedException，而是ClosedByInterruptedException，除此之外，也可以通过调用InterruptibleChannel的close方法来使线程跳出阻塞方法，并抛出AsynchronousClosedException 对于java.nio.channels包的Selector类的select方法，可以通过调用Selector类的close方法或者wakeup方法从而抛出ClosedSelectorExeception 123456789101112131415161718192021222324252627282930public class ReadThread extends Thread&#123; private final Socket client; private final InputStream in; public ReadThread(Socket client) throws IOException &#123; this.client = client; in = client.getInputStream(); &#125; public void interrupt() &#123; try &#123; socket.close(); &#125; catch(IOException ignore)&#123;&#125; finally &#123; super.interrupt(); &#125; &#125; public void run() &#123; //调用in.read方法 &#125;&#125;]]></content>
      <categories>
        <category>java同步包</category>
      </categories>
      <tags>
        <tag>java并发</tag>
        <tag>线程中断</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[socket原理]]></title>
    <url>%2F2018%2F10%2F21%2Fsocket%2F</url>
    <content type="text"><![CDATA[socket编程介绍简介进程间通信的方法有管道，命名管道，信号，消息队列，共享内存，信号量，这些方法要求通信的两个线程位于同一个主机。对于非同一个主机可以使用TCP／IP协议搞定。套接字是网络通信的基础。当一个程序创建了一个socket并与端口号绑定时候，意味着向TCP/IP协议申明了对端口的占有。比如端口为8080。所有目标为8080端口的TCP/IP协议包都会被该程序收到。Accept函数，就是抽象的TCP连接建立过程，accept函数返回的是新socket是指代本次连接。一个链接包括两个部分，一个是源IP和源端口，另一部分是目标IP和目标端口。所以accept可以产生多个socket。Socket类似于是对TCP/IP协议协议的抽象，对外提供了编程的接口、使用这个接口可以方便的使用tcp/IP的功能。所有socket是对TCP/IP协议栈的抽象，而不是简单的映射关系。socket包括客户端和服务端。Socket是客户端使用的，构造函数如下 1Socket(String host, int port, InetAddress localAddress, int localPort)throws IOException 会尝试和服务端建立链接，失败抛出异常，成功后返回socket对象，是一个同步阻塞IOserverSocket是服务端使用的，构造函数如下 1ServerSocket(int port, int backlog, InetAddress bindAddr)throws IOException 其中 port是服务端监听的端口号，backlog是accept队列的大小。bindAddr是服务端绑定的IP listen，connect，accept的流程以及原理客户端发起socket链接后，会使用TCP的3次握手和服务端建立链接，而serverSocket使用accept函数来得到链接的客户端。流程图如下 服务端new一个serverSocket后，会绑定一个端口设置状态为LISTEN，监听端口的情况。同时内核生成2个队列，一个是syn队列。另一个是accept队列。其中ACCEPT队列的长度由backlog决定。 服务端调用accept后，将会阻塞，等待ACCEPT队列中有元素。 客户端调用connect函数后，将发起SYN请求，请求与服务端建立TCP连接，第一次握手 服务端收到SYN请求后，将client放入syn队列中，并给客户返回ACK，此时还会携带一个要和客户端建立连接的请求标志SYN，称为第二次握手。 客户端收到SYN+ACK后，connect函数返回，并发送ACK给服务器端，称为第三次握手。 服务端收到ACK后，从SYN队列中移除client，并加入ACCEPT队列中，而accept函数等到资源，阻塞中唤醒，从ACCEPT队列中取出请求方，重新建立一个连接socketId，返回。 BIO编程网络编程的基本模型是C/S，即两个进程间的通信。服务端提供了IP和监听接口，客户端如果想对监听的地址发起连接请求,通过三次握手连接，如果连接建立成功，双方就可以通过socket通信。传统的同步阻塞模型开发中，ServerSocket负责绑定IP地址,启动监听端口；socket负责发起连接操作。连接成功后，双方通过输入流和输出流进行同步阻塞通信。BIO通信模型： 采用BIO通信模型的服务端，通常有一个独立的accept线程负责监听客户端的连接，他收到客户端连接请求后为每个客户端创建一个新的线程进行数据处理。处理完成后通过输入流返回给应答客户端。线程销毁。BIO的问题是当有一个新的客户端请求接入时候，服务端要建立一个新的线程来处理这个链路。该模型缺乏伸缩能力，当客户端并发量增加后，由于服务端和客户端的访问数量是1:1，则在线程数增加后，系统的性能就会下降很多。 BIO使用线程池我们可以使用线程池来实现一个线程或者多个线程来处理N个客户端模型。底层还是使用同步阻塞IO，称为伪异步IO模型 1234567891011121314151617181920public static void start(int port) throws IOException &#123; if (server != null) return; try &#123; server = new ServerSocket(port); System.out.println("服务器已启动，端口号: " + port); //无限循环监听客户端连接 while (true) &#123; Socket socket = server.accept(); executorService.execute(new ServerHandler(socket)); //new Thread(new ServerHandler(socket)).start(); &#125; &#125; finally &#123; if (server != null) &#123; System.out.println("服务器已关闭"); server.close(); server = null; &#125; &#125; &#125;&#125; 从上述的一部分代码中看出，使用线程池来管理了socket。使用了线程池后，不仅能帮我们管理线程,使用FixedThreadPool能有效控制线程的最大数量，保证系统的资源的控制。但是，限制了线程的最大数量，如果发生大量的并发请求，超过最大数量的线程就只能等待，直到线程池中有空闲的线程可以被复用。而对socket的输入流读取时会一直阻塞，直到发生： 有数据可以读取 可用数据读取完毕 发生空指针异常 所以在读取数据较慢时候(数据量大、网络传输慢)，其他的消息只能等待。 NIO编程从上述的BIO模型中，可以很明显的看出其实大部分的线程都是在等待数据传输过来，这部分的线程一直都是在等待的状态，相当于在IO模型的第一部分wait data的状态。使用NIO，在第一阶段不会创建线程，而是采用channel来等待数据，当数据读取完毕后才创建线程来处理。NIO提供了与传统的BIO模型中的socket和ServerSocket相对应的socketChannel和ServerSocketChannel两种不同的套接字实现。 channel理解Channel,中文意思“通道”，表示IO源与目标打开的连接，类似于传统的“流”。但是Channel不能直接访问数据，需要和缓冲区buffer进行交互。打个比方，山西有煤，我们想要，于是乎建了一条铁路连通到山西，这条铁路就是这里的”Channel”，而buffer类似于火车。使用channel来处理IO请求的工作原理如下。buffer是内核地址空间的，也可以把channel理解为一条TCP通道。 从上面的图中可以看出可以设置一个API直接从内核地址空间的buffer中读取数据，不要将数据copy到用户空间中。这样可以极大的提高效率。程序的数据要先到jvm用户地址缓冲区，再到计算机内存中。也就是不能直接和计算机内存进行数据操作。那么通过内存映射文件，也就是上诉方式，内部以直接缓冲区和内存映射文件实现了直接访问内存。这样大大提高了效率。但是也有缺点，如果写过去的数据很大，然后jvm没有及时回收内存，那么结果可想而知。因此，这个适用于那种长久存放在内存不也不会被短时间内就需要回收的数据。 缓冲区bufferBuffer是一个数据的缓冲对象。在NIO中，所有的数据都是通过buffer处理。channel的数据要先读取到buffer中才可以直接使用。directBuffer指的是内核上的缓冲对象。netty是直接读取这部分的数据，少了将数据从内核拷贝到用户的过程。 select选择器 Selector(选择器)是java中检测多个NIO通道，并能够知晓通道是否有读写事件的组件，这样子一个线程能管理多个channel，从而管理多个网络。 使用一个Selector来管理多个channel的好处是只要很少的线程来处理通道。对于操作系统来说，线程之间的上下文切换需要很大的开销，而且每个线程都占用系统的资源(内存)。当通道触发了一个事件，表明这个事件已经就绪。所以某个客户端的channel成功连接上服务器称为连接就绪。一个serverSocketChannel准备好接收新进入的连接称为接受就绪。一个有数据可读的通道为读就绪。等待写数据的通道为写就绪。 使用NIO编程相当于多路IO复用模型的第一部分。在数据准备阶段由Selector来搞定。当数据传输完毕，Selector会调用用户线程来进行真正的IO读写。这是第二部分的内容。则NIO是一个同步非阻塞IO模型。同步和异步指的是再真正的IO读写的时候需不需要用户线程参与。 使用NIO的代码如下 12345// Selector的创建Selector selector = Selector.open();// Selector注册channelchannel.configureBlocking(false);SelectionKey key = channel.register(selector,Selectionkey.OP_READ); 将channel与Selector配合使用。将channel注册到Selector上，使用registor()方法实现。使用Selector，Channel必须为非阻塞模式。 registor方法的第二个参数是Selector对那种Channel的时间感兴趣，可以监听不同的四种事件。Connect事件，Accept事件，Read事件，Write事件。selectkey的合集 1234SelectionKey.OP_CONNECTSelectionKey.OP_ACCEPTSelectionKey.OP_READSelectionKey.OP_WRITE 通过Selector来选择channel。一旦Selector注册了一个或者多个channel，就可以调用多个select方法。select()方法会阻塞到至少有一个通道在你注册的事件上就绪了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123public class ServerHandler implements Runnable&#123; private Selector selector; private ServerSocketChannel serverChannel; private volatile boolean started; public ServerHandler(int port) &#123; try &#123; selector = Selector.open(); //打开selector serverChannel = ServerSocketChannel.open();//打开channel serverChannel.configureBlocking(false); //channel为非阻塞 serverChannel.bind(new InetSocketAddress(port), 1024); //绑定本地端口 serverChannel.register(selector, SelectionKey.OP_ACCEPT); //将chaannel注册到selector中，这个channel专门监听连接请求 started = true; System.out.println("服务器已启动，端口号：" + port); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; public void stop()&#123; started = false; &#125; @Override public void run() &#123; while (started) &#123; try &#123; selector.select(1000); //1s返回 Set&lt;SelectionKey&gt; keys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; it = keys.iterator(); SelectionKey key = null; while(it.hasNext())&#123; key = it.next(); it.remove(); try&#123; handleInput(key); &#125;catch(Exception e)&#123; if(key != null)&#123; key.cancel(); if(key.channel() != null)&#123; key.channel().close(); &#125; &#125; &#125; &#125; &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (selector != null) &#123; try &#123; selector.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private void handleInput(SelectionKey key) throws IOException &#123; if (key.isValid()) &#123; //处理新接入的连接消息 if (key.isAcceptable()) &#123; ServerSocketChannel ssc = (ServerSocketChannel)key.channel(); //一个新的连接，则在服务端新建一个ServerSocketChannel专门来监听这个事件 //通过ServerSocketChannel的accept创建SocketChannel实例 //完成该操作意味着完成TCP三次握手，TCP物理链路正式建立 SocketChannel sc = ssc.accept(); //设置为非阻塞的 sc.configureBlocking(false); //注册为读 sc.register(selector, SelectionKey.OP_READ); &#125; if(key.isReadable())&#123; //得到这个通道的信息 类似于指针 //连接已经建立。有一个socket抽象，那么建一个socketChannel来得到这个socket的引用 SocketChannel sc = (SocketChannel) key.channel(); //创建ByteBuffer，并开辟一个1M的缓冲区 ByteBuffer buffer = ByteBuffer.allocate(1024); //读取请求码流，返回读取到的字节数 int readBytes = sc.read(buffer); //主动去读取channel内的数据 //读取到字节，对字节进行编解码 if(readBytes&gt;0)&#123; //将缓冲区当前的limit设置为position=0，用于后续对缓冲区的读取操作 buffer.flip(); //根据缓冲区可读字节数创建字节数组 byte[] bytes = new byte[buffer.remaining()]; //将缓冲区可读字节数组复制到新建的数组中 buffer.get(bytes); String expression = new String(bytes,"UTF-8"); System.out.println("服务器收到消息：" + expression);k //处理数据 String result = null; try&#123; result = expression.toString(); &#125;catch(Exception e)&#123; result = "计算错误：" + e.getMessage(); &#125; //发送应答消息 doWrite(sc,result); &#125; //没有读取到字节 忽略// else if(readBytes==0); //链路已经关闭，释放资源 else if(readBytes&lt;0)&#123; key.cancel(); sc.close(); &#125; &#125; &#125; &#125; //异步发送应答消息 private void doWrite(SocketChannel channel,String response) throws IOException&#123; //将消息编码为字节数组 byte[] bytes = response.getBytes(); //根据数组容量创建ByteBuffer ByteBuffer writeBuffer = ByteBuffer.allocate(bytes.length); //将字节数组复制到缓冲区 writeBuffer.put(bytes); //flip操作 writeBuffer.flip(); //发送缓冲区的字节数组 channel.write(writeBuffer); //****此处不含处理“写半包”的代码 &#125;&#125; 服务端建立一个NIO的过程 打开ServerSocketChannel，监听客户端连接 绑定监听端口，设置连接为非阻塞模式 创建Reactor线程，创建多路复用器并启动线程 将ServerSocketChannel注册到Reactor线程中的Selector上，监听ACCEPT事件 Selector轮询准备就绪的key Selector监听到新的客户端接入，处理新的接入请求，完成TCP三次握手，简历物理链路 设置客户端链路为非阻塞模式 将新接入的客户端连接注册到Reactor线程的Selector上，监听读操作，读取客户端发送的网络消息 异步读取客户端消息到缓冲区 对Buffer编解码，处理半包消息，将解码成功的消息封装成Task 将应答消息编码为Buffer，调用SocketChannel的write将消息异步发送给客户端]]></content>
      <categories>
        <category>socket编程</category>
      </categories>
      <tags>
        <tag>socket编程</tag>
        <tag>计算机网络</tag>
        <tag>TCP/IP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LINUX的IO模型]]></title>
    <url>%2F2018%2F10%2F21%2FIO-model%2F</url>
    <content type="text"><![CDATA[LINUX的5种IO模型简介同步阻塞，同步非阻塞，异步阻塞，异步非阻塞这些不同的IO模型是如何定义的。在看了几篇博客后我总结了下，把自己说服通了。服务端的应用程序要响应客户端的请求时，要有IO请求。在网络IO中，首先，内核会先收集完整的TCP或者UDP数据包，再将数据从内核复制到用户的内存中。这里的IO模型是针对于服务器端的，因为客户端一般都是阻塞的。操作系统是分为用户空间和内核空间。是由操作系统来获取网络中的IO请求和获取数据。用户的程序是通过系统调用来获取内核中的IO请求数据。对于一个网络IO的情况，它会涉及到两个系统对象，一个是调用这个IO的进程或者线程，另一个就是系统内核(kernel)。当一个read操作发生时，它会经历两个阶段： 1 等待数据准备 2 将数据从内核拷贝到进程中记住这两点很重要，因为这些IO Model的区别就是在两个阶段上各有不同的情况。UNIX提供了5种的IO模型，任何的IO请求一定是这5种中的一种。 阻塞IO模型 BIO在默认的情况下，BIO的操作均是阻塞的。比如I/O模型下的套接字接口，进程空间recvfrom类似于socket.accept()，其系统调用直到数据包到达并且被复制到应用进程的缓冲区或者错误时才返回，在此期间一直等待。进程在调用recvform开始直到返回的整段时间都是被阻塞的。当用户进程recvfrom这个系统调用时候，kernal就开始IO的第一个阶段：准备数据。对于network io来说，很多时候数据还没有到达（比如没有收到完整的UDP包），kerna要等到收到足够的数据。而在用户进程这边，整个进程都会被阻塞。当kernal把数据准备好，它会将数据从kernal拷贝到用户内存中，然后kernal返回结果，用户进程菜解除block状态。BIO在执行IO的两个阶段都被block了。 非阻塞IO模型 NIO用户进程在recvfrom的时候，如果数据没有准备好，那么操作系统直接返回一个错误，一般非阻塞IO都会轮训去检查这个状态，看内核中是否已经准备好数据。从用户的角度看，当它发起一个read IO操作后，并没有等待，而是立马得到一个返回结果，用户知道了数据没有准备好，等过段时间再发起read请求。一旦kernel准备好了数据，并且收到了用户的read请求，就会将数据从kernel拷贝到用户内存。用户的进程在不断询问kernel数据是否准备好。 信号驱动IO开启套接字信号驱动IO功能，并通过系统调用signalaction来执行一个信号处理函数(系统调用立即返回，进程继续工作，非阻塞)当有数据到达时候，为进程生成一个signal信号，通过信号应用程序调用recvfrom来读取数据。 IO复用模型在上面的非阻塞IO模型中，每个进程都要去一直轮训数据是否准备好，会浪费大量的CPU效率。则可以增加一个进程来专门做这个事情，即IO复用模型。linux提供select/poll，进程将一个或者多个fd传递给select或者poll系统调用。比如多个请求到达，进程先传递给select或者poll系统调用，阻塞在select操作上select/poll顺序扫描fd是否就绪。linux还提供epoll系统调用。epoll基于事件驱动方式来代替顺序扫描，因此性能更高，当有fd就绪，立即回掉函数rollback。基于select/poll这个函数会不断轮询所负责的socket，当socket有数据到达时候，通知用户进程。当用户进程调用select时候，进程就被block了。当有数据到达内核时候，select就会返回，这时候用户进程可以调用read操作。select和poll的区别select中采用轮训的方式处理，数据结构类似于数组的数据结构。select的监听的数目为1024. 而epoll是维护一个队列，当队列中有活跃的socket，epoll就会取出这个socket处理。相当于实现了一个伪AIO模型。或者可以理解为wait notify 异步IO告知内核启动某个操作，并让内核在整个操作完成后(包括数据的复制)通知进程。信号驱动IO模型是通知何时开始一个IO操作，异步IO模型是内核通知IO操作何时完成。当用户发起一个read操作后，立刻就去做其他的事情了。从内核角度看，当收到一个AIO后，会先立刻返回，不会阻塞用户的进程。等kernel准备好数据后，将数据copy到用户内存。完成后kernel将会给用户发送一个signal，告诉read操作完成。 多路IO复用技术在IO编程中，服务端需要同时处理多个客户端接入请求的情况。如果每个请求都使用一个线程，一个线程大概是1M左右，最多只能支持几w个并发数。可以使用多线程和多路IO复用技术。 多路IO复用技术将多个IO阻塞都绑定到一个select进程或者线程上，从而使系统在单线程的情况下能处理多个客户端的请求。相比于传统的多线程模型，多路IO复用的优势是系统开销小，系统不需要创建额外的线程，也不需要维护这些线程的运行，降低了系统的维护工作量，节省了系统资源。 多路复用IO的场景服务端要处理多个处于监听状态或者多个连接状态的套接字。服务器需要同时处理多种网络协议的套接字。 IO阻塞，非阻塞，同步和异步概念同步异步在IO操作完成后，是用户进程主动得到的还是由kernel通知的。阻塞非阻塞在询问IO操作的过程是用户进程阻塞等待还是立刻得到返回结果举几个例子吧 同步阻塞BIO socket就是一个同步阻塞的例子，当调用socket.accept后一直阻塞到由数据才返回 同步非阻塞NIO相当于是同步非阻塞。因为当发起一个io请求后，将自己绑定到select上了，等到select发现有数据后，再唤醒线程去请求数据。 异步阻塞调用blockingqueue的take()方法 take方法是从队列中获得数据，如果队列为空就阻塞。相当于第一阶段是阻塞的。但是队列中的数据不是主动去获取的，而是其他线程放入的。当有数据后通知take的线程，则是异步的。所以是异步阻塞的方法 异步非阻塞blockingqueue的poll方法，poll方法时有数据立即得到返回结果，没有数据就返回null 。所以在第一阶段是非阻塞的。数据不是主动去获取的，而是其他线程塞入的。则是异步的。AIO也是异步非阻塞的。]]></content>
      <categories>
        <category>socket编程</category>
      </categories>
      <tags>
        <tag>IO模型</tag>
        <tag>BIO</tag>
        <tag>NIO</tag>
        <tag>AIO</tag>
        <tag>同步</tag>
        <tag>异步</tag>
        <tag>阻塞</tag>
        <tag>非阻塞</tag>
        <tag>socket编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[netty基础]]></title>
    <url>%2F2018%2F10%2F21%2Fnetty-basic%2F</url>
    <content type="text"><![CDATA[netty基础handler(处理器)netty中的SimpleChannelInboundHandler继承了ChannelInboundHandler接口，这个接口提供了很多处理事件的接口方法，可以覆盖这些方法来实现自己的逻辑。 handlerAdded 服务端收到新的客户端连接，会调用该方法 handlerRevmoved 服务端收到客户端断开，调用该方法 channelRead0 服务端读到客户端的写入信息 channelActive 服务端监听客户端的活动 channelInactive 客户端不在线 exceptiponCause 当出现Throwable对象才会调用，当Netty出现IO错误或者处理器抛出异常。记录错误信息将有问题的channel关闭。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667public class SimpleChatServerHandler extends SimpleChannelInboundHandler&lt;String&gt;&#123; public static ChannelGroup channels = new DefaultChannelGroup(GlobalEventExecutor.INSTANCE); //所有的通道 /** * 有新的客户端接入，调用该方法 * */ @Override public void handlerAdded(ChannelHandlerContext ctx) throws Exception &#123; Channel incoming = ctx.channel(); // 每次有handler加入，就会生成ctx的channel for (Channel channel : channels) &#123; channel.writeAndFlush("[SERVER] - " + incoming.remoteAddress() + " 加入\n"); &#125; channels.add(incoming); &#125; /** * 有客户端离开，调用该方法 * */ @Override public void handlerRemoved(ChannelHandlerContext ctx) throws Exception &#123; Channel incoming = ctx.channel(); // 每次有handler加入，就会生成ctx的channel for (Channel channel : channels) &#123; channel.writeAndFlush("[SERVER] - " + incoming.remoteAddress() + " 离开\n"); &#125; channels.remove(incoming); &#125; @Override protected void channelRead0(ChannelHandlerContext ctx, String s) throws Exception &#123; Channel incoming = ctx.channel(); for (Channel channel : channels) &#123; if (channel != incoming) &#123; channel.writeAndFlush("[" + incoming.remoteAddress() + "]" + s + "\n"); &#125; else &#123; channel.writeAndFlush("[you]" + s + "\n"); &#125; &#125; &#125; /** * 在线检测 * */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; Channel incoming = ctx.channel(); System.out.println("SimpleChatClient:" + incoming.remoteAddress() + "在线"); &#125; /** * 掉线检测 * */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; // (6) Channel incoming = ctx.channel(); System.out.println("SimpleChatClient:"+incoming.remoteAddress()+"掉线"); &#125; /** * 异常检测 * */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) &#123; // (7) Channel incoming = ctx.channel(); System.out.println("SimpleChatClient:"+incoming.remoteAddress()+"异常"); // 当出现异常就关闭连接 cause.printStackTrace(); ctx.close(); &#125; netty的粘包和拆包问题服务端收到2个数据包，两条数据包都是完整的。 粘包服务端一共就收到一个数据包，数据包中有2条消息，发生了TCP粘包 拆包一条消息被拆分到2个包里发送了 发生TCP的粘包和拆包的主要原因是 应用程序写入的数据大于套接字缓冲区的大小，发生了拆包 应用程序写入的数据小于缓冲区的大小，网卡将应用多次写入的数据发送到网络中，发生粘包 进行MSS大小的TCP分段，当TCP报文长度大于MSS，发生拆包 接收方法不及时读取缓冲区大小，发生粘包 如何解决粘包、拆包问题： 使用带有消息头的协议，从消息头中读取出消息长度信息和开始标识。 设置定长信息，服务端每次读取既定长度的内容 设置消息边界，设置回车等等。]]></content>
      <categories>
        <category>socket编程</category>
      </categories>
      <tags>
        <tag>socket编程</tag>
        <tag>netty基础</tag>
        <tag>粘包和拆包</tag>
        <tag>NIO模型</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[现代操作系统知识点]]></title>
    <url>%2F2018%2F10%2F21%2Fmodern-operation-system%2F</url>
    <content type="text"><![CDATA[现代操作系统知识点现代操作系统有一些知识点需要归纳一下。先记录一部分，后续再慢慢补充。 线程和进程线程和进程的区别进程是一个程序在一个数据集上运行的实例，进程是系统进行资源分配和调度的独立单位。线程是CPU调度的基本单位。线程本身不拥有系统资源，线程之间共享进程的资源，线程可以撤销另一个进程，进程之间可以并发运行。进程只能由另一个进程fork出来。 创建进程的方法进程的创建有以下几种方法 系统初始化 系统初始化会在前台和后台创建一些必要的进程。 执行了一个从事创建进程的API，这个API被正在运行的进程调用 用户请求创建新进程。 一个批作业的初始化批作业是指运行多个程序，如果cpu有资源，就创建进程运行其他的程序所有的进程只能由一个已经运行的进程创建，子进程是父进程的一个副本。但是地址空间不同，线程无法创建进程。进程的状态进程主要分为三种状态： 运行态(该时刻进程占用CPU) 就绪态(可运行，但是还没轮到他运行) 阻塞态(除非某种外部事件发生唤醒他，不然不能运行) 使用线程的原因在传统的操作系统中，进程拥有独立的内存地址空间和一个用于控制的线程。但是，现在的情况更多的情况下要求在同一地址空间下拥有多个线程并发执行（阻塞）。因此线程被引入操作系统。 多线程之间共享同一个地址空间和所有可用数据的能力。多进程模型(多个进程之间不共享地址空间)不能表达出来的。 线程比进程更加轻量级，所以线程比进程更快创建和取消。 线程的创建时间比进程快１０倍到１００倍。 性能方面。如果多线程都是从事cpu密集工作，那么不会提升性能。 但是存在I/O阻塞，使用多线程会提升速度。不同的进程分配在堆上的内存不能互相访问，因为进程之间的内存空间是互相独立的。操作系统实现线程的几种方式内核线程操作系统知道线程的存在，线程表存放在操作系统内核所有阻塞线程的调用都是以系统调用(system call)的方式实现。当一个线程阻塞时，系统可以选择将CPU交给同一个进程中的其他线程或者其他进程中的线程。在内核中实现线程的成本较高，可以采用线程回收技术。当一个线程被销毁时，修改标志位而不是销毁线程本身。当注册一个新的线程时，同样修改标志位，类似于线程池。用户线程将线程包都放在用户空间，内核对线程包不知道。内核按照单线程进程管理。进程中要用专门的线程表来跟踪线程的运行。用户级线程的优点 在用户空间下进行线程切换的速度要远快于在操作系统内核中实现 在用户空间下实现线程使得程序员可以实现自己的线程调度算法。比如进程可以实现垃圾回收器来回收线程。还有，当线程数量过多时，由于在用户空间维护线程表，不会占用大量的操作系统空间。 用户级线程的缺点: 如何实现系统阻塞调用 因为内核当线程阻塞时，会按照单线程进程处理，阻塞整个进程，即使这个进程中的其他线程还在工作。CPU只能调度内核线程，即轻量级进程。 如果线程长时间不释放CPU,因为用户空间没有时钟中断，导致进程中的其他线程得不到CPU而持续等待。(CPU只能切换内核线程,不能切换线程) 混合模式还有一种实现方式是将上面两种模式进行混合，用户空间中进程管理自己的线程，操作系统内核中有一部分内核级别的线程。在这种模式下，操作系统只能看到内核线程。用户空间线程基于操作系统线程运行。因此，程序员可以决定使用多少用户空间线程以及操作系统线程，这无疑具有更大的灵活性。而用户空间线程的调度和前面所说的在用户空间下执行实现线程是一样的，同样可以自定义实现。如果线程阻塞，那么内核就调用内核线程去调度其他的线程。内核级线程中有一个可以轮流使用的用户线程合集。 进程间通信进程间通信只要包括3个方面 进程A如何把消息传递给进程B 进程之间的同步问题。比如共同抢占资源和进程之间的先后顺序 进程间的通信的方式有管道，信号量，消息队列，共享内存和套接字 管道：半双工的通信方式，数据只能单向流动，而且只能在有亲缘关系的进程使用。进程的亲缘关系指父子进程关系 有名管道:半双工方式，允许没有亲缘关系的进程通信 信号量：信号量是限制访问资源的数目 和semophere类似 消息队列：消息队列是消息的链表，存放在内存中，消息队列克服信号传递信息少，管道只能承载无格式字节符和缓冲区受限制。 信号：通知进程某个事件完成。 wait nofity 共享内存，共享的内存 堆 套接字：其他可能需要用同一个系统内核做中介，套接字是基于网络传输来实现。 socket 进程调度的方式当计算机系统是多道程序设计系统，则多个进程会竞争CPU，这样就需要一个调配程序告诉CPU在哪个时间点执行哪个进程，这就是调度。 轮转调度：每个进程平均分时间段去使用CPU，这样导致管理时间很久，浪费和大 优先级调度：每个进程都有一个优先级别，级别高的有权先调度，级别低的用后面再调度。 最短进程优先：最短进程优先就会有最短响应时间。 保证调度：向用户做出明确的调度保证，然后去实现它。 彩票调度：改进版的彩票调度，向每个进程提供的各种系统资源的彩票，一旦要做出决策时，就随机抽取一张彩票，拥有该彩票的进程获得该资源，得到CPU的应用时间。 公平分享调度：这个是为了改善不同用户间的进程而设置的。 用户空间和内核空间 进程上下文和中断上下文我们知道现在操作系统都是采用虚拟存储器，那么对32位操作系统而言，它的寻址空间（虚拟存储空间）为4G（2的32次方）。操心系统的核心是内核，独立于普通的应用程序，可以访问受保护的内存空间，也有访问底层硬件设备的所有权限。为了保证用户进程不能直接操作内核，保证内核的安全，操心系统将虚拟空间划分为两部分，一部分为内核空间，一部分为用户空间。针对linux操作系统而言，将最高的1G字节（从虚拟地址0xC0000000到0xFFFFFFFF），供内核使用，称为内核空间，而将较低的3G字节（从虚拟地址0x00000000到0xBFFFFFFF），供各个进程使用，称为用户空间。每个进程可以通过系统调用进入内核，因此，Linux内核由系统内的所有进程共享。于是，从具体进程的角度来看，每个进程可以拥有4G字节的虚拟空间。需要注意的细节问题： 内核空间中存放的是内核代码和数据，而进程的用户空间中存放的是用户程序的代码和数据。不管是内核空间还是用户空间，它们都处于虚拟空间中。 内核态与用户态：当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核运行态（内核态）。此时处理器处于特权级最高的（0级）内核代码中执行。当进程处于内核态时，执行的内核代码会使用当前进程的内核栈。每个进程都有自己的内核栈。当进程在执行用户自己的代码时，则称其处于用户运行态（用户态）。此时处理器在特权级最低的（3级）用户代码中运行。当正在执行用户程序而突然被中断程序中断时，此时用户程序也可以象征性地称为处于进程的内核态。因为中断处理程序将使用当前进程的内核栈。 调度程序激活当内核了解到一个线程阻塞后，内核就通知这个该进程的运行时系统，并且在堆栈中传递有问题的线程的编号和问题描述。然后运行时系统就将该线程标记为阻塞并从就绪表中取出另一个线程，设置寄存器，启动这个线程。当内核知道了之前的线程可运行了，就在再次调用进程的运行时系统，通知这个事件，这时候运行时系统可以根据自己的判断立即启动这个线程或者放在就绪表中稍后运行。 存储管理存储管理主要讲了操作系统的分页，分段和页面置换算法和寻址的细节实现。 存储器抽象无储存器抽象，程序都是访问物理地址。则在电脑上无法运行两个程序。暴露物理地址的问题是 如果程序可以寻址内存的多个地址，那么容易破坏操作系统 这种模型无法运行多个程序 解决多个程序之间在内存中互不影响的问题： 在没有内存抽象的系统中实现并行使用多线程编程。 因为多线程是进程中的所有线程对同一个内存映像可见。 但是人们希望在同一时间运行没有关联的程序，这是线程抽象不能提供。总结 暴露地址空间带来的问题 用户程序可以寻址内存的每个字节，可以破坏操作系统。 无法在一个系统中运行多个程序。当一个程序在2000的位置写入新的值，会将原来的程序在2000的值擦除。 地址空间地址空间是一个进程用于寻址内存的一套地址集合。每个进程都有自己的地址空间，并且和其他的进程不同。 基址寄存器和界限寄存器程序的起始物理地址装载到基址寄存器中，程序的长度装到界限寄存器中。但是他们的缺点是每次访问内存都需要进行加法和比较运算，效率相对低。程序过大，无法将多个程序都放在内存中运行。解决办法有交换策略和虚拟内存。 交换内存把一个进程完整的调入内存，运行一段时间后保存回磁盘。交换策略会在内存中产生空闲区，通过把所有进程尽可能向下移动，有可能将小的空闲区合成一块，该技术称为内存紧缩。如果程序的数据段会增长，如java允许程序在堆上动态分配内存。则分配内存时候分配空闲区。空闲内存管理可以使用位图或者是链表进行存储管理。分配内存有多重算法，对应的是NP问题，现在常用的算法有：首次适配算法，最佳适配算法，下次适配算法等等。 虚拟内存比如内存1g，但是程序需要2g的内存。那么使用交换内存技术就无法实现。又或者内存1g，程序1g。如果sata磁盘的速率为100m/s，那么每次交换需要10s时间。效率很低。虚拟内存将整块的程序分成小片,那么交换的时候不需要全部交换，可以省去很多时间。定义：每个程序都拥有自己的地址空间，这个空间被划分成多个块，称为虚拟页面。将这个页面向实际的地址空间映射。但是不是所有的页都要在地址空间中。如果不存在，称为页面缺陷。由操作系统从磁盘中找到这部分的程序写入地址中。如图所示。cpu向MMU发送页面8的地址发现没有对内存的实际映射，引发缺页中断，那么MMU将把内存中不常使用的页框中的内容写到磁盘，比如页框1，然后把页面1的对应关系设置为未映射，将页面8的内容读到页框1中。 分页技术现在大部分虚拟内存系统都使用分页技术。虚拟地址通过送到MMU转换成物理地址。虚拟地址空间按照固定大小划分成页面的若干单元，在物理内存中对应的单元称为页框。现有系统的页大小一般是512字节到64kb。 虚拟地址寻址MMU的内部结构如下所示。这个页表是MMU的内部一个表格，使用页号作为页表的索引。当输入的虚拟地址为8196(十六进制2004)，那么高4位作为页号，低12位作为偏移量。则输入的实际地址为24580。达到寻址目的。 加速分页过程当有32位地址时，如果使用4kb的页面大小，那么会有2^20个的页面索引号。页表查询会非常慢。解决办法： 可以使用转换检测缓冲区（TLB）来加速转换。ＴＬＢ中保存了最近使用的虚拟地址。每次MMU都会先去TLB中寻找页框的对应号，如果没有才会进行正常的页表查询。 多级页表对于32位地址总线可以使用 32位的地址总线，划分成10位的PT1区，10位的PT2区，12位的偏移。那么PT1将地址划分成4M，PT2将地址划分成4K。每一个表项为1024个表索引。那么PT1将地址分成了4M一份。存储页表项大概需要16M。因为2^22个表项，一个表项为4个字节。 倒排页表对于64位的地址总线，虚拟地址的大小为2^64。 对于64位虚拟地址，4kb的页，1g的ram。如果是使用4kb大小的页面大小，那么久需要2^50 个页表项，一个页表的指针大小为8个字节，那么整个页表要超过3000万GB。不现实。使用倒排页表将使用虚拟页表到物理地址的映射。则只需要2^18 个页表项，即262144个页表项。1g为2的30次方，4kb为2的12次方。问题：从虚拟地址到物理地址的映射无法直接得到。要先去查找物理地址。那么每次都要查找2^18 项的表，运行会很慢。解决办法：使用散列表，用虚拟地址散列，每一项为物理地址对应虚拟地址。用虚拟地址为key，则将64位的hash散列到2^18 -1槽的物理地址map中，这时候肯定会存在hash冲突。其中每一项记录的是虚拟页面和物理地址的key_value。然后在这个继续根据hash来查找真实的物理页面号。 页面置换算法：当发生缺页中断时，操作系统要在内存中找到一个页面置换出去，将即将调入的页面问题：如果使用经常使用的页面置换，那么将会发生频繁的磁盘写入写出过程降低效率。那么要选择最优的页面来置换。 最优页面置换算法：此算法是理想状态，不可能实现。它希望把最后才使用的页面置换出去，不过由于不可知每个页面的下一次使用时间，所以是做不到的。 最近未使用页面置换算法(NRU not recently used)：系统为每个页面设置两个状态位。当页面被访问的时候设置R位，当页面被修改的时候设置M位置换算法为：当启动一个进程时，该进程的所有的页面两个位都设置为0，R位定期的被清零（20ms），以区别最近页面有没有访问。如果R还是1，那么说明这个页面在20ms内使用了，是频繁使用的。NRU算法随机地从类编号最小的非空类中挑选一个页面淘汰。 先进先出页面算法(FIFO)该算法淘汰存在时间最长的页面，可能会淘汰重要的不实用的页面。 第二次机会页面置换算法：检查页面的R位，如果R位为0，则被置换出去，如果R位是1，则将R位清零，并将页面放在链表的尾部，并修改它的装入时间，就想好刚刚装入一样。第二次会算法就是寻找一个最近的时钟间隔以来没有被访问过的页面，如果所有的页面都被访问过，该算法就简化为纯粹的FIFO算法。 最近最少使用页面置换算法(LRU Least Recently Used)：当出现缺页中断时，置换最长时间未使用的页面 老化算法只需要8位的时间寄存器，寄存器的值不断右移，最后判断最小的值。如果时钟的间隔是20ms，8位一共是160ms，在160ms时间内使用最少的次数的页面。 工作集算法:跟踪程序的主要的页面，然后将该页面预先放入内存，减少缺页中断。页面算法总结：LRU算法是非常优秀的算法，但是只能通过特定的硬件来实现。NFU是一种近似于LRU的算法。它的性能不是非常好，但是可以很有效的实现，因此是一个很好的选择。总之，最好的两种算法是老化算法和工作集时钟算法。他们分别基于LRU和工作集。缺页中断处理 硬件陷入内核，在内核堆栈中保存程序计数器。 系统发现缺页中断后，找到该虚拟页面，检查地址是否有效或者写保护，无效杀死进程等。 地址有效，则检查是否有空闲页框，没有就用页面置换算法找到一个合适的页面替换。 如果页面脏了，就重写回磁盘，IO阻塞，内核运行其他进程。 页框干净后，磁盘查找所需所需页面在磁盘的位置，通过磁盘将页面写入内存。 等页面完全写入内存后，将恢复程序计数器，重新运行该进程。 死锁的概念可抢占资源和不可抢占资源的概念 可抢占资源指可以从占有的进程中将资源抢占而不出错，存储器等 不可抢占资源指在使用过程中无法抢占。如打开的文件，刻录机等死锁发生的条件 互斥 占有和等待条件 获取了一个资源的进程可以获取新的资源 不可抢占条件 已经分配给一个进程的资源不能被强制剥夺，只能等进程释放 环路等待条件 多个进程在请求资源时形成了环路IO阻塞的过程当进程请求的资源不存在时候发生IO阻塞时候，就进入休眠，进入队列，等待满足的条件发生由CPU唤醒]]></content>
      <categories>
        <category>现代操作系统</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>现代操作系统</tag>
        <tag>计算机基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[面试基础 TCP知识点]]></title>
    <url>%2F2018%2F10%2F20%2FTCP%2F</url>
    <content type="text"><![CDATA[咳咳，TCP知识点归纳总结一波。作为后端工程师需要了解一些的计算机网络知识点，点到为止即可吧。 计算机网络知识要点 计算机网络分层OSI分层 : 物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。5层协议： 物理层，数据链路层，网络层，传输层，应用层 IP地址分类A类地址：以0开头，第一个字节范围：0~127； 0开始 第1位到第8位 网络标识 后24位主机标识 2^24-2 = 65,777,214 个主机B类地址：以10开头，第一个字节范围：128~191； 10开头 从1位到16位 网络标识 后12位主机 2^12 -2 = 65534个主机C类地址：以110开头，第一个字节范围：192~223； 110开头 从1位到24位 网络标识 2^8 -2 = 254个D类地址：以1110开头，第一个字节范围为224~239；1110 第1位到32位 没有主机标识 用于多播 ARP地址解析协议 address resolution protocolARP是同一个链路层的地址解析协议。每一个主机都会在自己的ARP缓冲区中建立ARP列表，表示IP和MAC的对应关系。当源主机发送数据包到目标主机时，先检查自己的ARP列表中是否有目标IP对应的mac地址。没有的话就发送ARP请求包，其中含有源主机IP地址，MAC地址，目标主机IP地址。网络中的主机收到ARP后会检查自己的ARP列表，存在就发送结果。 DNS域名系统 domain name system浏览器发送www.baidu.com的执行过程 1. 客户端浏览器通过DNS解析到网址的IP地址。2.在应用层客户端发送HTTP请求到IP地址。3.在传输层将HTTP回话分成报文段，添加源端口和目标端口。4.网络层，在报文中添加源IP地址和目标地址，并通过路由得到一条从客户端到服务端的路径。5.在链路层，发送ARP请求得到目标的mac地址，发送数据。 TCP和UDP的区别TCP是面向连接、可靠的数据流传输，而UDP提供的是非连接，不可靠的数据流传输。TCP注重数据的安全性，而UDP是传输的速度快，安全性一般。 TCP的连接过程 3次握手，4次挥手 TCP的窗口和重发机制TCP使用窗口的概念提高发送速度，因为每一次的ack的确认应答造成流量浪费，并且速度慢。窗口的大小指无需确认应答而可以继续发送数据的最大值。这个机制是使用了缓冲区。没有确认应答的信号存储在缓冲区中，而不是丢弃。某些ack即使丢弃也无需重发，可以通过下一次的ack确认信号来确认。 TCP的可靠性机制TCP的可靠性是相对于UDP的不可靠传输而言的。TCP一定能保证数据到达对方。实现TCP的可靠性机制是：1.校验和 保证数据没有被破坏2.定时器 超时重发3.序号 检测丢失的分组和冗余的分组4.确认应答ACK 收到3个同样的ACK信号，表示数据丢失，客户端重传 客户端没有收到ACK，超时重发数据包5.窗口 增加吞吐量 TCP链接的半开链接当客户端和服务端建立TCP链接后，如果客户端掉线，没有主动断开链接和重启系统，服务端就等不到这个数据，浪费资源。TCP链接有SO_KEEP_ALIVE选项，如果在一定的时间内没有数据传输就发送探针，没有响应就移除该链接。但是SO_KEEP_ALIVE是基于整个内核维护，所有的socket都会受到影响。可以在应用层来解决这个问题。使用PING PONG心跳机制来解决这个问题。不能再服务端发送，浪费资源。客户端发送，服务端来响应。 TCP的三次握手过程？为什么会采用三次握手，若采用二次握手可以吗？建立连接的过程是利用客户服务器模式，假设主机A为客户端，主机B为服务器端。TCP的三次握手过程：主机A向B发送连接请求；主机B对收到的主机A的报文段进行确认；主机A再次对主机B的确认进行确认。采用三次握手是为了防止失效的连接请求报文段突然又传送到主机B，因而产生错误。失效的连接请求报文段是指：主机A发出的连接请求没有收到主机B的确认，于是经过一段时间后，主机A又重新向主机B发送连接请求，且建立成功，顺序完成数据传输。考虑这样一种特殊情况，主机A第一次发送的连接请求并没有丢失，而是因为网络节点导致延迟达到主机B，主机B以为是主机A又发起的新连接，于是主机B同意连接，并向主机A发回确认，但是此时主机A根本不会理会，主机B就一直在等待主机A发送数据，导致主机B的资源浪费。采用两次握手不行，原因就是上面说的实效的连接请求的特殊情况。]]></content>
      <categories>
        <category>计算机基础</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
        <tag>面试相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ConcurrentHashMap]]></title>
    <url>%2F2018%2F09%2F10%2FConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[#HashMap和ConcurrentHashMap的原理，非常重要哦！！！最近在看JAVA并发编程实践，ConcurrentMap是Concurrent包中一个非常重要的同步容器，在工作中也会使用到它。对于这样的容器，想要最为一个合格的后端攻城狮，必须经常的将它的源码翻出来看看，不然搬砖就搬的太失败了。本文想记录下自己对HashMap和ConcurrentHashMap的分析。在1.7版本和1.8版本中java的源码发生了巨大的变化，好多之前用ReenTrantLock的貌似都改成了使用CAS或者violatile来实现。只能说HB法则太好用了。。。。 1.7版本的HashMapHashMap是key-value的数据结构，同时key和value均可以为null，如果key为null，默认是放到table[0]的位置。HashMap的底层是数组+链表的结构。HashMap里面是存放了一个数组，数组的每个元素都是一个单向链表。链表的每个节点是Entry结构，成员结构为key,value,hash,next。在HashMap中还有其他成员 capacity: 当前的数组容量，始终保持2^n， 扩容后大小为当前的2倍。 loadFactor: 负载因子，默认为0.75 threshold: 扩容的阈值，等于capacity * loadFactor put的过程1.7版本的hashmap的实现比较简单。 1234567891011121314151617181920212223242526272829public V put(K key, V value) &#123; // 当数组为null，初始化数组 if (table == EMPTY_TABLE) &#123; inflateTable(threshold); &#125; // 如果 key 为 null，将这个key放在table[0]的位置 if (key == null) return putForNullKey(value); // 1. 求 key 的 hash 值 int hash = hash(key); // 2. 找到对应的数组下标 int i = indexFor(hash, table.length); // 3. 遍历一下对应下标处的链表，看是否有重复的 key 已经存在， // 如果有，直接覆盖，put 方法返回旧值就结束了 for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; modCount++; // 4. 不存在重复的key，将entry加入到table的曹里面 addEntry(hash, key, value, i); return null;&#125; 数组的初始化插入第一个元素时会初始化HashMap，主要是计算初始化的table大小和阈值，table大小必须是2^n 12345678910private void inflateTable(int toSize) &#123; // 保证数组大小一定是 2 的 n 次方。 // 比如这样初始化：new HashMap(20)，那么处理成初始数组大小是 32 int capacity = roundUpToPowerOf2(toSize); // 计算扩容阈值：capacity * loadFactor threshold = (int) Math.min(capacity * loadFactor, MAXIMUM_CAPACITY + 1); // 算是初始化数组吧 table = new Entry[capacity]; initHashSeedAsNeeded(capacity); &#125; 计算数组的具体位置1234static int indexFor(int hash, int length) &#123; //hash对数组长度取模即可。 return hash &amp; (length-1);&#125; 添加entry到链表中123456789101112131415161718192021void addEntry(int hash, K key, V value, int bucketIndex) &#123; // 如果当前 HashMap 大小已经达到了阈值，并且新值要插入的数组位置已经有元素了，那么要扩容 if ((size &gt;= threshold) &amp;&amp; (null != table[bucketIndex])) &#123; // 扩容 resize(2 * table.length); // 扩容以后，重新计算 hash 值. 如果key为null，放到0的位置 hash = (null != key) ? hash(key) : 0; // 重新计算扩容后的新的下标 bucketIndex = indexFor(hash, table.length); &#125; // createEntry(hash, key, value, bucketIndex);&#125;// 这个很简单，其实就是将新值放到链表的表头，然后 size++void createEntry(int hash, K key, V value, int bucketIndex) &#123; //找到表头 Entry&lt;K,V&gt; e = table[bucketIndex]; //当前节点为新的表头，next指向e table[bucketIndex] = new Entry&lt;&gt;(hash, key, value, e); size++;&#125; 数组扩容1234567891011121314void resize(int newCapacity) &#123; Entry[] oldTable = table; int oldCapacity = oldTable.length; if (oldCapacity == MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return; &#125; // 新的数组 Entry[] newTable = new Entry[newCapacity]; // 将原来数组中的值迁移到新的更大的数组中 transfer(newTable, initHashSeedAsNeeded(newCapacity)); table = newTable; threshold = (int)Math.min(newCapacity * loadFactor, MAXIMUM_CAPACITY + 1);&#125; 数组扩容会将原来的table[i]节点拆分到newTable[i]和newTable[i+oldLength]的位置。如果原来的数组长度为16，那么table[1]的节点的元素会分配到table[1]和table[17]的位置。 get过程分析get的过程比较简单 根据key计算hash值 根据hash值计算数组下标，hash &amp; (length-1) 遍历数组该位置的链表，直到找到key相等的key就可以了 所以在同一个链表中，key的hash都是相同的。 123456789101112131415161718192021222324252627public V get(Object key) &#123; // key 为 null 的话，会被放到 table[0]，所以只要遍历下 table[0] 处的链表就可以了 if (key == null) return getForNullKey(); // Entry&lt;K,V&gt; entry = getEntry(key); return null == entry ? null : entry.getValue();&#125;final Entry&lt;K,V&gt; getEntry(Object key) &#123; if (size == 0) &#123; return null; &#125; int hash = (key == null) ? 0 : hash(key); // 确定数组下标，然后从头开始遍历链表，直到找到为止 for (Entry&lt;K,V&gt; e = table[indexFor(hash, table.length)]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; return null;&#125; 1.8版本的HashMap相比于1.7版本的HashMap，主要有以下几个优化 Entry改成了Node，红黑树的节点为TreeNode 当链表的长度大于8时，链表会转化成红黑树存储，提高查找效率。 Node结构Node结构和Entry结构基本相同。使用红黑树时节点为TreeNode，可以根据第一个节点为Node还是TreeNode来判断是链表还是红黑树。 12345678910111213141516171819202122232425262728293031323334353637static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; V value; Node&lt;K,V&gt; next; Node(int hash, K key, V value, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.value = value; this.next = next; &#125; //重写了hashCode，key的hash^value的hash public final int hashCode() &#123; return Objects.hashCode(key) ^ Objects.hashCode(value); &#125; public final V setValue(V newValue) &#123; V oldValue = value; value = newValue; return oldValue; &#125; //判断两个Entry是不是相等，判断key和value都相等即可 public final boolean equals(Object o) &#123; if (o == this) return true; if (o instanceof Map.Entry) &#123; Map.Entry&lt;?,?&gt; e = (Map.Entry&lt;?,?&gt;)o; if (Objects.equals(key, e.getKey()) &amp;&amp; Objects.equals(value, e.getValue())) return true; &#125; return false; &#125; &#125; put过程12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152final V putVal(int hash, K key, V value, boolean onlyIfAbsent, boolean evict) &#123; //onlyIfAbsent表示只有key不存在才会进行put操作。 Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; p; int n, i; //table还没有初始化，要resize到16的初始大小 if ((tab = table) == null || (n = tab.length) == 0) n = (tab = resize()).length; //根据hash找到具体的数据下表，赋值给p如果为null，直接在该下表new一个Node。 if ((p = tab[i = (n - 1) &amp; hash]) == null) tab[i] = newNode(hash, key, value, null); else &#123; Node&lt;K,V&gt; e; K k; //hash相等，并且==或者equals判断key相等，使用==主要是判断null if (p.hash == hash &amp;&amp; ((k = p.key) == key || (key != null &amp;&amp; key.equals(k)))) e = p; //如果p是TreeNode结构，表示该链表是红黑树存储 else if (p instanceof TreeNode) e = ((TreeNode&lt;K,V&gt;)p).putTreeVal(this, tab, hash, key, value); else &#123; //单向链表存储结构 bitCount计数节点的个数 for (int binCount = 0; ; ++binCount) &#123; //如果next节点为null，表示没有找到key相同的节点，那就新建一个Node，插入到最后面 if ((e = p.next) == null) &#123; p.next = newNode(hash, key, value, null); //如果插入节点后，bitCount大于发直，要把该位置转化成红黑树的结构 if (binCount &gt;= TREEIFY_THRESHOLD - 1) // -1 for 1st treeifyBin(tab, hash); break; &#125; //找到key相同的节点 if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) break; p = e; &#125; &#125; //如果e不为null，onlyIfAbsent为false时，替换oldValue值。 if (e != null) &#123; // existing mapping for key V oldValue = e.value; if (!onlyIfAbsent || oldValue == null) e.value = value; afterNodeAccess(e); return oldValue; &#125; &#125; ++modCount; if (++size &gt; threshold) resize(); //扩容 afterNodeInsertion(evict); return null; &#125; resize扩容过程1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677final Node&lt;K,V&gt;[] resize() &#123; Node&lt;K,V&gt;[] oldTab = table; int oldCap = (oldTab == null) ? 0 : oldTab.length; //容量，数组的长度 int oldThr = threshold; int newCap, newThr = 0; if (oldCap &gt; 0) &#123; if (oldCap &gt;= MAXIMUM_CAPACITY) &#123; threshold = Integer.MAX_VALUE; return oldTab; &#125; else if ((newCap = oldCap &lt;&lt; 1) &lt; MAXIMUM_CAPACITY &amp;&amp; oldCap &gt;= DEFAULT_INITIAL_CAPACITY) newThr = oldThr &lt;&lt; 1; // double threshold 扩大一倍的阈值，thr = cap*factor &#125; else if (oldThr &gt; 0) // initial capacity was placed in threshold newCap = oldThr; else &#123; // zero initial threshold signifies using defaults newCap = DEFAULT_INITIAL_CAPACITY; newThr = (int)(DEFAULT_LOAD_FACTOR * DEFAULT_INITIAL_CAPACITY); &#125; if (newThr == 0) &#123; float ft = (float)newCap * loadFactor; newThr = (newCap &lt; MAXIMUM_CAPACITY &amp;&amp; ft &lt; (float)MAXIMUM_CAPACITY ? (int)ft : Integer.MAX_VALUE); &#125; threshold = newThr; @SuppressWarnings(&#123;"rawtypes","unchecked"&#125;) Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]; //创建新的数组 table = newTab; if (oldTab != null) &#123; for (int j = 0; j &lt; oldCap; ++j) &#123; //遍历老的数组 Node&lt;K,V&gt; e; if ((e = oldTab[j]) != null) &#123; oldTab[j] = null; //将老的table的位置设为null，便于垃圾回收 if (e.next == null) //如果只有当个元素 newTab[e.hash &amp; (newCap - 1)] = e; //赋值给新的位置，并且位置不变 else if (e instanceof TreeNode) //如果是红黑树，将红黑树的位置分成2份 ((TreeNode&lt;K,V&gt;)e).split(this, newTab, j, oldCap); else &#123; // preserve order //将链表赋值给新的数组，将hash值根据newCap的最高位分成2部分，保证老的曹位置均不需要改变，这样可以使用一套hash算法 Node&lt;K,V&gt; loHead = null, loTail = null; Node&lt;K,V&gt; hiHead = null, hiTail = null; Node&lt;K,V&gt; next; do &#123; next = e.next; if ((e.hash &amp; oldCap) == 0) &#123; if (loTail == null) loHead = e; else loTail.next = e; loTail = e; &#125; else &#123; if (hiTail == null) hiHead = e; else hiTail.next = e; hiTail = e; &#125; &#125; while ((e = next) != null); //低位槽 if (loTail != null) &#123; loTail.next = null; newTab[j] = loHead; &#125; //高位槽 if (hiTail != null) &#123; hiTail.next = null; newTab[j + oldCap] = hiHead; &#125; &#125; &#125; &#125; &#125; return newTab; &#125; 1.7resize过程死循环，1.8解决该问题1.8在resize过程中出现了loTail和hiTail两个链表，这个地方有必要讲解下。在1.7版本采用的transfer在并发时会出现死循环，而1.8是按照原来链表的顺序，不会出现死循环的情况。画图讲解下把。 在1.7版本中，resize的过程是反着插入，如下图所示，比如链表是3-&gt;5 那么在新的链表插入会变成5-&gt;3。这样在多线程中会容易出现死循环。也是图中的AB线程所示。当resize中，A线程刚好执行到获取到链表的第一个Entry，设为e。这个时候线程A被剥夺CPU时间挂起，B线程执行put操作，那么B也会执行resize操作，当线程B执行完毕后就会在图中所示的newTable[3]-&gt;5-&gt;3。这时候线程A会执行如下代码 123e.next = newTable[i];newTable[i] = e;e = e.next; 一顿操作后就会把3的引用又指向5了，这个时候A线程就会在这个链表死循环了。 1.8的resize过程中使用loHead和hiHead按照顺序移动新的链表，解决了死循环的问题。如下所示。遍历原来的链表，使用loHead和loTail来记录头结点和尾节点，然后一直在尾节点添加新的节点，这样计算B线程执行完毕后，A线程再去执行时也是读取到和原来的一样的记录。不会造成死循环。 get过程分析get的步骤和之前差不多 判断key的hash值，根据hash &amp; (length-1)找到下标 如果key为null，找到table[0]的值，取出 找到数组的位置，判断Node类型，如果是TreeNode，用红黑树的方法取数据 遍历链表，找到key相等 123456789101112131415161718192021222324252627public V get(Object key) &#123; Node&lt;K,V&gt; e; return (e = getNode(hash(key), key)) == null ? null : e.value;&#125;final Node&lt;K,V&gt; getNode(int hash, Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; first, e; int n; K k; if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (first = tab[(n - 1) &amp; hash]) != null) &#123; // 判断第一个节点是不是就是需要的 if (first.hash == hash &amp;&amp; // always check first node ((k = first.key) == key || (key != null &amp;&amp; key.equals(k)))) return first; if ((e = first.next) != null) &#123; // 判断是否是红黑树 if (first instanceof TreeNode) return ((TreeNode&lt;K,V&gt;)first).getTreeNode(hash, key); // 链表遍历 do &#123; if (e.hash == hash &amp;&amp; ((k = e.key) == key || (key != null &amp;&amp; key.equals(k)))) return e; &#125; while ((e = e.next) != null); &#125; &#125; return null;&#125; ##1.7版本的ConcurrentHashMap在1.7版本的ConcurrentHashMap中，为了提高并发的能力，采用了分段锁的概念。在内部采用了Segment的结构，一个Segment就是一个Hash Table结构，在Segment内部维护了链表数组。如上图所示，采用了Segment数组和HashEntry组成，也是数据+链表的实现方式。 成员结构Segment是同步map的内部类，同步map由segment数组组成。 1234567891011121314/** * Segment 数组，存放数据时首先需要定位到具体的 Segment 中。 */final Segment&lt;K,V&gt;[] segments;transient Set&lt;K&gt; keySet;transient Set&lt;Map.Entry&lt;K,V&gt;&gt; entrySet;static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; transient volatile int count; //元素的个数 在插入时候，count++,在删除时候count-- transient int modCount; //对table造成影响的操作数目,在插入和删除数据的时候modcount++ transient int threshold; //容量 transient volatile HashEntry&lt;K,V&gt;[] table; //链表数组，每一个元素代表链表的头部 final float loadFactor;&#125; 接着看HashEntry的组成，将value设置为volatile类型的，在get的时候就不需要加锁，保证了可见性。 12345 final K key; //不可变， final int hash; //不可变 volatile V value; //可见 final HashEntry&lt;K,V&gt; next; //引用不可变&#125; Segment的个数为2^n，方便使用位移操作加快定位的过程。key的hash值的高n位作为Segment的值，而低位作为HashEntry的定位。 get操作123456789101112131415161718192021222324252627282930313233//根据key获得segment的下表public V get(Object key) &#123; int hash = hash(key.hashCode()); return segmentFor(hash).get(key, hash);&#125;final Segment&lt;K,V&gt; segmentFor(int hash) &#123; return segments[(hash &gt;&gt;&gt; segmentShift) &amp; segmentMask]; //将hash右移segmentShift位后得到高n位，在跟segmentMask做&amp;操作，得到高n位的值&#125;//根据key和segment定位到table的表头。在V get(Object key, int hash) &#123; //count是volatile类型的，根据HB原则其他线程的put操作都被当前线程观察到。在其他线程的count++是在锁中完成、 if (count != 0) &#123; // read-volatile HashEntry&lt;K,V&gt; e = getFirst(hash); //玄幻遍历链表得到值 while (e != null) &#123; if (e.hash == hash &amp;&amp; key.equals(e.key)) &#123; V v = e.value; if (v != null) return v; return readValueUnderLock(e); // recheck 需要的，因为new一个节点至少需要3个步骤，重拍序导致可能赋引用，再初始化对象，使得value为null。需要加锁，保证可见性。 &#125; e = e.next; &#125; &#125; return null;&#125;//低Cap位得到table的下表HashEntry&lt;K,V&gt; getFirst(int hash) &#123; HashEntry&lt;K,V&gt;[] tab = table; return tab[hash &amp; (tab.length - 1)];&#125; put操作123456789101112131415161718192021222324252627282930V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; lock(); //对segment加锁 try &#123; int c = count; if (c++ &gt; threshold) // ensure capacity rehash(); HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue; if (e != null) &#123; oldValue = e.value; if (!onlyIfAbsent) e.value = value; &#125; else &#123; oldValue = null; ++modCount; tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value); count = c; // write-volatile 保证了其他线程能看到最新的添加的Entry节点。 &#125; return oldValue; &#125; finally &#123; unlock(); &#125;&#125; get时候为什么value可能会为null，需要加锁recheck在get过程中为什么会出现v为null的情况呢。这个我之前一直想不通，自从理解了内存重拍序后才明白的。可以看下我的另一个博客Happens-Before的如何写一个安全的单例的例子。其实就是内存重拍序导致的内存不可见。比如在get时正好其他线程在执行put操作，tab[index] = new HashEntry&lt;K,V&gt;(key, hash, first, value);在new一个HashEntry时至少需要3个步骤。1.开辟一个内存空间2.对象初始化3.将对象引用给栈内的局部变量。 这个过程由于指令重拍序变成1-3-2。那么就会出现value为null的情况。正好B线程执行到3，然后A线程get这个内容时得到这个引用，但是value还没有被赋值，取出的value为null。 1234V v = e.value;if (v != null) return v;return readValueUnderLock(e); remove操作1234567891011121314151617181920212223242526272829303132333435V remove(Object key, int hash, Object value) &#123; lock(); //加锁 try &#123; int c = count - 1; HashEntry&lt;K,V&gt;[] tab = table; int index = hash &amp; (tab.length - 1); //得到table的下标 HashEntry&lt;K,V&gt; first = tab[index]; HashEntry&lt;K,V&gt; e = first; while (e != null &amp;&amp; (e.hash != hash || !key.equals(e.key))) e = e.next; V oldValue = null; if (e != null) &#123; V v = e.value; if (value == null || value.equals(v)) &#123; oldValue = v; // All entries following removed node can stay // in list, but all preceding ones need to be // cloned. //在删除节点后面的节点可以保留，但是节点之前的节点都需要重新赋值。因为引用是final类型的，不能改变 ++modCount; HashEntry&lt;K,V&gt; newFirst = e.next; // 先新建一个newFirst，指向Node4，然后再新建一个Node1指向newFirst，然后再新建一个Node2指向Node1。 for (HashEntry&lt;K,V&gt; p = first; p != e; p = p.next) newFirst = new HashEntry&lt;K,V&gt;(p.key, p.hash, newFirst, p.value); tab[index] = newFirst; count = c; // write-volatile &#125; &#125; return oldValue; &#125; finally &#123; unlock(); &#125;&#125; remove操作是先找到要删除元素的位置，不能简单的把要删除元素的前面一个元素的next指针指向后面一个元素就可以了。因为HashEntry的next是final类型，赋值后不能改变，那么就要把待删除元素的前面元素都复制一遍，在一个链接到数组上面。 并发的保证在1.7的版本中，get操作是不需要加锁的，所以需要考虑get和put之间的先后顺序。 put操作的线程安全性segement继承了reentrantlock，在put时会调用lock独占锁操作，那么保证每次只有一个线程才能put进去。而默认是16个segment，所以concurrenthashmap可以支持16个线程并发访问。 get和put的先后顺序 因为table是volatile的，并且value也是volatile的，那么保证了可见性，即每次put后，get一定能获得最新的table和HashEntry节点。 1.8版本的COncurrentHashmap在1.8版本中，放弃使用了Segment，而是采用对table的每个槽都使用synchonorized加锁操作，因为synchonorized使用了偏向锁和轻量级锁的优化，同时两个线程put到一个槽的概率很低，所以升级到重量级锁的概率很低。在性能上也不差很多。和18版本的HashMap结构类似，但是需要保证线程安全性。 put操作1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); //求key的hash值，采用key的hashcode高16位和第16位异或 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //如果table为空，初始化table if (tab == null || (n = tab.length) == 0) tab = initTable(); //找到hash对应的table下标记为i，第一个节点为f else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果f为空，对i的槽CAS操作放入新的Node， //如果失败，表示其他线程放入Node，for循环重试 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //如果f的hash是MOVED，表示数组正在扩容 else if ((fh = f.hash) == MOVED) //帮助扩容 tab = helpTransfer(tab, f); else &#123; V oldVal = null; //表示f节点不为空，对table的头结点f加监视器锁 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //double check if (fh &gt;= 0) &#123; //头结点的hash大于0，表示链表 binCount = 1;//链表的长度计数 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //如果key相等，即hash相等且key的值相等，那么就覆盖旧的值 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) e.val = value; break; &#125; //插入到链表的最末端 Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //红黑树 else if (f instanceof TreeBin) &#123; Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; //binCount不为0，表示为链表操作 if (binCount != 0) &#123; if (binCount &gt;= TREEIFY_THRESHOLD) //如果链表的长度大于8，会将链表转化成红黑树 //同时，如果还会判断数组是否需要扩容 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 其中，有几个重要的函数是数组初始化initTable(),数组的扩容或者红黑树化treeifyBin(),helpTransfer()帮助扩容操作。 数组初始化initTable()123456789101112131415161718192021222324private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; if ((sc = sizeCtl) &lt; 0) //表示其他线程进行initTable操作 Thread.yield(); // lost initialization race; just spin else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //先设置sizeCtl为-1 try &#123; if ((tab = table) == null || tab.length == 0) &#123; //初始化table int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //设置sizeCtl，即Cap为0.75 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; sizeCtl = sc; &#125; break; &#125; &#125; return tab;&#125; 链表转红黑树或者数组扩容treeifyBin()treeifyBin不一定会做红黑树转化，而且还会做数组的扩容操作。 1234567891011121314151617181920212223242526272829private final void treeifyBin(Node&lt;K,V&gt;[] tab, int index) &#123; Node&lt;K,V&gt; b; int n, sc; if (tab != null) &#123; //当数组的长度小于64，即32或者16时会进行数组扩容操作 if ((n = tab.length) &lt; MIN_TREEIFY_CAPACITY) tryPresize(n &lt;&lt; 1); //扩容的方法 else if ((b = tabAt(tab, index)) != null &amp;&amp; b.hash &gt;= 0) &#123; //b为table的头结点，加锁访问 synchronized (b) &#123; if (tabAt(tab, index) == b) &#123; TreeNode&lt;K,V&gt; hd = null, tl = null; for (Node&lt;K,V&gt; e = b; e != null; e = e.next) &#123; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt;(e.hash, e.key, e.val, null, null); if ((p.prev = tl) == null) hd = p; else tl.next = p; tl = p; &#125; //将红黑树设置到数组的位置上 //treeNode继承了Node setTabAt(tab, index, new TreeBin&lt;K,V&gt;(hd)); &#125; &#125; &#125; &#125;&#125; 数组的扩容操作 tryPresize()12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//size已经翻倍了private final void tryPresize(int size) &#123; // c：size 的 1.5 倍，再加 1，再往上取最近的 2 的 n 次方。 int c = (size &gt;= (MAXIMUM_CAPACITY &gt;&gt;&gt; 1)) ? MAXIMUM_CAPACITY : tableSizeFor(size + (size &gt;&gt;&gt; 1) + 1); int sc; while ((sc = sizeCtl) &gt;= 0) &#123; Node&lt;K,V&gt;[] tab = table; int n; // 这个 if 分支和之前说的初始化数组的代码基本上 //是一样的，在这里，我们可以不用管这块代码 //tab的初始化操作 if (tab == null || (n = tab.length) == 0) &#123; n = (sc &gt; c) ? sc : c; if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; try &#123; if (table == tab) &#123; @SuppressWarnings("unchecked") Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = nt; sc = n - (n &gt;&gt;&gt; 2); // 0.75 * n &#125; &#125; finally &#123; sizeCtl = sc; &#125; &#125; &#125; else if (c &lt;= sc || n &gt;= MAXIMUM_CAPACITY) break; else if (tab == table) &#123; // 我没看懂 rs 的真正含义是什么，不过也关系不大 int rs = resizeStamp(n); //sc小于0，sc为什么会有小于0的情况？？？sc是个局部变量啊 if (sc &lt; 0) &#123; Node&lt;K,V&gt;[] nt; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; // 2. 用 CAS 将 sizeCtl 加 1，然后执行 transfer 方法 // 此时 nextTab 不为 null if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; // 1. 将 sizeCtl 设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2) // 我是没看懂这个值真正的意义是什么？不过可以计算出来的是，结果是一个比较大的负数 // 调用 transfer 方法，此时 nextTab 参数为 null //这个CAS的操作是如果SIZECTL的sizeCtl的内存值=sc， //就把sizeCtl设置成(rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) transfer(tab, null); //数据迁移函数 &#125; &#125;&#125; 在数组扩容时采用sizeCtl来控制扩容的进度。如果tab为null，说明是要进行数组的初始化，那么就用CAS将sizeCtl设置成-1，然后再进行tab的初始化，再将sizeCtl设置成一个正值，结束while循环。如果tab不为null，那么就将sizeCtl设置成负数，再执行transfer(tab, null)，在下一个循环将sizeCtl+1，执行 transfer(tab, nt)。所以可能的操作是执行一次transfer(tab，null)+多次transfer(tab, nt)。 其中，可以看下sizeCtl的介绍 123456789/** * Table initialization and resizing control. When negative, the * table is being initialized or resized: -1 for initialization, * else -(1 + the number of active resizing threads). Otherwise, * when table is null, holds the initial table size to use upon * creation, or 0 for default. After initialization, holds the * next element count value upon which to resize the table. */private transient volatile int sizeCtl; sizeCtl控制table的初始化或者扩容操作，当为负数时，表示table正在初始化或者resize，-1表示初始化，-(1+nt)，nt为线程的数目。另外，table为null时，sizeCtl为设置table初始化的容量大小。当初始化后，sizeCtl存的是下一次需要扩容的数量 transfer这部分代码实在是看不懂了 先马着吧，，，阿西吧 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199private final void transfer(Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab) &#123; int n = tab.length, stride; // stride 在单核下直接等于 n，多核模式下为 (n&gt;&gt;&gt;3)/NCPU，最小值是 16 // stride 可以理解为”步长“，有 n 个位置是需要进行迁移的， // 将这 n 个任务分为多个任务包，每个任务包有 stride 个任务 if ((stride = (NCPU &gt; 1) ? (n &gt;&gt;&gt; 3) / NCPU : n) &lt; MIN_TRANSFER_STRIDE) stride = MIN_TRANSFER_STRIDE; // subdivide range // 如果 nextTab 为 null，先进行一次初始化 // 前面我们说了，外围会保证第一个发起迁移的线程调用此方法时，参数 nextTab 为 null // 之后参与迁移的线程调用此方法时，nextTab 不会为 null if (nextTab == null) &#123; try &#123; // 容量翻倍 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1]; nextTab = nt; &#125; catch (Throwable ex) &#123; // try to cope with OOME sizeCtl = Integer.MAX_VALUE; return; &#125; // nextTable 是 ConcurrentHashMap 中的属性 nextTable = nextTab; // transferIndex 也是 ConcurrentHashMap 的属性，用于控制迁移的位置 transferIndex = n; &#125; int nextn = nextTab.length; // ForwardingNode 翻译过来就是正在被迁移的 Node // 这个构造方法会生成一个Node，key、value 和 next 都为 null，关键是 hash 为 MOVED // 后面我们会看到，原数组中位置 i 处的节点完成迁移工作后， // 就会将位置 i 处设置为这个 ForwardingNode，用来告诉其他线程该位置已经处理过了 // 所以它其实相当于是一个标志。 ForwardingNode&lt;K,V&gt; fwd = new ForwardingNode&lt;K,V&gt;(nextTab); // advance 指的是做完了一个位置的迁移工作，可以准备做下一个位置的了 boolean advance = true; boolean finishing = false; // to ensure sweep before committing nextTab /* * 下面这个 for 循环，最难理解的在前面，而要看懂它们，应该先看懂后面的，然后再倒回来看 * */ // i 是位置索引，bound 是边界，注意是从后往前 for (int i = 0, bound = 0;;) &#123; Node&lt;K,V&gt; f; int fh; // 下面这个 while 真的是不好理解 // advance 为 true 表示可以进行下一个位置的迁移了 // 简单理解结局：i 指向了 transferIndex，bound 指向了 transferIndex-stride while (advance) &#123; int nextIndex, nextBound; if (--i &gt;= bound || finishing) advance = false; // 将 transferIndex 值赋给 nextIndex // 这里 transferIndex 一旦小于等于 0，说明原数组的所有位置都有相应的线程去处理了 else if ((nextIndex = transferIndex) &lt;= 0) &#123; i = -1; advance = false; &#125; else if (U.compareAndSwapInt (this, TRANSFERINDEX, nextIndex, nextBound = (nextIndex &gt; stride ? nextIndex - stride : 0))) &#123; // 看括号中的代码，nextBound 是这次迁移任务的边界，注意，是从后往前 bound = nextBound; i = nextIndex - 1; advance = false; &#125; &#125; if (i &lt; 0 || i &gt;= n || i + n &gt;= nextn) &#123; int sc; if (finishing) &#123; // 所有的迁移操作已经完成 nextTable = null; // 将新的 nextTab 赋值给 table 属性，完成迁移 table = nextTab; // 重新计算 sizeCtl：n 是原数组长度，所以 sizeCtl 得出的值将是新数组长度的 0.75 倍 sizeCtl = (n &lt;&lt; 1) - (n &gt;&gt;&gt; 1); return; &#125; // 之前我们说过，sizeCtl 在迁移前会设置为 (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2 // 然后，每有一个线程参与迁移就会将 sizeCtl 加 1， // 这里使用 CAS 操作对 sizeCtl 进行减 1，代表做完了属于自己的任务 if (U.compareAndSwapInt(this, SIZECTL, sc = sizeCtl, sc - 1)) &#123; // 任务结束，方法退出 if ((sc - 2) != resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT) return; // 到这里，说明 (sc - 2) == resizeStamp(n) &lt;&lt; RESIZE_STAMP_SHIFT， // 也就是说，所有的迁移任务都做完了，也就会进入到上面的 if(finishing)&#123;&#125; 分支了 finishing = advance = true; i = n; // recheck before commit &#125; &#125; // 如果位置 i 处是空的，没有任何节点，那么放入刚刚初始化的 ForwardingNode ”空节点“ else if ((f = tabAt(tab, i)) == null) advance = casTabAt(tab, i, null, fwd); // 该位置处是一个 ForwardingNode，代表该位置已经迁移过了 else if ((fh = f.hash) == MOVED) advance = true; // already processed else &#123; // 对数组该位置处的结点加锁，开始处理数组该位置处的迁移工作 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; Node&lt;K,V&gt; ln, hn; // 头结点的 hash 大于 0，说明是链表的 Node 节点 if (fh &gt;= 0) &#123; // 下面这一块和 Java7 中的 ConcurrentHashMap 迁移是差不多的， // 需要将链表一分为二， // 找到原链表中的 lastRun，然后 lastRun 及其之后的节点是一起进行迁移的 // lastRun 之前的节点需要进行克隆，然后分到两个链表中 int runBit = fh &amp; n; Node&lt;K,V&gt; lastRun = f; for (Node&lt;K,V&gt; p = f.next; p != null; p = p.next) &#123; int b = p.hash &amp; n; if (b != runBit) &#123; runBit = b; lastRun = p; &#125; &#125; if (runBit == 0) &#123; ln = lastRun; hn = null; &#125; else &#123; hn = lastRun; ln = null; &#125; for (Node&lt;K,V&gt; p = f; p != lastRun; p = p.next) &#123; int ph = p.hash; K pk = p.key; V pv = p.val; if ((ph &amp; n) == 0) ln = new Node&lt;K,V&gt;(ph, pk, pv, ln); else hn = new Node&lt;K,V&gt;(ph, pk, pv, hn); &#125; // 其中的一个链表放在新数组的位置 i setTabAt(nextTab, i, ln); // 另一个链表放在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; else if (f instanceof TreeBin) &#123; // 红黑树的迁移 TreeBin&lt;K,V&gt; t = (TreeBin&lt;K,V&gt;)f; TreeNode&lt;K,V&gt; lo = null, loTail = null; TreeNode&lt;K,V&gt; hi = null, hiTail = null; int lc = 0, hc = 0; for (Node&lt;K,V&gt; e = t.first; e != null; e = e.next) &#123; int h = e.hash; TreeNode&lt;K,V&gt; p = new TreeNode&lt;K,V&gt; (h, e.key, e.val, null, null); if ((h &amp; n) == 0) &#123; if ((p.prev = loTail) == null) lo = p; else loTail.next = p; loTail = p; ++lc; &#125; else &#123; if ((p.prev = hiTail) == null) hi = p; else hiTail.next = p; hiTail = p; ++hc; &#125; &#125; // 如果一分为二后，节点数少于 8，那么将红黑树转换回链表 ln = (lc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(lo) : (hc != 0) ? new TreeBin&lt;K,V&gt;(lo) : t; hn = (hc &lt;= UNTREEIFY_THRESHOLD) ? untreeify(hi) : (lc != 0) ? new TreeBin&lt;K,V&gt;(hi) : t; // 将 ln 放置在新数组的位置 i setTabAt(nextTab, i, ln); // 将 hn 放置在新数组的位置 i+n setTabAt(nextTab, i + n, hn); // 将原数组该位置处设置为 fwd，代表该位置已经处理完毕， // 其他线程一旦看到该位置的 hash 值为 MOVED，就不会进行迁移了 setTabAt(tab, i, fwd); // advance 设置为 true，代表该位置已经迁移完毕 advance = true; &#125; &#125; &#125; &#125; &#125;&#125;]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>HashMap</tag>
        <tag>ConcurrentHashMap</tag>
        <tag>并发编程实践</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解final关键字的作用]]></title>
    <url>%2F2018%2F08%2F30%2Ffinal%2F</url>
    <content type="text"><![CDATA[final关键字特性final关键字在java中使用非常广泛，可以申明成员变量、方法、类、本地变量。一旦将引用声明为final，将无法再改变这个引用。final关键字还能保证内存同步，本博客将会从final关键字的特性到从java内存层面保证同步讲解。这个内容在面试中也有可能会出现。 final使用final变量final变量有成员变量或者是本地变量(方法内的局部变量)，在类成员中final经常和static一起使用，作为类常量使用。其中类常量必须在声明时初始化，final成员常量可以在构造函数初始化。 12345678public class Main &#123; public static final int i; //报错，必须初始化 因为常量在常量池中就存在了，调用时不需要类的初始化，所以必须在声明时初始化 public static final int j; Main() &#123; i = 2; j = 3; &#125;&#125; 就如上所说的，对于类常量，JVM会缓存在常量池中，在读取该变量时不会加载这个类。 12345678910public class Main &#123; public static final int i = 2; Main() &#123; System.out.println("调用构造函数"); // 该方法不会调用 &#125; public static void main(String[] args) &#123; System.out.println(Main.i); &#125;&#125; final方法final方法表示该方法不能被子类的方法重写，将方法声明为final，在编译的时候就已经静态绑定了，不需要在运行时动态绑定。final方法调用时使用的是invokespecial指令。 12345678910111213141516class PersonalLoan&#123; public final String getName()&#123; return"personal loan”; &#125;&#125; class CheapPersonalLoan extends PersonalLoan&#123; @Override public final String getName()&#123; return"cheap personal loan";//编译错误，无法被重载 &#125; public String test() &#123; return getName(); //可以调用，因为是public方法 &#125;&#125; final类final类不能被继承，final类中的方法默认也会是final类型的，java中的String类和Integer类都是final类型的。 1234final class PersonalLoan&#123;&#125; class CheapPersonalLoan extends PersonalLoan &#123; //编译错误，无法被继承 &#125; final关键字的知识点 final成员变量必须在声明的时候初始化或者在构造器中初始化，否则就会报编译错误。final变量一旦被初始化后不能再次赋值。 本地变量必须在声明时赋值。 因为没有初始化的过程 在匿名类中所有变量都必须是final变量。 final方法不能被重写, final类不能被继承 接口中声明的所有变量本身是final的。类似于匿名类 final和abstract这两个关键字是反相关的，final类就不可能是abstract的。 final方法在编译阶段绑定，称为静态绑定(static binding)。 将类、方法、变量声明为final能够提高性能，这样JVM就有机会进行估计，然后优化。 final方法的好处: 提高了性能，JVM在常量池中会缓存final变量 final变量在多线程中并发安全，无需额外的同步开销 final方法是静态编译的，提高了调用速度 final类创建的对象是只可读的，在多线程可以安全共享 从java内存模型中理解final关键字java内存模型对final域遵守如下两个重拍序规则 初次读一个包含final域的对象的引用和随后初次写这个final域，不能重拍序。 在构造函数内对final域写入，随后将构造函数的引用赋值给一个引用变量，操作不能重排序。 以上两个规则就限制了final域的初始化必须在构造函数内，不能重拍序到构造函数之外，普通变量可以。 具体的操作是 java内存模型在final域写入和构造函数返回之前，插入一个StoreStore内存屏障，静止处理器将final域重拍序到构造函数之外。 java内存模型在初次读final域的对象和读对象内final域之间插入一个LoadLoad内存屏障。 new一个对象至少有以下3个步骤 在堆中申请一块内存空间 对象进行初始化 将内存空间的引用赋值给一个引用变量，可以理解为调用invokespecial指令 普通成员变量在初始化时可以重排序为1-3-2，即被重拍序到构造函数之外去了。 final变量在初始化必须为1-2-3。 读写final域重拍序规则123456789101112131415161718192021public class FinalExample &#123; int i; final int j; static FinalExample obj; public void FinalExample () &#123; i = 1; // 1 j = 2; // 2 &#125; public static void writer () &#123; //写线程A obj = new FinalExample (); // 3 &#125; public static void reader () &#123; //读线程B执行 if(obj != null) &#123; //4 int a = object.i; //5 int b = object.j; //6 &#125; &#125;&#125; 我们可以用happens-before来分析可见性。结果是保证a读取到的值可能为0，或者1 而b读取的值一定为2。首先，由final的重拍序规则决定3HB2，但是3和1不存在HB关系，原因在上面说过了。 因为线程B在线程A之后执行，所以3HB4。那么2和4的HB关系怎么确定?? final的重拍序规则规定final的赋值必须在构造函数的return之前。所以2HB4。因为在一个线程内4HB6.所以可以得出结论2HB5。则b一定能得到j的最新值。而a就不一定了，因为没有HB关系，可以读到任意值。 HB判断可见性关系真是太方便了。可以参考我的另外一个博客http://medesqure.top/2018/08/25/happen-before/ 可能发生的执行时序如下所示。 final对象是引用类型如果final域是一个引用类型，比如引用的是一个int类型的数组。对于引用类型，写final域的重拍序规则增加了如下的约束 在构造函数内对一个final引用的对象的成员域的写入和随后在构造函数外将被构造对象的引用赋值给引用变量之间不能重拍序。 即先写int[]数组的内容，再将引用抛出去。 1234567891011121314151617181920212223public class FinalReferenceExample &#123; final int[] intArray; //final是引用类型 static FinalReferenceExample obj; public FinalReferenceExample () &#123; //构造函数 在构造函数中不能被重排序 final类型在声明或者在构造函数中要赋值。 intArray = new int[1]; //1 intArray[0] = 1; //2 &#125; public static void writerOne () &#123; //写线程A执行 obj = new FinalReferenceExample (); //3 &#125; public static void writerTwo () &#123; //写线程B执行 obj.intArray[0] = 2; //4 &#125; public static void reader () &#123; //读线程C执行 if (obj != null) &#123; //5 int temp1 = obj.intArray[0]; //6 &#125; &#125;&#125; JMM保证了3和2之间的有序性。同样可以使用HB原则去分析，这里就不分析了。执行顺序如下所示。 final引用不能从构造函数“逸出”JMM对final域的重拍序规则保证了能安全读取final域时已经在构造函数中被正确的初始化了。但是如果在构造函数内将被构造函数的引用为其他线程可见，那么久存在对象引用在构造函数中逸出，final的可见性就不能保证。 其实理解起来很简单，就是在其他线程的角度去观察另一个线程的指令其实是重拍序的。 123456789101112131415161718public class FinalReferenceEscapeExample &#123; final int i; static FinalReferenceEscapeExample obj; public FinalReferenceEscapeExample () &#123; i = 1; //1写final域 obj = this; //2 this引用在此“逸出” 因为obj不是final类型的，所以不用遵守可见性 &#125; public static void writer() &#123; new FinalReferenceEscapeExample (); &#125; public static void reader &#123; if (obj != null) &#123; //3 int temp = obj.i; //4 &#125; &#125;&#125; 操作1的和操作2可能被重拍序。在其他线程观察时就会访问到未被初始化的变量i，可能的执行顺序如图所示。 本文结束，欢迎阅读。本人博客 http://medesqure.top/ 欢迎观看]]></content>
      <categories>
        <category>java并发编程</category>
      </categories>
      <tags>
        <tag>内存可见性</tag>
        <tag>内存模型</tag>
        <tag>final关键字</tag>
        <tag>线程安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Happens-Before]]></title>
    <url>%2F2018%2F08%2F25%2Fhappen-before%2F</url>
    <content type="text"><![CDATA[happens-before简介在看JVM的内存模型时对内存可见性一直有个问题，线程A锁住，更新了对象内容A，释放锁，线程B锁住，为什么能获得对象A的最新值。还有双重检查生成单例时为什么需要把instance设置成violatile。问题的本质是线程同步的原子性，可见性，有序性的实现原理。我在看了http://ifeve.com/java-%E4%BD%BF%E7%94%A8-happen-before-%E8%A7%84%E5%88%99%E5%AE%9E%E7%8E%B0%E5%85%B1%E4%BA%AB%E5%8F%98%E9%87%8F%E7%9A%84%E5%90%8C%E6%AD%A5%E6%93%8D%E4%BD%9C/ 这个文章后有一种恍然大悟的感觉，终于搞明白了。 在深入理解JVM虚拟机文章中说过一句话，JMM(java内存模型)中的happens-before(hb规则)规则定义了java多线程操作的有序性和可见性，防止编译器重排序对结果的影响。 官方文档说: 一个变量被多个线程读取并且至少被一个线程写入时，如果读操作和写操作没有HB规则，那么将会产生数据竞争问题。为了保证操作B能看到操作A的结果(无论A和B是否在一个线程)，那么A和B之间必须满足HB规则，如果没有，将会导致重排序。 总结起来就是2点 如果满足HB规则，那么能保证可见性和有序性。比如线程加锁，同一个锁时，顺序为线程A-线程B，那么线程B一定能看到线程A的任何修改结果。缓存和主内存之间的关系会失效。 HB规则的实现原理具体我也不知道，好像是根据CPU总线事务来操作的。只要知道HB规则会使缓存失效。 缓存一致性和java内存模型(JMM java memory model) 在谈论java线程模型时必须要了解缓存一致性原则，这个是java内存模型的基础。java内存模型是一个概念模型，底层是寄存器、缓存内存、主内存、CPU之间的互相协作。 在多处理器的情况下，共享数据的交互硬件之间的关系如下:JMM 缓存一致性协议(MESI) 每个CPU都有属于自己的高速缓存，在需要同步的情况下，如果在缓存中更新了数据后，其他CPU读取该共享变量的缓存后就会出现缓存不一致的错误。这个时候就需要MESI协议来实现缓存一致性。可以采用LOCK#信号来对总线进行锁定，一个CPU在总线上输出该信号后，其他CPU的请求将会被阻塞，则该CPU可以独自共享内存，但是该方法的开销太大，之后的计算机一般采用缓存锁定的方式。MESI代表缓存数据的4种状态的名字，分别为Modified, Exclusive, Shared, Invalid Modified被修改的缓存。该缓存在本CPU中有缓存数据,其他CPU中没有，对其他缓存中的值是已经被修改过的，但是没有更新到内存中。 Exclusive独占的。处于该状态的缓存，在本CPU中有缓存，并且数据没有修改，在内存中一致。 Shared共享的。处于这个状态的数据在多个CPU中都有缓存，且和内存一致。-Invalid失效的数据。缓存的数据已经失效，或者不在缓存中。 嗅探技术：嗅探能够嗅探到其他处理器访问主内存和它们的内存缓存 缓存行在以上的4种状态的基础上，通过“嗅探”的技术完成以下功能 一个处于M状态的缓存行，必须时刻监听所有试图读取该缓存行对应的主内存地址的值，如果监听到，则必须在此操作执行前将缓存行写回CPU中。 处于S状态的缓存行，必须监听使该缓存行无效或者独占该缓存行的请求，监听到后将该缓存行设置为I 处于E状态，必须监听其他试图读取该缓存行的主内存地址的操作，监听到，将该缓存行的状态设置为S 只有E和M状态可以进行写操作并且不需要额外操作，想要对S状态的缓存字段写操作，先发送一个RFO广播，该广播可以让其他CPU缓存中的相同的字段的状态变成I 通过以上的机制可以保证处理器的读写操作是原子性的，并且读到的数据都是最新的，即内存可见性。 总结以上的EMSI协议，其实就是能通过使缓存失效和读取变量强制从主内存中读取的方式来保证了内存的可见性。类似的，java中的锁和violatile也是这样的原理. java并发编程中的几个原则 在使用synchorized和RenntrantLock时，我们只关注了它们的原子性，其实它们的可见性和有序性更加的重要。可见性保证了同步的两个线程读取的变量的是最新值。有序性保证了线程的先后顺序。原子性就是你们所理解的那样子。 原子性Java主要提供了锁机制以及CAS操作实现原子性，对于单个读/写操作是通过LOCK#信号或“缓存锁定”实现的。 除此之外，long和double类型的变量读/写是非原子性的，每次都只读/写32位数据，所以一个单个的读/写操作就变成了两个读/写操作，有可能在只读/写了其中32位操作后CPU就被其他线程抢占到。 可见性每个线程都有私有的缓存。java中提供了violatile保证了内存的可见性，底层通过了Lock#或者缓存锁定实现。 有序性编译器和处理器会对代码进行排序，排序包括了 1. 语句的执行顺序重排序。 2.指令集并行的重排序，多个CPU协同读取 3.内存系统的重排序 缓存和内存的数据同步存在时间差。 内存屏障 内存屏障是一个CPU指令，java编译器会在生成指令的适当位置插入内存屏障指令来禁止特定类型的处理器重排序，作用有2个: 保证了特定操作的执行顺序 保证了某些变量的内存可见性如果在指令间插入了Memory Barrier，则会告诉编译器和CPU，不管什么指令都不能和这条指令重排序，即插入了内存屏障后禁止在内存屏障前后的指令执行重拍序。Memory Barrier强制刷出各种CPU缓存数据，任何CPU的线程都能读取这些数据的最新值。JMM内存屏障可以保证了load和store之间的有序性和可见性。 HB规则 程序次序原则: 在一个线程内，代码按照顺序执行 管程锁定规则: 在同一个monitor上，unlock操作时间上先行发生于后面的lock操作 volatile变量规则: 对一个volatile变量的写操作先于读操作 线程启动原则: Thread的start()先于该线程的任何操作 线程终止原则: Thread的所有操作都先于线程的终止检测。可以通过Thread.join()和Thread.isAlive()的返回值检测线程是否已终止 线程终端规则: 线程的interrupt()方法先于中断线程检测到中断事件的发生，即可以使用interrupted()方法检测到线程是否被中断了。 对象终结原则: 对象构造函数执行完毕先于finilized()方法 传递性: A先于B，B先于C。可以推断出A先于C 只要满足如上的8条规则，都能保证后面操作的读线程能读取到前面写线程的最新值，即保证了可见性。其中对传递性的规则是最重要的，如果A HB B， B HB C，那么A的操作共享变量的结果对C都是可见的。实现可见性的原理是通过缓存一致性协议(MESI)和内存屏障(Memory Barrrier)。 同步的实现解析Happens-Before的排序规则十分的强大，一般是使用happens-Before和监视器锁或者volatile变量的规则结合来保证对某个未被锁保护变量的访问。 如下代码是线程同步的简单列子，没有使用锁，仅仅通过volatile变量就保证了线程同步。相比于锁。没有线程的阻塞，极大的提升了效率。 12345678910111213141516171819202122232425262728293031323334353637383940414243public class HappenBeforeTest&#123; static int num = 0; static volatile boolean flag = false; class task1 implements Runnable &#123; @Override public void run() &#123; while (num &lt; 100) &#123; if (!flag &amp;&amp; (num == 0 || ++num % 2 == 0)) &#123; System.out.println(num); flag = true; &#125; &#125; &#125; &#125; class task2 implements Runnable &#123; @Override public void run() &#123; while (num &lt; 100) &#123; if (flag &amp;&amp; (++num % 2 != 0)) &#123; System.out.println(num); flag = false; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Thread thread1 = new Thread(new HappenBeforeTest().new task1()); Thread thread2 = new Thread(new HappenBeforeTest().new task2()); thread1.start(); thread2.start(); &#125;&#125; 以上的代码会按照循序打印出0~100的数字，但是num变量并不是volatile，并且num++也不能保证原子性，会有可见性问题。问题是为什么t1更新了num，t2能感知到。 其实以上代码执行的顺序如下可以使用Happens-Before来完成可见性分析。 t1 num++，然后修改了volatile变量 则1 HB 2 t2 读取了修改后的volatile变量 则2 HB 3 t2 读取num的变量，并执行了num++ 则3 HB 4 根据传递性原则，可以推断到1 HB 4 根据以上的分析，可以得到t2 对 t1的操作结果具有可见性，不用锁也能得到正确的线程执行顺序。即使num没有进行加锁访问。 3个线程按顺序打印3个线程按照循序打印ABC各3次还可以使用一下的方法，只是利用了volatile的可见性和HB规则。但是使用while去一直循环查询感觉效率并没有wait-notify高。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class HappenBeforeTest&#123; static int num = 0; static volatile int flag = 0; class task1 implements Runnable &#123; @Override public void run() &#123; while (num &lt; 9) &#123; if (flag == 0) &#123; System.out.println("A"); num++; flag = 1; &#125; &#125; &#125; &#125; class task2 implements Runnable &#123; @Override public void run() &#123; while (num &lt; 9) &#123; if (flag == 1) &#123; System.out.println("B"); num++; flag = 2; &#125; &#125; &#125; &#125; class task3 implements Runnable &#123; @Override public void run() &#123; while (num &lt; 9) &#123; if (flag == 2) &#123; System.out.println("C"); num++; flag = 0; &#125; &#125; &#125; &#125; public static void main(String[] args) &#123; Thread thread1 = new Thread(new HappenBeforeTest().new task1()); Thread thread2 = new Thread(new HappenBeforeTest().new task2()); Thread thread3 = new Thread(new HappenBeforeTest().new task3()); thread1.start(); thread2.start(); thread3.start(); &#125;&#125; 其他规则实现同步以下的代码也能保证a的正确访问，因为JMM已经保证了访问的先后顺序和可见性。 12345678910111213141516171819202122232425262728293031323334//Thread的join()方法保证了可见性static int a = 1; public static void main(String[] args)&#123; Thread tb = new Thread(() -&gt; &#123; a = 2; &#125;); Thread ta = new Thread(() -&gt; &#123; try &#123; tb.join(); &#125; catch (InterruptedException e) &#123; //NO &#125; System.out.println(a); &#125;); ta.start(); tb.start(); &#125; //Thread的start()方法保证可见性 static int a = 1; public static void main(String[] args)&#123; Thread tb = new Thread(() -&gt; &#123; System.out.println(a); &#125;); Thread ta = new Thread(() -&gt; &#123; tb.start(); a = 2; &#125;); ta.start(); &#125; volatile双重检查实现单例原理上面说过了volatile的作用一共有2个。 可见性volatile变量写完会立即同步到主内存，并且使其他缓存失效，只能从主内存中读取，这个是由内存一致性协议(MESI)决定。见 缓存一致性协议 防止指令重拍序volatile变量会在代码编译时插入LOCK#指令，该操作相当于一个内存屏障，内存屏障能保证重拍序无法将后面的指令重拍序到内存屏障之前。 双重检查锁(DCL)这个DCL之前在分析java内存模型时已经说过，还是会存在对象没有构造完全的风险。 12345678910111213141516171819202122232425public class Singleton &#123; private static Singleton instance = null; private int age; public static Singleton getInstance() &#123; if(instance == null) &#123; //1 synchonorized(Singleton.class) &#123; //2 if(instance == null) &#123; //3 instance = new Singleton(); //4 &#125; &#125; &#125; return instance; //5 &#125; public Singleton() &#123; this.age = 18; &#125; public int getAge() &#123; //6 return age; &#125;&#125; 对于步骤4，看上去只有instance = new Singleton()一个操作，但是其实至少有3个步骤 在堆中开辟一块新的内存(new) 调用对象的构造函数对内存进行初始化(invokespecial) 将内存的引用赋值给变量(astore) 但是存在指令重拍序时，很可能发生了如下的执行顺序，1-3-2。这个没有疑问。重点来了，我们来好好分析一下可能出现的对象构造不完全的情况。 线程A执行到4，执行new的顺序恰好是1-3-2 当其执行完3时，这个时候该线程的CPU时间被剥夺分配给线程B，而B恰好执行了步骤1. 因为1不是同步操作，所以线程B判断if(instance == null)返回false，因为这个时候这个引用已经被分配值了。所以直接返回了一个instance。 不管B是不是会去访问age变量，但是一个没有被构造完全的对象被引用了，就存在了风险。 画个图吧，这个我觉得已经讲的非常明白了 不过这个概率发生的概率大概和买彩票中500w差不多了吧。咳咳但是使用了volatile之后，instance = new Singleton()的执行顺序一定会是1-2-3，从Happens-Before的规则出发，instance对象的初始化一定会被线程B观察到，所以才会是正确的构造结果。不会导致未被完全构造完成的对象发布出去。 总结这个文章写得有点多了，最后总结一下吧。使用HB规则能简单的推导出上一个操作对下一个操作的可见性。这个特性在使用ReentrantLock也被使用到了。所以其也可以实现线程同步的原子性，可见性，有序性。其在内部使用了volatile的state状态来定义状态，每次操作共享变量时会先读取state变量，这个就和同步的实现解析一样了。因为CAS只是保证了赋值的原子性。其实并发容器中大部分都是用了这个HB来保证可见性，CountDownlatch,Semaphore，Future等等。 最后，啰嗦一句，使用HB规则去判断可见性，是java内存模型的精髓。个人博客]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>线程同步</tag>
        <tag>内存可见性</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[AQS原理]]></title>
    <url>%2F2018%2F08%2F25%2FAQS%2F</url>
    <content type="text"><![CDATA[AQS的原理解析简介java中实现线程同步有synchronized和ReentrantLock方法，当然还有其他的方法。synchronized是使用monitorenter和monitorexit指令来同步代码块。而ReentrantLock是底层依赖AQS(AbstractQueuedSynchronizer)组件来实现的，即非阻塞同步队列。AQS相比于monitor可以实现多种同步方式，比如独占锁，共享锁，条件队列，公平锁等模式。在并发效率上，synchronized有自旋锁，偏向锁，轻量级锁，重量级锁的优化后，效率和ReentrantLock是差不多的。但是在同步的模式上只能是独占锁。AQS使用CAS机制和用volatile的state值来记录获取锁，竞争锁，释放锁的操作。AQS不关心如何挂起线程，AQS是判断资源是否能被访问，当线程不能被访问时对线程加入队列，挂起和唤醒等操作。 可以思考如下的问题 线程如何访问AQS维护的资源 当资源不可访问时，当前的线程如何挂起 当线程提前被中断或者其他原因退出访问资源，如何从AQS队列中退出 我们在使用时，AQS主要的功能有独占锁和共享锁。在实现了AQS的子类中，一般只会使用其中的一种。比如ReentrantLock实现了独占锁，CountDownLatch和Semphere实现了共享锁。 AQS的数据结构AQS维护了一个volatile int state(共享资源)和一个FIFO非阻塞等待队列来实现的。 node节点node节点的代码如下所示， 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051static final class Node &#123; // 共享锁模式 static final Node SHARED = new Node(); // 独占锁模式 static final Node EXCLUSIVE = null; static final int CANCELLED = 1; static final int SIGNAL = -1; static final int CONDITION = -2; static final int PROPAGATE = -3; /** * CANCELLED，值为1，表示当前的线程被取消 * SIGNAL，值为-1，表示当前节点的后继节点包含的线程需要运行，也就是unpark； * CONDITION，值为-2，表示当前节点在等待condition，也就是在condition队列中； * PROPAGATE，值为-3，表示当前场景下后续的acquireShared能够得以执行； * 值为0，表示当前节点在sync队列中，等待着获取锁。 */ // 线程的等待状态 volatile int waitStatus; //前驱节点 volatile Node prev; //后继节点 volatile Node next; //该节点的线程 volatile Thread thread; // 存储condition队列中的后继节点 Node nextWaiter; //是否是共享模式 final boolean isShared() &#123; return nextWaiter == SHARED; &#125; // 获取前驱节点 final Node predecessor() throws NullPointerException &#123; Node p = prev; if (p == null) throw new NullPointerException(); else return p; &#125; Node() &#123; &#125; // Used by addWaiter Node(Thread thread, Node mode) &#123; this.nextWaiter = mode; this.thread = thread; &#125; // Used by Condition Node(Thread thread, int waitStatus) &#123; this.waitStatus = waitStatus; this.thread = thread; &#125; &#125; 在node类中有prev和next，看出AQS的同步队列是双向队列。有thread来指向当前线程，nextWaiter 如果当前的节点时共享模式，值指向一个SHARE节点。当前节点是条件队列中，值会指向下一个等待条件的节点。waitstatus表示当前节点的状态，值如下所示。 -1 SIGNAL 当前节点的后继节点被阻塞，当前节点被释放后要唤醒后继节点 1 CANCELLED 当前节点超时或者中断被取消，唯一大于0的值 -2 CONDITION 当前节点处于条件队列中，条件没达成不能获取锁 -3 PROPAGATE 当前节点处于传播模式，共享锁模式使用该值 0 无 节点初始状态，head初始化条件队列时使用 在独占锁模式下的同步队列结构如下：head节点存储的是new出来的节点，它的waitStatus的值为0，tail指向队列的最后一个节点。 共享锁的同步队列如下：共享锁和独占锁时使用同一个同步队列，队列中的节点可以是共享类型也可以是独占类型。除了以上的同步队列，还有一个条件队列入地下所示。使用的也是Node节点，是一个单向队列，用nextWaiter来指向下一个节点。 CAS操作AQS中有3个重要的变量,head、tail、state都是volatile类型的，保证了可见性。 12345678910111213141516// 队头结点 private transient volatile Node head; // 队尾结点 private transient volatile Node tail; // 代表共享资源 private volatile int state; protected final int getState() &#123; return state; &#125; protected final void setState(int newState) &#123; state = newState; &#125; //CAS操作，当stateoffset的内存的值state和expect相等时将内存的值设为updateprotected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this,stateOffset, expect, update); &#125; 源码解读AQS定义了两种的资源共享方式 Exclusive 独占锁模式，只有一个线程能执行，ReentrantLock Share 共享锁模式 多个线程可以同时执行，CountDownLatch/Semaphore AQS独占锁模式一般情况下，ReentrantLock的释放方式为 123reentrantLock.lock();//do somethingreentrantlock.unlock(); ReentrantLock保证了在同一时刻只有一个线程能获取到锁，其余的线程都要挂起等待，直到拥有锁的线程释放了锁，被挂起的线程被唤醒重新竞争锁。ReentrantLock的加锁都是由AQS完成的，它只是初始化了AQS的state资源的数量和获取资源。ReentrantLock分为公平锁和非公平锁。 获取独占锁获取独占锁的流程如下所示结合ReentrantLock的源码分析ReentrantLock 的构造函数中是初始化sync = new NonfairSync()，其中NonfairSync继承Sync，Sync继承了AQS 123public ReentrantLock() &#123; sync = new NonfairSync(); //构造一个syn&#125; ReentrantLock.lock得到获取锁的入口函数，调用sync.lock() 123public void lock() &#123; sync.lock();&#125; 公平锁和非公平锁将lock方法重写了，根据不同的sync调用不同的lock 12345678910111213//非公平锁final void lock() &#123; //用CAS修改state，如果state为0 设置为1 表示当前线程获取锁 if (compareAndSetState(0, 1)) setExclusiveOwnerThread(Thread.currentThread()); //当前线程设置为独占锁 else acquire(1); //尝试获取锁&#125;t//公平锁final void lock() &#123; acquire(1);&#125; 如果state为0，说明没有线程获取锁，可以设置当前线程获取独占锁，当前线程不加入队列，如果state为1，表示有线程占用资源，需要调用acquire()去获取锁 123abstract static class Sync extends AbstractQueuedSynchronizer &#123;&#125;static final class NonfairSync extends Sync &#123;&#125;static final class FairSync extends Sync &#123;&#125; 公平锁 每个线程强占锁的顺序是先后调用lock方法的顺序，并依次获取锁。 非公平锁 每个线程强占锁的顺序不变，和调用lock方法的先后顺序无关。公平还是非公平是在获取锁的时候是直接获取锁还是先去队列中排队。 acquire()方法12345678public final void acquire(int arg) &#123; //tryAcquire子类重写，不同的获取资源逻辑 //addWaiter是将节点加入到队列的tail //acquireQueued是不断循环，中断线程 if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)) selfInterrupt();&#125; tryAcquire()方法tryAcquire()方法AQS并没有实现，具体的实现方法留给子类去实现了。从方法里可以看到当state为0表示没有线程占用锁，当state &gt; 0 表示了线程占用，并且记录了重复进入的次数。state的更新采用CAS技术。同时，公平锁和非公平锁的实现也体现出来了。非公平锁是唤醒的线程均去尝试设置state。而非公平锁会只有同步队列的head节点的next节点才能去设置state。说明公平锁是按照FIFO队列中的顺序获取锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758//如果是非公平锁，调用nonfairAcquire()final boolean nonfairTryAcquire(int acquires) &#123; //得到当前的线程 final Thread current = Thread.currentThread(); //得到lock的state状态 int c = getState(); //没有线程占用锁 if (c == 0) &#123; //当前线程直接去抢占锁 if (compareAndSetState(0, acquires)) &#123; //当前线程获取锁，设置为独占锁 setExclusiveOwnerThread(current); return true; &#125; &#125; //当前线程再次获取锁，锁可以重入 则state加1 else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) // overflow throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125;//如果是公平锁，调用protected final boolean tryAcquire(int acquires) &#123; final Thread current = Thread.currentThread(); int c = getState(); if (c == 0) &#123; //当前线程要排序再获取锁。当前线程是head节点的next节点并且当前节点设置state为1 则获取锁成功 if (!hasQueuedPredecessors() &amp;&amp; compareAndSetState(0, acquires)) &#123; setExclusiveOwnerThread(current); return true; &#125; &#125; else if (current == getExclusiveOwnerThread()) &#123; int nextc = c + acquires; if (nextc &lt; 0) throw new Error("Maximum lock count exceeded"); setState(nextc); return true; &#125; return false;&#125;// 判断当前的线程是不是head的下一个节点 按顺序唤醒public final boolean hasQueuedPredecessors() &#123; Node t = tail; Node h = head; Node s; //head的节点是一个哨兵节点 不保存节点信息 //s=head.next节点并且s的线程不是当前线程 也就是说head节点的next节点不是当前节点 return h != t &amp;&amp; ((s = h.next) == null || s.thread != Thread.currentThread()); &#125; 入队列操作 acquireQueued(addWaiter(Node.EXCLUSIVE))当tryAcquire()方法返回false，表示锁被线程占用并且不是当前线程，无法重入。需要将当前线程入队列并且将线程挂起。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697//这个方法是将当前的线程加入到阻塞队列中//每次都先尝试快速入队，如果失败了 再调用enq自旋入队private Node addWaiter(Node mode) &#123; Node node = new Node(Thread.currentThread(), mode); // Try the fast path of enq; backup to full enq on failure //尝试快速入队，没有竞争条件肯定成功，如果失败进入enq自旋重复入队 Node pred = tail; if (pred != null) &#123; node.prev = pred; if (compareAndSetTail(pred, node)) &#123; //如果pred和tail的元素一样，则说明没有其他线程改变tail 可以插入 pred.next = node; return node; //插入成功，直接返回 &#125; &#125; enq(node); //自旋入队 return node;&#125;//自旋入队private Node enq(final Node node) &#123; for (;;) &#123; Node t = tail; if (t == null) &#123; // Must initialize if (compareAndSetHead(new Node())) //队列中没有元素，new一个Node作为哨兵节点 即head=new Node() tail = head tail = head; &#125; else &#123; node.prev = t; //node指向tail if (compareAndSetTail(t, node)) &#123; //当t没有被修改，CAS修改tail t.next = node; return t; //返回tail节点 &#125; &#125; &#125;&#125;//acquiredQueued主要是将线程挂起，等待唤醒 每次唤醒都是唤醒head节点的下一个节点 head节点为获得锁的节点//如果当前节点是head节点的下一个节点，并且成功获得锁就唤醒，然后将head节点也就是释放锁的节点移除队列，next节点变成head节点，准备下一次唤醒next节点final boolean acquireQueued(final Node node, int arg) &#123; boolean failed = true; try &#123; boolean interrupted = false; for (;;) &#123; //一直循环 //获取当前节点的前驱结点 final Node p = node.predecessor(); //问题：为什么是前驱节点而不是当前节点？因为我们队列在初始化时候生成了个虚拟头节点，相当于多出来了个节点。 if (p == head &amp;&amp; tryAcquire(arg)) &#123; //前驱结点为head节点并且尝试获取锁成功，则将当前节点设置为头节点并且放回 //head节点的线程为获取到锁的线程，head节点的next节点为阻塞等待的线程 setHead(node); p.next = null; // help GC failed = false; return interrupted; &#125; //判断当前线程是不是应该挂起 如果应该挂起则挂起，等待release唤醒释放 //如果不挂起，那么线程在for循环里面一直抢占cpu //当阻塞后被唤醒了就继续循环 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) interrupted = true; &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;//使用park方法方法将线程挂起 同时唤醒和中断都可以导致线程醒来，判断线程的中断标志位private final boolean parkAndCheckInterrupt() &#123; //调用这个方法阻塞线程，最终调用Unsafe.park(false, 0L)这个是native方法 LockSupport.park(this); //检查线程的中断状态 return Thread.interrupted(); &#125;//判断当前节点是不是应该挂起 因为每次都是由node节点的pre节点来判断是不是要挂起 //当pre节点被取消了，就将该节点移出阻塞队列private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) //唤醒下一个节点 return true; if (ws &gt; 0) &#123; //pre节点被取消了 do &#123; node.prev = pred = pred.prev; //node节点指向pre节点的pre节点，相当于把取消的节点从队列中移除 &#125; while (pred.waitStatus &gt; 0); //将所有的waitstatus的节点都从队列中去除 pred.next = node; &#125; else &#123; /* * waitStatus must be 0 or PROPAGATE. Indicate that we * need a signal, but don't park yet. Caller will need to * retry to make sure it cannot acquire before parking. */ compareAndSetWaitStatus(pred, ws, Node.SIGNAL); //将pre节点设置为signal &#125; //将取消的节点剔除出队列后返回false，重新for循环 return false;&#125; 公平锁和非公平锁的唯一区别是在lock时的处理逻辑不同。 公平锁是在lock时先把当前线程入到FIFO队列中，再去按照顺序获取锁。 非公平锁是在lock时可以不管FIFO队列中是否有等待线程，先去阐释获取一次锁，即CAS操作state，失败了才入FIFO队列，否则直接获得锁。 释放独占锁流程ReentrantLock调用unlock()方法释放独占锁， 123public void unlock() &#123; sync.release(1);&#125; 具体的流程如下所示。 release()释放锁调用release()方法，内部调用了被子类重写的tryRelease()方法来释放资源。假如资源state释放完毕为0，则当前线程不再占用锁，找到AQS的头结点(head结点为当前的活动线程，要释放head结点的next节点)，调用unparkSuccessor()方法释放FIFO队列中第一个等待锁的节点。 1234567891011public final boolean release(int arg) &#123; if (tryRelease(arg)) &#123; //成功将state减去了，就要从的等待队列中唤醒一个线程。 //如果是同一个线程，则将锁的计数器state-1，返回false，表示锁还没有释放 Node h = head; //从队列里面唤醒一个线程 if (h != null &amp;&amp; h.waitStatus != 0) //waitstatus为-1，要唤醒下一个节点 unparkSuccessor(h); return true; &#125; return false;&#125; tryRelease()方法具体由子类重写的该方法来释放state资源。 state - release 如果state还是大于0，说明线程被重入了，则还要占有线程。当tryRelease方法返回true时，说明当前线程已经不占用锁，需要唤醒一个线程来强占锁。具体逻辑为找到head节点的next节点唤醒。 1234567891011121314protected final boolean tryRelease(int releases) &#123; //计数 int c = getState() - releases; if (Thread.currentThread() != getExclusiveOwnerThread()) throw new IllegalMonitorStateException(); boolean free = false; if (c == 0) &#123; free = true; //释放锁，lock没有线程占用 setExclusiveOwnerThread(null); &#125; setState(c); return free;&#125; unparkSuccessor(Node node)唤醒下一个节点只有node节点的waitStatus为负数(1为cancel),才能唤醒下一个节点。如果next节点被取消了，那么就要从tail节点开始查找，找到FIFO队列中最早没有被取消的节点，唤醒该节点。 1234567891011121314151617181920private void unparkSuccessor(Node node) &#123; int ws = node.waitStatus; if (ws &lt; 0) //如果状态为负(Signal, Propagate)，那么清除状态为0 //如果失败，或者状态被其他线程改变也没有关系 compareAndSetWaitStatus(node, ws, 0); //唤醒的节点是head节点的next节点。如果该节点被取消了， //那么就从后往前遍历找到最早没有被取消的节点 Node s = node.next; if (s == null || s.waitStatus &gt; 0) &#123; s = null; for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; &#125; if (s != null) //唤醒队列中的一个线程 LockSupport.unpark(s.thread); &#125; 当调用了LockSupport.unpark(s.thread)方法后，s线程将会被唤醒，重新回到LockSupport.park(this);方法，继续执行。其中shouldParkAfterFailedAcquire()方法会从队列中剔除pre节点被取消的节点。只有head节点的next节点才能得到锁资源，并被设置成新的head节点。head节点表示当前正在获取锁资源的节点。 1234567891011121314151617181920212223private final boolean parkAndCheckInterrupt() &#123; //调用这个方法阻塞线程，最终调用Unsafe.park(false, 0L)这个是native方法 LockSupport.park(this); //检查线程的中断状态 return Thread.interrupted(); &#125;private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) &#123; int ws = pred.waitStatus; if (ws == Node.SIGNAL) //唤醒下一个节点 return true; if (ws &gt; 0) &#123; //pre节点被取消了 do &#123; node.prev = pred = pred.prev; //node节点指向pre节点的pre节点，相当于把取消的节点从队列中移除 &#125; while (pred.waitStatus &gt; 0); //将所有的waitstatus的节点都从队列中去除 pred.next = node; &#125; else &#123; compareAndSetWaitStatus(pred, ws, Node.SIGNAL); //将pre节点设置为signal &#125; //将取消的节点剔除出队列后返回false，重新for循环 return false;&#125; AQS共享锁模式共享锁的实现方式为CountDownLatch闭锁方式，使一个或者多个线程等待时间的发生。闭锁在new时初始化了state的计数器为一个正值，表示当前正在的事件数量。COuntDown()方法表示一个事件发生了，计数器的值减1.await等待计数器的值为0，表示等待的事件已经发生。如果state不为0，则await会阻塞计数器为0，或者等待线程中断或者等待超时。 await等待获取共享锁流程123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; countdownlatch等待获取共享锁的流程如下所示。client调用await()方法，当state不等于0，则线程会被封装成Node加到FIFO等待队列并挂起线程等待被唤醒。 acquireSharedInterruptibly(arg)方法1234567891011121314public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; //响应线程的中断，检查线程是否被中断 if (Thread.interrupted()) throw new InterruptedException(); //返回-1，说明state不为0 也就是CownDownLatch的计数器不为0 if (tryAcquireShared(arg) &lt; 0) //获取共享锁，小于0 表示获取失败 doAcquireSharedInterruptibly(arg);&#125;//CountDownLatch的计数器是否为0 tryAcquire只是判断当前的线程能否获取锁protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; doAcquireSharedInterruptibly(arg)该方法是将thread包装成Node，加入到FIFO队列中 12345678910111213141516171819202122232425262728293031323334353637383940414243444546private void doAcquireSharedInterruptibly(int arg) throws InterruptedException &#123; //将当前节点包装成共享节点 //将node加入到FIFO队列中 final Node node = addWaiter(Node.SHARED); boolean failed = true; try &#123; for (;;) &#123; //一直判断node节点的状态 final Node p = node.predecessor(); if (p == head) &#123; //如果当前节点是head节点的next节点，说明当前节点是AQS队列中获取锁的第一个节点 //按照FIFO原则，可以直接尝试获取锁 int r = tryAcquireShared(arg); if (r &gt;= 0) &#123; //如果当前node获取锁成功，就要将当前节点设为AQS第一个节点 //AQS队列的第一个节点表示当前已经获取锁的节点 setHeadAndPropagate(node, r); p.next = null; // help GC failed = false; return; &#125; &#125; //如果当前节点没有获取到锁，就要检查需要把当前节点挂起 if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); &#125; &#125; finally &#123; if (failed) cancelAcquire(node); &#125;&#125;//将头节点设置成传播属性private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); //每一个成为头节点都要释放下一个节点 &#125;&#125; 释放共享锁的流程AQS调用countDown()方法会state减1，当state减为0时，会释放FIFO队列中的所有线程，即共享锁。 releaseShared()方法tryReleaseShared()后如果state=0，则countDownLatch中的所有子线程都执行完毕，要唤醒await的线程，这些线程都在AQS中被挂起。下一步是唤醒AQS的头节点，然后由头节点依次唤醒下一个节点。 123456789101112131415161718192021public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; //如果state =0 就唤醒FIFO的队列的线程 doReleaseShared(); return true; &#125; return false;&#125;//如果state为0 表示当前线程释放锁，唤醒队列中线程protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (; ; ) &#123; int c = getState(); if (c == 0) return false; int nextc = c - 1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; AQS的doReleaseShared()方法 唤醒head节点的next节点1234567891011121314151617181920212223private void doReleaseShared() &#123; for (; ; ) &#123; Node h = head; if (h != null &amp;&amp; h != tail) &#123; int ws = h.waitStatus; if (ws == Node.SIGNAL) &#123; //如果当前节点是SIGNAL意味着，它正在等待一个信号。 //或者说，它在等待被唤醒，因此做两件事 /*重置waitStatus标志位，如果失败则重试*/ if (!compareAndSetWaitStatus(h, Node.SIGNAL, 0)) continue; // loop to recheck cases /*重置成功后,唤醒等待获取共享锁的第一个节点*/ unparkSuccessor(h); &#125; else if (ws == 0 &amp;&amp; !compareAndSetWaitStatus(h, 0, Node.PROPAGATE)) //如果本身头节点的waitStatus是处于重置状态（waitStatus==0）的，将其设置为“传播”状态。 //意味着需要将状态向后一个节点传播。 continue; // loop on failed CAS &#125; if (h == head) // loop if head changed break; &#125;&#125; 当调用unparkSuccessor()方法唤醒AQS队列的第一个节点时，被唤醒的线程会继续执行doAcquireSharedInterruptibly()方法，如果当前的节点是head节点的next节点，就把该节点设置成新的head节点，然后移除老的head节点。再接着调用doReleaseShared()方法依次唤醒下一个节点。 每一个设置成新的head节点都要调用doReleaseShared()方法区唤醒head节点的next节点。从而实现了共享对象的传播。1234567891011private void setHeadAndPropagate(Node node, int propagate) &#123; Node h = head; // Record old head for check below setHead(node); if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 || (h = head) == null || h.waitStatus &lt; 0) &#123; Node s = node.next; if (s == null || s.isShared()) doReleaseShared(); &#125;&#125; 可中断的锁的实现方式在上面的独占锁和共享锁中，调用lock()方法均是不可中断的。在调用void lock()方法区获取锁时，如果锁被占用，线程将会阻塞，调用线程的interrupt()方法也不能取消锁。当想要等待超时或者中断退出的锁实现时，需要使用lockInterruptibly()方法。LockSupport.park()方法可以响应中断，但是不会抛出InterruptedException的异常。 AQS的acquireInterruptibly方法如果线程被中断了，会抛出InterruptedException()异常。 1234567public final void acquireInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (!tryAcquire(arg)) doAcquireInterruptibly(arg); // @1&#125; doAcquireInterruptibly()方法从这段代码就看出来了lock从中断退出的。当线程被中断了，读取Thread.Interruped()方法为true，表示线程被中断了，就抛出异常，从for循环中退出。在最外面捕获异常后调用cancelAcquire(node)方法将节点取消。 12345678910111213141516171819202122private void doAcquireInterruptibly(int arg) throws InterruptedException &#123; final Node node = addWaiter(Node.EXCLUSIVE); // @1 boolean failed = true; try &#123; for (;;) &#123; final Node p = node.predecessor(); if (p == head &amp;&amp; tryAcquire(arg)) &#123; // @2 setHead(node); p.next = null; // help GC failed = false; return; &#125; if (shouldParkAfterFailedAcquire(p, node) &amp;&amp; parkAndCheckInterrupt()) throw new InterruptedException(); //@3 &#125; &#125; finally &#123; if (failed) cancelAcquire(node); //@4 &#125;&#125; cancelAcquire()方法取消节点的步骤如下 从node出发找到一个未被取消的prev节点，并移除中间的取消节点。 如果node是tail节点，就调用CAS将prev设置为tail节点。如果CAS失败，表示有其他线程设置了tail节点，结束 如果node节点不是tail节点，那么就要将node从队列中移除。prev.next = node.next是否能操作的逻辑是prev不是head节点，prev.waitStatus是Signal或者设置waitStatus的类型为signal成功并且node.next节点是非取消的，则可以将node节点移除。 如果prev为head节点，那么执行一次唤醒操作。 123456789101112131415161718192021222324252627282930private void cancelAcquire(Node node) &#123; if (node == null) return; node.thread = null; Node pred = node.prev; while (pred.waitStatus &gt; 0) // @1 node.prev = pred = pred.prev; Node predNext = pred.next; //@2 node.waitStatus = Node.CANCELLED; if (node == tail &amp;&amp; compareAndSetTail(node, pred)) &#123; // @3 compareAndSetNext(pred, predNext, null); &#125; else &#123; // @4 int ws; if (pred != head &amp;&amp; ((ws = pred.waitStatus) == Node.SIGNAL || (ws &lt;= 0 &amp;&amp; compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &amp;&amp; pred.thread != null) &#123; // @5 Node next = node.next; if (next != null &amp;&amp; next.waitStatus &lt;= 0) compareAndSetNext(pred, predNext, next); &#125; else &#123; // @6 unparkSuccessor(node); &#125; node.next = node; // help GC &#125; &#125; 不同的子类对AQS的state的维护 ReentrantLock: 独占锁 如果state为0 说明锁是空闲的，调用tryAcquire()设置state=1，当前线程获取锁 如果state大于1，则表示当前线程获得了重入的效果，其他线程只能被park，直到这个线程进入锁的次数为0而释放原子状态 Semaphare 共享锁 state记录了当前还有多少次许可证可以使用。当state小于0，则线程被阻塞。否则线程可以执行。维护了同时可以并发的线程数量 CountDownLatch 共享锁 闭锁是state来维护一个状态，在这个状态到达一个状态之前，所有的线程都会被park，当state=0时，则所有被park的线程都会被唤醒。 FutureTask 独占锁 用state来表示执行任务的线程的执行状态。当调用get()方法会获取state的值，当大于0(RUNNING)时，表示线程还在执行。，AQS就会park掉get()方法的线程。在跑任务的线程结束后会回调一个方法设置state的状态为0(FiNISHED)。然后unpark唤醒get的线程，获取执行结果。 总结最后，我们来做一个总结。AQS的主要任务是 设计了同步器的基本范式，结构 使用lockSupport包的park和unpark操作线程的状态 对阻塞FIFO队列的维护 AQS设计了独占锁模式和共享锁模式。区别是 独占锁的state是在1和0之间切换，保证了同一时间只有一个线程是活动的，其他线程都被阻塞。，唤醒FIFO队列每次只唤醒一个。 共享锁的state是在整数区间内，如果state大于0表示阻塞线程，否则唤醒FIFO队列中的所有线程 AQS的框架里面依赖的tryAcquire，tryRealease，tryAcquireShared，tryReleaseShared 方法在AQS中没有实现，这四个方法是对state资源的管理，由子类根据不同的场景定制。 参考文献https://blog.csdn.net/lingfenglangshao/article/details/78233414]]></content>
      <categories>
        <category>java同步包</category>
      </categories>
      <tags>
        <tag>java并发</tag>
        <tag>线程同步</tag>
        <tag>内存可见性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[threadLocal原理解析]]></title>
    <url>%2F2018%2F08%2F17%2FthreadLocal%2F</url>
    <content type="text"><![CDATA[ThreadLocalThreadLocal的用法 在工作中使用到了ThreadLocal变量，但是对其原理不是非常的清楚，只是知道可以保存一个共享变量到本地线程的副本，线程之间不会竞争访问该变量。具体到在原理层面上如何去实现，还有ThreadLocal引发的内存泄漏问题都不是非常清楚。这篇博客将会讲讲我对源码的了解。 ThreadLocalLocal的用法如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class ThreadlocalTest &#123; //创建一个ThreadLocal对象，设置初始值为3 private ThreadLocal&lt;Integer&gt; tlA = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return 3; &#125; &#125;; private ThreadLocal&lt;Integer&gt; tlB = new ThreadLocal&lt;Integer&gt;() &#123; @Override protected Integer initialValue() &#123; return 3; &#125; &#125;; //信号量 每次允许一个线程进入 Semaphore semaphore = new Semaphore(1); public class Worker implements Runnable &#123; @Override public void run() &#123; try &#123; Thread.sleep(1000); semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; int valA = tlA.get(); System.out.println(Thread.currentThread().getName() + "tlA 的初始值 = " + valA); valA = new Random().nextInt(); tlA.set(valA); System.out.println(Thread.currentThread().getName() + "tlA 的新值 = " + valA); int valB = tlB.get(); System.out.println(Thread.currentThread().getName() +"tlB 的初始值 = "+ valB); valB = new Random().nextInt(); tlA.set(valB); System.out.println(Thread.currentThread().getName() +"tlB 的新值 = "+ valB); semaphore.release(); &#125; &#125; /*创建三个线程，每个线程都会对ThreadLocal对象tlA进行操作*/ public static void main(String[] args)&#123; ExecutorService es = Executors.newFixedThreadPool(3); ThreadlocalTest tld = new ThreadlocalTest(); es.execute(tld.new Worker()); es.execute(tld.new Worker()); es.execute(tld.new Worker()); es.shutdown(); &#125;&#125; 运行结果如下所示： 123456789101112pool-1-thread-1tlA 的初始值 = 3pool-1-thread-1tlA 的新值 = -1506777037pool-1-thread-1tlB 的初始值 = 3pool-1-thread-1tlB 的新值 = 906618508pool-1-thread-3tlA 的初始值 = 3pool-1-thread-3tlA 的新值 = 1707618403pool-1-thread-3tlB 的初始值 = 3pool-1-thread-3tlB 的新值 = -1088499016pool-1-thread-2tlA 的初始值 = 3pool-1-thread-2tlA 的新值 = -601273490pool-1-thread-2tlB 的初始值 = 3pool-1-thread-2tlB 的新值 = 1428640209 从运行结果来看，每次调用ThreadLocal对象的get方法都得到了初始值3，让3个线程按照顺序执行，从结果看pool-1-thread-1线程结束后设置的tlA的新值对pool-1-thread-3没有影响，线程3还是得到的是ThreadLocal对象的初始值3。相当于把该ThreadLocal对象当成是本地变量一样，但是该变量其实是一个共享全局变量。 骚一点，接着对上述的代码做一些简单的改变。将main函数改变线程池的容量大小为1 123456789/*创建三个线程，每个线程都会对ThreadLocal对象tlA进行操作*/ public static void main(String[] args)&#123; ExecutorService es = Executors.newFixedThreadPool(1); ThreadlocalTest tld = new ThreadlocalTest(); es.execute(tld.new Worker()); es.execute(tld.new Worker()); es.execute(tld.new Worker()); es.shutdown(); &#125; 运行结果如下 123456789101112pool-1-thread-1tlA 的初始值 = 3pool-1-thread-1tlA 的新值 = -1998579477pool-1-thread-1tlB 的初始值 = 3pool-1-thread-1tlB 的新值 = 1571049844pool-1-thread-1tlA 的初始值 = 1571049844pool-1-thread-1tlA 的新值 = -1394637541pool-1-thread-1tlB 的初始值 = 3pool-1-thread-1tlB 的新值 = 618157570pool-1-thread-1tlA 的初始值 = 618157570pool-1-thread-1tlA 的新值 = -732125710pool-1-thread-1tlB 的初始值 = 3pool-1-thread-1tlB 的新值 = 2035779705 从运行结果中看出tlA的值被多个线程共享了，其实是因为线程池用的都是同一个线程，所以访问的是共享的变量。 接着我们看其实现原理 ThreadLocal的源码解析在Thread类中定义了一个threadLocals,默认是null。 123/* ThreadLocal values pertaining to this thread. This map is maintained * by the ThreadLocal class. */ ThreadLocal.ThreadLocalMap threadLocals = null; 在第一次调用ThreadLocal的get方法时，会为Thread线程创建一个ThreadLocalMap对象，这个是一个散列表，key是ThreadLocal对象，set方法中的值作为value，第一次调用get时，以initValue()方法返回的结果作为值。 123456789101112131415161718192021222324public T get() &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) &#123; ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings("unchecked") T result = (T)e.value; return result; &#125; &#125; return setInitialValue(); &#125; //设置初始值private T setInitialValue() &#123; T value = initialValue(); //这个方法可以被重写，设置自己的初始值 Thread t = Thread.currentThread(); ThreadLocalMap map = t.threadLocals; if (map != null) map.set(this, value); else t.threadLocals = new ThreadLocalMap(this, firstValue); return value; &#125; 图片出处 https://www.cnblogs.com/nullzx/p/7553538.html ThreadLocalMap对象ThreadLocalMap是ThreadLocal对象内部的一个静态类，内部是维护了一个Entry的散列表，代码如下 123456789101112131415161718192021222324252627282930313233static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k);//调用weakReference的构造函数 value = v; &#125; &#125; private Entry[] table; ThreadLocalMap(ThreadLocal&lt;?&gt; firstKey, Object firstValue) &#123; table = new Entry[INITIAL_CAPACITY]; int i = firstKey.threadLocalHashCode &amp; (INITIAL_CAPACITY - 1); table[i] = new Entry(firstKey, firstValue); size = 1; setThreshold(INITIAL_CAPACITY); &#125; private Entry getEntry(ThreadLocal&lt;?&gt; key) &#123; int i = key.threadLocalHashCode &amp; (table.length - 1); Entry e = table[i]; if (e != null &amp;&amp; e.get() == key) return e; else return getEntryAfterMiss(key, i, e); &#125; &#125; 每个线程都有一个ThreadLocalMap对象，key为ThreadLocal&lt;?&gt;对象，value为Object。可以在方法中定义多个threadLocal对象，但是一般都是讲ThreadLocal对象定义为static类型或者外部类中。相同的key在不同的Thread中的值是不同的。每个线程都操作各自的ThreadLocalmap对象。 Entry继承了WeakReference，且设置key为弱引用，WeakReference是在gc时一定会被回收的对象，softReference是在gc后内存不足才会再gc一遍回收软引用指向的对象。 ThreadLocal造成的内存泄露 首先，我们要明确Entry是一个强引用，Entry的key即threadLocal是一个弱引用，当这个对象只有没弱引用持有时，一定是被gc掉的。 考虑一种情况，在一个方法内申明一个ThreadLocal对象，并设置了value值。当方法运行结束时，该threadLocal对象将没有被栈的变量指向，只有Entry的一个弱引用。那么在gc时，会出现上图中所示的key为null，value存在的情况，而且该value将无法被访问。则就出现了内存泄漏。 在get方法中的getEntry方法中存在如下的一段代码。当key为null时，会调用expungeStaleEntry()方法去遍历删除所有的key为null的Entry方法。在调用get方法，set方法，remove方法，在key为null时会删除所有的为null的key 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354private Entry getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e) &#123; Entry[] tab = table; int len = tab.length; while (e != null) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == key) return e; if (k == null) expungeStaleEntry(i); else i = nextIndex(i, len); //其实就是i++ e = tab[i]; &#125; return null;&#125;//遍历删除所有key为null的Entryprivate int expungeStaleEntry(int staleSlot) &#123; Entry[] tab = table; int len = tab.length; // expunge entry at staleSlot tab[staleSlot].value = null; tab[staleSlot] = null; size--; // Rehash until we encounter null Entry e; int i; for (i = nextIndex(staleSlot, len); (e = tab[i]) != null; i = nextIndex(i, len)) &#123; ThreadLocal&lt;?&gt; k = e.get(); if (k == null) &#123; e.value = null; tab[i] = null; size--; &#125; else &#123; //重新hash int h = k.threadLocalHashCode &amp; (len - 1); if (h != i) &#123; tab[i] = null; // Unlike Knuth 6.4 Algorithm R, we must scan until // null because multiple entries could have been stale. while (tab[h] != null) h = nextIndex(h, len); tab[h] = e; &#125; &#125; &#125; return i;&#125; 上述的方法并不能保证解决内存泄漏的问题，因为在调用get方法是不一定能获得key为null的对象。当线程结束时，ThreadLocalMap对象会被回收，那么完美。但是使用线程池时，如果ThreadLocal对象被回收，而线程是回收待使用，则value会一直存在堆中无法被访问。内存就会被一直泄漏。使用线程池时使用不当还会发生bug。当定义一个static的ThreadLocal对象，使用线程池，在线程中set了一个ThreadLocal对象。那么下一个线程会得到上一个线程的value，造成bug。就像最开始的代码中的运行结果。所以在线程结束时，手动remove掉该ThreadLocal。 ok]]></content>
      <categories>
        <category>并发编程</category>
      </categories>
      <tags>
        <tag>ThreadLocal</tag>
        <tag>并发编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机 第13章 线程安全和锁优化]]></title>
    <url>%2F2018%2F08%2F14%2FJVM-13%2F</url>
    <content type="text"><![CDATA[线程安全与锁优化线程安全的定义: 当多个线程访问一个对象时，如果不用考虑这些线程在运行时的调度和交替运行，也不需要执行额外的同步，或者在调用方法时进行其他的协调操作，调用这个对象的行为都可以获得正确的结果，那么这个对象就是线程安全的。 线程安全的5种数据不可变一个final的对象被正确的构造出来后(在构造过程中没有发生this指针溢出)，那么这个对象永远不会处于多个线程中不一致的情况，即是线程安全的。如果共享数据是基本数据类型，只要使用final关键字修饰就可以了。如果是对象，则保证对象的行为对状态不会有影响。比如java.lang.String类。调用他的substring()等方法都是返回一个新构造的对象，线程安全的。对象行为不影响自己状态可以把对象中带有状态的变量都申明为final，这样在构造函数结束后就是不可变的。比如java.lang.Integer的构造函数。final类型的变量由JVM保证读取变量的值必须在变量赋值之后。 1234567891011private final int value; /** * Constructs a newly allocated &#123;@code Integer&#125; object that * represents the specified &#123;@code int&#125; value. * * @param value the value to be represented by the * &#123;@code Integer&#125; object. */ public Integer(int value) &#123; this.value = value; 绝对线程安全java.util.Vector是一个线程安全的容器，因为它的方法都加上了synchronized关键字，虽然效率比较低，但是是线程安全的。 1234567891011121314151617181920212223242526272829303132private static Vector&lt;Integer&gt; vector = new Vector&lt;Integer&gt;(); public static void main(String[] args) &#123; while (true) &#123; for (int i = 0; i &lt; 10; i++) &#123; vector.add(i); &#125; Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125;); removeThread.start(); printThread.start(); // 不要同时产生过多的线程，否则会导致操作系统假死 while (Thread.activeCount() &gt; 20); &#125; 上述的操作会导致数据越界，因为组合操作不是线程安全的，需要对Vector对象进行加锁操作。 1234567891011121314151617181920Thread removeThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized(vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; vector.remove(i); &#125; &#125; &#125; &#125;); Thread printThread = new Thread(new Runnable() &#123; @Override public void run() &#123; synchronized(vector) &#123; for (int i = 0; i &lt; vector.size(); i++) &#123; System.out.println(vector.get(i)); &#125; &#125; &#125; 相对线程安全大部分的容器都是相对线程安全的， Vector、HashTable、Collections 的 synchronizedCollection() 方法包装的集合等。 线程安全的实现方法互斥同步多个线程并发访问时保证共享书只会被一个线程使用，实现互斥同步的手段有临界区、互斥量、信号量。在java中使用synchronized关键字，被编译后会在同步块的前后分别加入monitorenter和monitorexit两个字节码指令，这两个字节码都需要一个reference类型的参数来指明锁定的对象。synchronized明确指明了锁定的对象，那么就是这个对象，如果没有指明，那么就要看synchronized修饰的是实例方法还是类方法，分别取对应的对象实例和class对象作为锁对象。根据虚拟机规范的要求，在执行 monitorenter 指令时，首先要尝试获取对象的锁。如果这个对象没被锁定，或者当前线程已经拥有了那个对象的锁，把锁的计数器加 1，相应的，在执行 monitorexit 指令时将锁计数器减 1，当计数器为 0 时，锁就被释放。如果获取对象锁失败，那当前线程就要阻塞等待，知道对象锁被另外一个线程释放为止。使用synchronized同步代码块有2点需要注意： synchronized 同步块对同一条线程来说是可重入的，不会出现自己把自己锁死的问题。采用计数器的方式+1即可。 java线程是通过操作系统的内核线程或者称为轻量级线程来实现阻塞和唤醒。则每次阻塞线程，需要操作系统先将用户态切换到内核态，状态转换需要耗费很多的时间，可能比代码执行的时间还长。因此synchronized操作是重量级锁，虚拟机本身对synchronized进行了优化，比如操作系统在阻塞线程前进行一段时间的自旋等待过程，避免频繁切换状态 除了synchonorized，还可以使用java.util.concurrent包的ReentrantLock来实现同步。用法上也可以实现重入锁，ReentrantLock加入了许多高级功能，等待可中断、实现公平锁、锁绑定多个条件 等待可中断是指当持有锁的线程长期不释放锁的时候，正在等待的线程可以选择放弃等待，改为处理其他事情，可中断特性对处理执行时间非常长的同步块很有帮助。 公平锁是指多个线程在等待同一个锁时，必须按照申请锁的时间顺序来依次获得锁；而非公平锁则不保证这一点，在锁被释放时，任何一个等待锁的线程都有机会获得锁。synchronized 中的锁是非公平的，ReentrantLock 默认情况下也是非公平的，但可以通过带布尔值的构造函数要求使用公平锁。 锁绑定多个条件是指一个 ReentrantLock 对象可以同时绑定多个 Condition 对象，而在 synchronized 中，锁对象的 wait() 和 notify() 或 notifyAll() 方法可以实现一个隐含的条件，如果要和多于一个的条件关联的时候，就不得不额外添加一个锁，而 ReentrantLock 则无须这样做，只需要多次调用 newCondition() 方法即可。 非阻塞同步互斥同步最主要的问题是进行线程切换和唤醒所带来的性能问题，因为要从用户态切换到核心态，使用轻量级线程来调度用户线程的。并且互斥同步属于悲观锁，无论数据是否存在竞争，都会进行加锁的操作。采用乐观的并发策略的实现可以不用将线程挂起，这种同步操作称为非阻塞同步。java中一般使用CAS指令完成乐观锁的操作，该指令有3个操作元素，分别是内存位置V、旧的预期值A和新值B。CAS 指令执行时，当且仅当V符合旧值预期值A时，处理器用新值B更新V的值，否则它就不执行更新，但是无论是否更新了V的值，都会返回V的旧值，上述的处理过程是一个原子操作。 12345678public final int incrementAndGet() &#123; for (;;) &#123; int current = get(); //使用volatile保证可见性 int next = current + 1; if (compareAndSet(current, next)) return next; &#125; &#125; incrementAndGet()方法在一个无限循环中，不断尝试将一个比当前值大 1 的新值赋给自己(内部维护了volatile的值)。如果失败了，那说明在执行 “获取-设置” 操作的时候值已经有了修改，于是再次循环进行下一次操作，直到设置成功为止。 但是CAS存在漏洞，即ABA问题，初始值为A，在准备赋值时检查仍然为A，但是其中可能先变成B。即ABA问题。 ThreadLocal无同步方案如果一个变量希望只在一个线程中使用，那么可以把这个变量的可见性范围限制在一个线程之中。比如web服务端中，一个请求对应一个服务器线程的处理方式可以使用线程本地储存完成。如果一个变量会被多个线程访问，可以使用volatile变量，该变量的原理前面已经讲过了。如果一个变量需要被一个线程独享，那么可以使用ThreadLocal类来实现线程本地存储。这个类的原理另外开一篇博客说明。 锁优化代码层减少锁的持有时间(锁粗化)，减少锁的粒度(concurrentHashMap,分段锁机制),锁分离(读写锁) JVM层面 锁消除 如果运行时不会出现竞争，直接将锁消除。 偏向锁 为了避免一个线程对访问的对象重复加锁和解锁，浪费资源。JVM将对象设置为可偏向的，这个是在对象的对象头的Mark Word里面设置的。默认将Mark Word的ThreadId设置为0，当第一个线程访问这个对象时，通过CAS操作将ThreadID设置为线程的ID，线程运行同步代码块。执行完不释放偏向锁，线程下次访问的时候不需要加锁和解锁。如果另外的线程竞争这个锁时，当前线程的锁升级为轻量级锁，另外的线程进行自选等待，如果自旋结束前，上一个线程释放了轻量级锁，该线程获得轻量级锁，如果自旋结束后锁没有被释放，那么轻量级锁会升级为重量级锁，自旋结束的线程进入阻塞状态。 自旋锁 当一个物理机器存在一个以上的处理器能让两个线程同时进行，那么可以让后面请求锁的线程先忙循环(自旋)，但是不放弃处理器的执行时间，称为自旋锁。 自旋锁虽然避免了线程切换的开销，但是也是会占用处理器的执行时间，如果锁占用的时间很短，自旋等待的效果会很好。否则会性能浪费。引入了自适应的自旋锁，默认是10次的自旋时间，如果锁在同一个对象，并且上一次自旋成功了，那么这次的自旋时间会加长，否则会缩短。 锁消除 对于如下的代码，因为String是final类型的，所以一定是线程安全的。 123public static String concatString(String s1, String s2, String s3) &#123; return s1 + s2 + s3;&#125; 但是在代码编译后会变成如下的样子 12345678public static String concatString(String s1, String s2, String s3) &#123; StringBuffer sb = new StringBuffer(); sb.append(s1); sb.append(s2); sb.append(s3); return sb.toString();&#125; StringBuffer的append()方式使用了synchonorized同步代码块。虚拟机观察了变量sb后，发现它无法逃逸到concatString()方法之外，其他线程无法访问到，则这里虽然有锁，但是会被消除，代码编译后不会添加monitorenter和moniterexit。 锁的状态和转化锁的状态主要有 无锁状态、偏向锁状态、轻量级锁状态，重量级锁状态状态转化 当JVM设置偏向状态时，则默认对象处于偏向锁状态 (CAS操作) 当两个线程竞争锁时，获得偏向锁的线程升级为轻量级锁，如果不再活动，转化成无锁状态，如果再活动，升级为重量级锁，然后解锁，进入无锁状态。轻量级锁能提升程序的同步性能的依据是绝大多数的锁，在整个同步周期内是不存在竞争的。因为没有竞争，轻量级锁使用CAS操作避免了互斥量的开销，如果存在锁竞争，除了互斥量的开销，还要发生CAS操作，因此在有竞争的情况下，使用轻量级锁比重量级锁更慢。偏向锁的执行过程代码进入同步快，如果没有被锁定(标志位为”01”)，那么在当前线程的栈帧中建立一个锁记录(Lock Record)的空间，存储当前对象的Mark Word(因为对象头需要记录锁相关的内容)然后虚拟机使用CAS操作将对象的Mark Word更新为 Lock Record的指针，如果成功了，那么线程有了对象的锁，将Mark Word的锁标志变成“00” 图中画错了。如果跟新失败了，那么检查对象的Mark Word是否指向当前线程的栈帧，如果是则已经获得锁直接进入同步快，否则锁被其他线程抢占了。如果多个线程竞争同一个锁，那么轻量级锁没用了，升级为重量级锁。]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>线程安全与锁优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机 第8章 虚拟机字节码执行引擎]]></title>
    <url>%2F2018%2F08%2F14%2FJVM-8%2F</url>
    <content type="text"><![CDATA[第8章 虚拟机字节码执行引擎 JAVA虚拟机规范中规定了虚拟机字节码执行引擎的概念模型。从概念模型的角度讲解虚拟机的方法调用和字节码执行。 运行时栈帧结构栈帧时用于支持虚拟机进行方法调用和方法执行的数据结构，是虚拟机运行时的数据区虚拟机栈的栈元素。栈帧中保存了方法调用的局部变量表，操作数栈，动态链接和方法返回地址等信息。每一个方法的开始执行到执行完毕对应着栈帧在虚拟机栈中的入栈和出栈操作。一个线程中的方法调用链可能很长，在活动线程中，只有栈顶的栈帧才是有效的。 局部变量表局部变量表是一组变量值存储空间，主要来保存方法参数和方法内定义的局部变量。在java代码编译时确定了该方法所需分配的局部变量表的最大容量。局部变量的存储单位是slot，一个Slot可以存放一个32位以内（boolean、byte、char、short、int、float、reference和returnAddress）的数据类型，reference类型表示一个对象实例的引用，returnAddress已经很少见了，可以忽略。对于64位的数据类型，long和double采用高位对齐的方式分配连续的两个slot。 对于reference类型表示对一个对象实例的引用，该引用有2个用处。 使用该引用找到java堆中该对象的存储的地址索引。 使用该引用可以找到该对象所属类的数据类型在方法区中存储的类型信息，其实就是该类的class对象的信息，class对象比较特殊，存储在方法区中。(对象头里面也有class地址的信息) java虚拟机通过索引定位的方式来使用局部变量表，索引范围是从0到最大值。0代表的是this指针。索引n代表使用了第n个slot，64位的数据是连续使用n和n+1的slot。slot可以被复用，为了节省空间。类变量表一般有2次的初始化机会，一次是在类加载的准备阶段为类变量赋零值，执行系统的初始化。另一个是在类加载的初始化阶段，赋程序猿在代码定义的初始值。但是局部便利那个不存在系统初始化的阶段，这意味着定义的局部变量必须认为初始化。 操作数栈操作数栈是一个后进先出的数据结构，当方法执行时，方法中的操作数对应着入栈和出栈的操作。即会各种指令向操作数栈中写入和提取内容。 在概念模型中，一个活动线程的两个栈帧是相互独立的，但是虚拟机会做优化处理，让下一个栈帧的部分操作数栈和上一个栈帧的局部变量表重叠，可以共享一部分数据，无需额外的数据赋值传递。 动态链接每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用。持有引用为了支持方法调用过程的动态链接。class文件中的常量池中存在大量的符号引用，字节码的方法调用指令是以指向常量池中的符号引用作为参数的。则可以通过字节码迅速定位到具体的方法代码。一部分符号引用在类加载或者第一次使用时转化成直接引用，这种转化称为静态解析。另一部分在每次运行时才转为直接引用，称为动态链接。 方法返回地址存放调用该方法的计数器的值。当一个方法开始后有2种方式退出。&nbsp;&nbsp;&nbsp;&nbsp;1. 遇到return返回，正常退出。&nbsp;&nbsp;&nbsp;&nbsp;2. 遇到异常，并且这个异常在方法内没有catch，即在方法内部没有匹配的异常处理器，导致方法退出，方法异常退出不会给调用者返回任何值。无论哪种方法退出后都会返回该方法调用的位置，正常退出使用计数器的值作为地址，异常退出要通过异常处理表来确定返回地址。 方法调用方法调用阶段是为了确定调用方法的版本，即具体调用的是哪一个方法，方法调用和方法执行不同，调用阶段不涉及方法内部的运行过程。==在class文件中存储的都只是符号引用而不是具体的内存布局的入口。只有在类加载阶段或者运行期间才能确定方法的直接应用。== 方法的解析在类加载的解析阶段，会将一部分的符号引用转化成直接引用，这个解析成功的前提条件是：方法在程序真正运行前就有一个可以调用的版本，并且这个版本在运行期间不可改变。java中的static方法，private方法，init方法和父类方法是“编译期克制，运行期不可变的”。可以在类加载期间进行解析。java虚拟机中提供了5中方法调用字节码 &nbsp;&nbsp;&nbsp;&nbsp;1. invokestatic:调用静态方法 &nbsp;&nbsp;&nbsp;&nbsp;2. invokespecial:调用构造器，私有方法和父类方法 &nbsp;&nbsp;&nbsp;&nbsp;3. invokevirtual:调用虚方法 &nbsp;&nbsp;&nbsp;&nbsp;4. invokeinterface:调用接口方法 &nbsp;&nbsp;&nbsp;&nbsp;5. invokedynamic：现在运行时动态解析出该方法，然后执行。 其中，invokestatic和invokespecial指令调用的放啊都可以在解析阶段找到唯一调用版本。符合这个条件的有静态方法，私有方法，实例构造器，父类方法。在类加字啊 12345678910111213141516171819202122public class MethodInvokeTest &#123; public static void sayHello()&#123; log.info("我是不可改变的，任何方式都无法改变我的结构..."); &#125; // 为了对比说明，我们来看一下一个普通的方法sayHello() public void eatApple()&#123; log.info("我是可以改变的，子类可以通过继承改变我的结构"); &#125;&#125;public class MethodInvokeExtendsClass extends MethodInvokeTest&#123; public void eatApple()&#123; log.info("我输出我自己的内容..."); &#125; public static void main(String[] args) &#123; MethodInvokeExtendsClass methodInvokeExtendsClass = new MethodInvokeExtendsClass(); // invokespecial指令 methodInvokeExtendsClass.eatApple(); // invokevirtual指令 --输出：我输出我自己的内容... MethodInvokeTest.sayHello(); // invokestatic指令 --我是不可改变的，任何方式都无法改变我的结构... &#125;&#125; 方法的分派方法的解析是一个静态的过程，==在编译期间可以得到最终的版本==，在类加载的解析阶段可以把涉及的符号引用全部转化成直接饮用，而方法的分派(Dispacher)调用可能是静态的也可能是动态的。 静态 Dispather静态分派我理解的最常见的就是方法的重载(overload)了。即在编译期间就要确定是调用哪一个方法。具体代码如下： 123456789101112131415161718192021222324252627282930public class StaticDispatchTest extends Object&#123; final static Log log = LogFactory.getLog(StaticDispatchTest.class); // 父类 static abstract class Fish&#123;&#125; // 子类：鲫鱼 static class Jiyu extends Fish&#123;&#125; // 子类：鲤鱼 static class Liyu extends Fish&#123;&#125; // 下面写几个重载的方法 public void swimming(Fish fish)&#123; log.info("我是鱼，我用鱼鳍游泳..."); &#125; public void swimming(Jiyu jiyu)&#123; log.info("我是鲫鱼，我用鱼鳍游泳..."); &#125; public void swimming(Liyu liyu)&#123; log.info("我是鲤鱼，我用鱼鳍游泳..."); &#125; // 测试 public static void main(String[] yangcq)&#123; Fish jiyu = new Jiyu(); Fish liyu = new Liyu(); StaticDispatchTest staticDispatchTest = new StaticDispatchTest(); staticDispatchTest.swimming(jiyu); // 打印：我是鱼，我用鱼鳍游泳... staticDispatchTest.swimming(liyu); // 打印：我是鱼，我用鱼鳍游泳... &#125;&#125; 在方法的重载时是通过参数的静态类型而不是实际类型作为判定依据的。静态类型在编译期间可知的。因此，在编译期间，javac可以根据参数的静态类型确定调用那个重载版本。jiyu和liyu的静态类型都是Fish。并且静态分配时发生在编译期间，会自动寻找最合适的函数绑定。 动态Dispather动态Dispather的主要体现时在override上，代码如下 1234567891011121314151617181920212223242526public class DynamicDispatchTest extends Object&#123; // 父类 static abstract class Fish&#123; public void swimming()&#123; System.out.println("我是鱼，我用鱼鳍游泳..."); &#125; &#125; // 子类：鲫鱼 static class Jiyu extends Fish&#123; public void swimming()&#123; System.out.println("我是鲫鱼，我用鱼鳍游泳..."); &#125; &#125; // 子类：鲤鱼 static class Liyu extends Fish&#123; public void swimming()&#123; System.out.println("我是鲤鱼，我用鱼鳍游泳..."); &#125; &#125; public static void main(String[] yangcq)&#123; Fish jiyu = new Jiyu(); Fish liyu = new Liyu(); jiyu.swimming(); // 打印：我是鲫鱼，我用鱼鳍游泳... liyu.swimming(); // 打印：我是鲤鱼，我用鱼鳍游泳... &#125;&#125; 正常的方法调用都是调用invokeVirtual方法，invokeVirtual方法的解析 找到操作数栈顶的第一个元素所指向的对象的实际类型，记做C； 在类型C中找到与常量描述符相同的类型和方法，直接通过offset来找找到。然后返回改方法的直接引用地址。 如果在C中没有该方法，就从C的父类中去查找，直到找到具体调用的方法，如果没有找到，就抛出异常。由于invokevirtual指令执行的第一步就是在运行期间确定接收者的实际类型，所以2次调用中的invokevirtual指令把常量池中的类方法的符号引用解析到了不同的直接引用上，这个过程就是Java语言中方法重写的本质。我们把这种运行期间根据实际类型确定方法执行版本的分派过程称为动态分派。 虚拟机动态分派的实现动态分派的实现是在类加载的时候在方法区中建立一个虚方法表， 用虚方法表来代替元数据的查找来提高性能。虚方法表中存放的是各个方法的实际入口地址。如果方法没有被重写，就和父类的入口地址一样，否则用子类自己的地址。同时，相同的签名的方法，在父类和子类的虚方法表中应当有相同的索引序号，这样在类型转换时候可以方便改变查找的虚函数表。虚方法表一般在类加载的准备阶段初始化。]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>虚拟机字节码执行引擎</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM原理 第2章 java运行时数据区]]></title>
    <url>%2F2018%2F08%2F12%2FJVM-2%2F</url>
    <content type="text"><![CDATA[Java内存区域与内存溢出异常2.2 运行时数据区域&emsp;&emsp;java虚拟机在运行程序时会把管理的内存分为几个不同的数据区域，这些区域的作用不同并且创建和销毁的时间不同。java虚拟机将管理的内存分为以下几个数据区域。1234567线程共享部分1. 方法区2. 堆线程私有部分3. 虚拟机栈4. 本地方法栈5. 程序计数器 2.2.1 程序计数器&emsp;&emsp;一块比较小的内存区域，看成当前线程执行字节码的行号指示器。通过改变这个值来取下一条的指令，分支、循环、跳转、异常处理、线程恢复都是靠这个计数器来完成。&emsp;&emsp;java的多线程时通过线程轮流切换并分配处理器的执行时间来实现。为了线程切换后能恢复到正确的执行位置，每个线程需要独立的程序计数器，各个线程的程序计数器相互不影响。&emsp;&emsp;如果线程执行java方法，这个计数器记录正在执行的虚拟机字节码指令的地址，如果是执行native方法，计数器的值为空(undefined)。此内存区域为java虚拟机规范中没有规定任何OutOfMemoryError情况的区域。 2.2.2 java虚拟机栈&emsp;&emsp;java虚拟机栈(Java Virtual Machine Stacks)也是线程私有的，生命周期和线程相同。虚拟机栈描述的是java方法执行的内存模型。在调用方法的同时会创建一个栈帧(Stack Frame)来存储局部变量表，操作数栈，动态链接，方法出口等信息。每个方法从调用到执行完成对应栈帧在虚拟机栈中的入栈道出栈的过程。&emsp;&emsp;局部变量表中存放的是编译期间可知的基本数据类型(boolean, byte, char, short, int, float, long, double)、对象引用类型(reference类型),是指向堆对象的一个引用。其中long和double数据类型占用2个slot槽，其余占用一个slot槽。一个槽指向一个地址，long和double需要两个地址空间存放64位的数据，则需要两个slot。局部变量表的所需的空间在编译期间完成，在放啊运行期间不会改变局部变量表的大小。 &emsp;&emsp;在方法中声明的是基本类型的变量时，变量名和值(变量名和值时两个概念)是存放在方法栈中，申明的事引用变量时，对象的内存地址是存放在栈中。&emsp;&emsp;类中声明的是基本基本变量，称为全局变量，变量名和值都是存放在堆中。引用类型存放的是对象的地址。 &emsp;&emsp;在java虚拟机规范中对这个区域规范两种异常，线程请求的栈深度超过虚拟机提供的深度，抛出StackOverflowError异常，如果方法无法申请足够的内存，抛出OutOfMemoryError异常。 2.2.3 本地方法栈本地方法栈(Native Method Stack)和虚拟机栈类似。只是本地方法栈是为虚拟机使用到的native方法服务。本地方法栈也会抛出StackOverflowError和OutOfMemoryError异常。 2.2.4 Java堆&emsp;&emsp;Java堆是虚拟机管理内存最大的部分。是线程共享的。在虚拟机启动的时候创建。存放的是实例对象。 java堆是垃圾收集器管理的主要部分。所以也称为GC堆。 线程共享的java堆中可以划分出线程私有的分配缓冲区(TLAB thread local allcation buffer)。 2.2.5 方法区方法区中存放的是被虚拟机加载的类信息，常量，静态变量，编译后的代码等。GC分代收集扩展至方法区。 2.2.6 运行时常量池class文件中出了类的版本，字段，方法等信息还有常量池，存放编译期间生成的各种字面量和符号引用，该部分在类加载后放在方法区中的运行时常量池中存放。在运行期间也会将新的常量放入池内。比如String的intern()方法。 2.2.7 直接内存在NIO类中，引入了基于通道(channel)与缓冲区(Buffer)的I/O方法，可以使用Native函数直接在堆外分配内存，然后通过存储在java堆中的DirectByteBuffer对象作为这个内存的引用操作。可以提高性能，避免在Java堆和native堆中来回复制数据。显然，本机直接内存不会受到java堆大小的限制，但是受到本机的物理内存的影响。 2.3 对象的创建过程 当虚拟机遇到一个new指令，首先检查这个指令的参数在常量池能定位到一个符号引用，再检查这个符号引用的类是否被加载，解析和初始化，没有要先执行类加载过程。 将一块等同该对象大小的空间从java堆中划分出来，一般是维护一个队列，记录可用的内存。 为了保证分配对象的线程安全，1.使用TLAB来分配2.使用CAS来进行失败重试保证内存分配的原子性。 分配完对象，需要对内存空间进行初始化为零值。并且设置对象的对象头的一些值，比如哈希值，GC年代等等。 上述工作完成后，虚拟机角度看一个对象产生了，但是从java程序看，对象还没有初始化，因为没有执行方法。 对象的内存布局在虚拟机中，一个对象在内存中的分配区域主要有：对象头，实例数据，对其补充。如图所示 对象头对象头中主要有Mark Word和指向class元类型的指针。 第一部分用于存储对象自身的运行时数据，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳、对象分代年龄，这部分信息称为“Mark Word”；Mark Word 被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据自己的状态复用自己的存储空间。 第二部分是类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例；如果对象是一个 Java 数组，那在对象头中还必须有一块用于记录数组长度的数据。因为虚拟机可以通过普通 Java 对象的元数据信息确定 Java 对象的大小，但是从数组的元数据中无法确定数组的大小。这部分数据的长度在 32 位和 64 位的虚拟机（未开启压缩指针）中分别为 32bit 和 64bit。 例如，在 32 位的 HotSpot 虚拟机中，如果对象处于未被锁定的状态下，那么 Mark Word 的 32bit 空间中的 25bit 用于存储对象哈希码，4bit 用于存储对象分代年龄，2bit 用于存储锁标志位，1bit 固定为 0，如下表所示： 在 32 位系统下，存放 Class 指针的空间大小是 4 字节，Mark Word 空间大小也是4字节，因此头部就是 8 字节，如果是数组就需要再加 4 字节表示数组的长度，如下表所示： 在 64 位系统及 64 位 JVM 下，开启指针压缩，那么头部存放 Class 指针的空间大小还是4字节，而 Mark Word 区域会变大，变成 8 字节，也就是头部最少为 12 字节，如下表所示： 压缩指针：开启指针压缩使用算法开销带来内存节约，Java 对象都是以 8 字节对齐的，也就是以 8 字节为内存访问的基本单元，那么在地理处理上，就有 3 个位是空闲的，这 3 个位可以用来虚拟，利用 32 位的地址指针原本最多只能寻址 4GB，但是加上 3 个位的 8 种内部运算，就可以变化出 32GB 的寻址。 实例数据实例数据是对象存储的有效信息，在程序代码中定义的各种类型的字段内容。 对齐补充由于HotSpot VM的自动内存管理系统要求对象起始地址必须是 8 字节的整数倍，也就是说对象的大小必须是 8 字节的整数倍。对象头部分是 8 字节的倍数，所以当对象实例数据部分没有对齐时，就需要通过对齐填充来补全。 估算对象大小32 位系统下，当使用 new Object() 时，JVM 将会分配 8（Mark Word+类型指针） 字节的空间，128 个 Object 对象将占用 1KB 的空间。如果是 new Integer()，那么对象里还有一个 int 值，其占用 4 字节，这个对象也就是 8+4=12 字节，对齐后，该对象就是 16 字节。 以上只是一些简单的对象，那么对象的内部属性是怎么排布的？ 12345Class A &#123; int i; byte b; String str;&#125; 其中对象头部占用 ‘Mark Word’4 + ‘类型指针’4 = 8 字节；byte 8 位长，占用 1 字节；int 32 位长，占用 4 字节；String 只有引用，占用 4 字节；那么对象 A 一共占用了 8+1+4+4=17 字节，按照 8 字节对齐原则，对象大小也就是 24 字节。 这个计算看起来是没有问题的，对象的大小也确实是 24 字节，但是对齐（padding）的位置并不对： 在 HotSpot VM 中，对象排布时，间隙是在 4 字节基础上的（在 32 位和 64 位压缩模式下），上述例子中，int 后面的 byte，空隙只剩下 3 字节，接下来的 String 对象引用需要 4 字节来存放，因此 byte 和对象引用之间就会有 3 字节对齐，对象引用排布后，最后会有 4 字节对齐，因此结果上依然是 7 字节对齐。此时对象的结构示意图，如下图所示： 对象的访问定位在访问对象时，通过栈上的reference数据类操作堆上的具体对象。reference类型在具体的访问对象有2种方式： 使用句柄访问，&nbsp;&nbsp;&nbsp;&nbsp;在java堆中划分一块区域为句柄池，reference存储的是对象的句柄地址，句柄中包含对象的实例地址和对象类型。对象类型是通过对象头的指针来访问 直接指针访问&nbsp;&nbsp;&nbsp;&nbsp;reference存储的是对象的直接地址。]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>java运行时数据区</tag>
        <tag>对象创建</tag>
        <tag>对象访问定位</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机 第3章 垃圾回收器和内存分配策略]]></title>
    <url>%2F2018%2F08%2F12%2FJVM-3%2F</url>
    <content type="text"><![CDATA[垃圾回收和内存分配策略垃圾收集(Garbage Collection, GC)主要关注的是java堆。因为虚拟机栈，本地方法栈，程序计数器都是随着线程的产生和消失。所以这部分的内存分配是在编译器可知。对它的内存分配是确定的。对于java堆的对象实例，只有在运行期间才知道创建那些对象实例，则这部分的内存分配和回收是动态的。 引用计数算法给对象添加引用计数器，有引用就值加1，失效就减1.计数器为0就不可能再被使用。效率高，但是不能解决对象相互引用的问题。GC Rootsde 的可达性分析来判断对象是否存活。比如 12345678910public class A&#123; public Object instance = null;&#125;A a1 = new A();A a2 = new A();a1.instance = a2;a2.instance = a1;a1 = null;a2 = null;System.gc(); 则a1 和a2 应该要被回收的，但是他们有引用，不可能被回收的问题。可达性分析算法:通过一系列的称为”GC Roots”的对象作为起始点。当对象到GC Roots之间有可达的引用连认为对象可用。否则就认为对象不可达，可以回收。当一个对象到GC Roots 没有任何链相连就认为对象是不可用的。作为GC Roots的对象包括: * 虚拟机栈(栈帧的本地变量表)中引用的对象。 2.本地方法栈中的JNI(native 方法)引用的对象。 3.方法区中的常量或者类静态属性引用的对象。 // static的属性引用的对象 因为static是类加载就生成对象了 引用类型 1234567891011121314151617181920212223 1、强引用 new出来的对象，只要引用存在，该对象就不会被回收 2、软引用 SoftReference 引用一些有用但并非必须的对象，当系统出现内存溢出异常之前会对软引用的对象进行回收，回收后还没有足够的内存才会内存溢出 3、弱引用 被弱引用关联的对象只能生存到下一次的垃圾回收之前。即对象被引用了还是会被回收。WeakReferemce 4、虚引用 无法通过虚引用来获得对象的实例，设置虚引用的目的是对象被垃圾回收时收到一个系统通知。PhantomReference ``` ## 回收方法区回收方法区方法区(永久代)回收两个部分：废弃常量和无用的类。回收废弃常量比较简单。只要没有对象引用这个常量就可以将该常量移出常量池。**在常量池中有“abc”这个字符串，只要没有任何的String对象引用这个对象，该对象就会被回收。** 回收无用的类： 1.对象的实例被全部回收。 2.加载该类的classloader被回收。 3.class对象没有被引用，无法通过反射调用该类的方法。 该类可以被回收。 可达性分析：```java1. Object aobj = new Object ( ) ;2. Object bobj = new Object ( ) ;3. Object cobj = new Object ( ) ;4. aobj = bobj;5. aobj = cobj;6. cobj = null;7. aobj = null; 第4行和第7行都会导致有对象被回收。因为aobj、bobj、cobj都是虚拟机栈的局部变量表中的reference所指的对象。而其中new的3个object是存放在java堆中的。那么如果aobj=bobj后，那么aobj所指向的object就没有gc roots的引用链可以引用，就会被回收。而cobj也会被回收。 1231. String str = new String("hello");2. SoftReference&lt;String&gt; sr = new SoftReference&lt;String&gt;(new String("java"));//软引用3. WeakReference&lt;String&gt; wr = new WeakReference&lt;String&gt;(new String("world")); //弱引用 第二个在内存不足会被回收，第三个一定会被回收。 总结下常用的会被回收的情况 1.显示的将引用赋值为null或者将已经指向某个对象的引用指向新的对象。 123451. Object obj = new Object();2. obj = null;3. Object obj1 = new Object();4. Object obj2 = new Object();5. obj1 = obj2; 2.局部引用指向的对象 1234567void fun() &#123;..... for(int i=0;i&lt;10;i++) &#123; Object obj = new Object(); System.out.println(obj.getClass()); &#125;&#125; 循环每执行一次，生成的object对象都会被回收。 3.只有若引用与其关联的对象 1WeakReference&lt;String&gt; wr = new WeakReference&lt;String&gt;(new String("world")); 垃圾回收算法：Mark-Sweep（标记清除算法） 标记出所有需要被回收的对象，清除就是回收所有的标记对象的占用的内存。 图中看出容易产生碎片。后续无法为大的对象分配内存。 复制算法将内存分为相等的2快，每次垃圾回收将存活的对象全复制到另外一般的干净的内存中，然后对整半个内存清理。 不需要考虑内存碎片等情况。缺点：内存缩小到原来的一半。现在的虚拟机都是采用这个方法来收集新生代：新生成的对象98%是要死的。那么存活的对象很少。可以把内存分为1个较大的Edge区域和2个Survicor空间。比例为8：1。那么每次回收就把Survivior的对象和Eden对象的存活对象复制到另一个Survivor区间。然后清理刚刚所有的Edge和Survivor区间的对象。当一个survivor中不能存放所有的存活对象时候，这些对象会直接通过担保机制进入到老年代。 当一个新生对象经过15次的垃圾回收后还存活，就将对象移动到老年代。 标记-整理算法标记复制算法在对象存活率较高时候要进行过多的复制操作，效率比较低。不想浪费50%的空间，还需要额外的空间担保分配以应对内存中100%的对象都存活的极端条件。所以在老年代中不使用这个方法，而是用标记整理算法。因为老年代的对象存活率较高 将对象标记，完成标记后将所有的存活对象都往一端移动，然后清理边界以外的内存。有点：充分利用内存。 分代收集算法 将对象分为新生代和老年代。对新生代采用复制算法。对老年代就采用标记-清理或者标记-整理。 ==枚举根节点：== 可作为GC Roots的节点主要是全局性引用（(常量池中)常量和(方法区中)类的静态属性变量）和 执行上下文(帧栈中的本地变量表)。但是有些方法区就有数百兆。那么如何快速定位常量、静态变量或者本地变量表。 需要使用OopMap数据结构。记录下栈和寄存器那些位置是引用。这样GC扫描直接可以得到GC Roots 。 安全点：导致OopMap变化的指令很多。那么就要就要设定在特定的地方记录OopMap。“让程序长时间执行的特征”设立安全点。比如方法调用、异常跳转、循环跳转等。产生safepoint。 线程安全： 在gc调用时，要暂停全部线程(除了虚拟机调用的线程)。那么有两种方案。 1. 抢先式中断 如果发生gc，就把所有的线程都中断。 2. 主动式中断 如果gc需要中断，就设定标志，各线程去轮训这个标志. 线程休眠：当线程休眠，无法响应JVM的中断请求。就进入&quot;安全区域&quot;。对安全区域的内容不用线程中断。直接清理。当线程开始后，要等清理完毕后才能开始工作。 典型的垃圾收集器： serial/serial old 收集器单线程收集器进行垃圾收集时，必须暂停所有用户线程。Serial收集器是针对新生代的收集器，采用的是Copying算法，Serial Old收集器是针对老年代的收集器，采用的是Mark-Compact算法。它的优点是实现简单高效，但是缺点是会给用户带来停顿。 ParNew收集器多线程版本。 CMS收集器 一种以获取最短回收停顿时间为目标的收集器，它是一种并发收集器，采用的是标记-清除算法。分为以下4个步骤1.初始标记 //暂停所有线程. 2.并发标记 3.重新标记//暂停所有线程 4.并发清除 产生大量的内存碎片，需要内存紧缩操作，这个过程不能并行。在并发清除时候要和用户线程一起操作，会降低效率。 G1收集器G1收集器是当今收集器技术发展最前沿的成果，它是一款面向服务端应用的收集器，它能充分利用多CPU、多核环境。因此它是一款并行与并发收集器，并且它能建立可预测的停顿时间模型。对新生代支持标记复制算法，对老年代支持标记整理算法。同时维护一个可预测时间大小的region域，根据时间要求去清除最优价值的区域。 内存分配和担保策略java的内存分配就是如何在堆上分配对象，对象主要分配在新生代的Eden区域，如果启动了本地内存分配缓冲，则将按线程有限在TLAB分配，在少数情况下也会分配在老年代。 对象优先在Eden分配&nbsp;&nbsp;&nbsp;&nbsp;小对象在Eden区分配，当Eden区没有足够的空间区域分配就会发起一次Minor GC。 大对象直接进入老年代&nbsp;&nbsp;&nbsp;&nbsp;大对象指需要连续内存空间的JAVA对象，一般是大String或者大数组，比如一个new Integer[1024]的对象就会分陪在老年代。 长期存活的对象会直接进入老年代&nbsp;&nbsp;&nbsp;&nbsp;虚拟机为每个对象分配一个age计数器，对象在Eden区出生并且经过一次minor gc后存活就被移动到survivor区域，并且age+1，每次经过minor gc就会年龄+1，当age增加到一定值(默认15)，会被移动到老年代。 动态对象年龄判断&nbsp;&nbsp;&nbsp;&nbsp;在survivor区域的相同年龄的所有对象的内存总和大于survivor空间的一半，年龄大于或者等于这个对象的直接进入老年代，无需默认的15的要求。 空间担保策略&nbsp;&nbsp;&nbsp;&nbsp;在发生Minor GC时，虚拟机都会先检查老年代的最大连续可用空间是否大于新生代的所有对象空间。如果成立，则Minor GC是安全的。如果小于的话，就会先进行一次Full GC。新生代采用复制收集算法，使用一个Survivor空间来做备份，当Minor GC后还出现大量的存活对象，survivor无法存储的对象将直接进入到老年代。前提是老年代有足够的空间容纳这个对象。反正老年代的空间不足就会full gc(我是这么理解的)]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>垃圾回收</tag>
        <tag>内存分配</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM原理 第12章 java内存模型和线程]]></title>
    <url>%2F2018%2F08%2F07%2FJVM-12%2F</url>
    <content type="text"><![CDATA[java内存模型和线程 JVM的内存模型是为了解决虚拟机实现多线程，但是多线程之间共享和竞争数据导致的问题。 硬件的效率与一致性计算机的存储设备和cpu的运算能力之间存在数量级之间的差距，所以现代计算机系统会在内存和cpu之间再插入告诉缓存cache，cache的速度和cpu的速度一致。这样的好处是每次运算都会先将数据复制到缓存中，在进行cpu计算，计算结束后再讲结果从缓存同步到内存中，这个cpu无需每次都等待缓慢的内存读写了。存在问题：缓存一致性 每个cpu都有自己的高速缓存，同时共享同一个主内存。当多个处理器处理涉及同一个内存，需要有一致性协议来保证数据一致性。同时为了使处理器内部的运算单元能被充分利用，处理器对输入的代码会进行乱序处理优化，处理器会保证结果的正确性 java内存模型 java的内存模型定义了虚拟机将变量存储到内存和从内存中取出变量这样的细节，包括实例字段，静态字段和构成数组对象的元素，但是不包括局部变量和方法参数，因为这些是私有的，不会被共享，不存在竞争问题。 Java内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存（可以与前面将的处理器的高速缓存类比），线程的工作内存中保存了该线程使用到的变量到主内存副本拷贝，线程对变量的所有操作（读取、赋值）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同线程之间无法直接访问对方工作内存中的变量，线程间变量值的传递均需要在主内存来完成，线程、主内存和工作内存的交互关系如下图所示 注意： reference变量是局部变量中，是线程私有的，但是它的实例对象是共享的。 拷贝副本不会一次性拷贝10m的变量。volatile变量还是有工作内存的拷贝，但是它的操作顺序由特殊的规定，使它的操作就像在主内存中访问。 这里的主内存、工作内存与Java内存区域的Java堆、栈、方法区不是同一层次内存划分。 内存间交互操作java内存模型规定了如下8种操作来完成主内存和工作内存之间的数据交互，虚拟机保证如下8种操作是原子性的。 lock 作用主内存的变量 把一个变量标识为线程独占的状态 unlock 作用主内存的变量 把一个变量从锁定状态释放出来，该变量可以被其他线程锁定 read 作用主内存的变量 把一个变量从主内存传输到工作内存，使可以被loan动作使用 loan 作用于工作内存 把从主内存read的变量载入工作工作内存的变量副本中 use 作用于工作内存 把工作内存的变量传递给cpu，当虚拟机遇到需要读取变量的字节码会执行该指令 assign 作用于工作内存 把cpu的执行结果赋值给工作内存副本 store 作用于工作内存 把工作内存的变量传输到主内存 write 把工作内存传输的变量存到主内存的变量中。 java内存模型规定了在执行上述的8中基本操作还要满足如下规则 read 和loan 必须同时出现，即工作内存从主内存读取了对象后必须接收 不能丢弃assign操作，即工作内存的变量变化了必须同步到主内存中 没有发生assign，不能将工作内存的变量同步到主内存 lock时会清空工作内存的值，cpu需要使用这个值时必须重新loan 在unlock之前，会先将变量同步到主内存。 如下的4条看上去是原子性的操作其中只有第一个是原子性，JVM保证简单的内存赋值是原子性，y=x首先要读取x变量的值，再将x的值赋给y，x++和x=x+1肯定不是原子性的操作。 1234x = 1y = xx++x = x + 1 volatile变量的特殊规定在使用了volatile变量后，当一个线程修改了这个值，另一个线程都会立刻得知。 如果是普通的变量，只有A线程修改了值，写回主线程，B线程再读取内存的值才可以。volatile的操作规定，v和w都是volatile变量： 线程T每次use变量v之前都要执行loan操作，loan操作和read必须同时出现。即（在工作内存中，每次使用v都会从主内存刷新得到最新的值，来保证能看见其他线程对变量v所做的改变。） 线程assign后必须执行store，store和write会同步出现，即(在工作内存中，每次修改v后必须同步回主内存中，用来保证其他线程能立即看见自己对变量v的修改) 保证volatile修饰的变量不会指令重排序优化，保证代码的执行顺序和程序的顺序相同。 volatile保证在将修改同步到内存之前，所有之前的操作都已经执行完毕，形成指令重拍序无法越过内存屏障，即保证了volatile之前的指令都已经执行完毕，在volatile之后的指令都没有执行。但是不保证其他指令的重拍序。volatile保证了指令不会被乱序，如果initialized没有使用volatile，那么可能由于指令重排序导致线程A的最后的initialized = true被提前执行，则线程B使用配置文件会出错。 volatile解决DCL(双重检查)问题 单例使用DCL写的懒汉式单例模式如下所示 12345678910111213141516171819202122232425public class Singleton &#123; private static Singleton instance = null; private int age; public static Singleton getInstance() &#123; if(instance == null) &#123; //1 synchonorized(Singleton.class) &#123; //2 if(instance == null) &#123; //3 instance = new Singleton(); //4 &#125; &#125; &#125; return instance; //5 &#125; public Singleton() &#123; this.age = 18; &#125; public int getAge() &#123; //6 return age; &#125;&#125; 在一般情况下该单例模式可以正常工作，但是在多线程调用该单例还是会出现并发的问题。因为可能线程会得到一个并未完全构造完成的对象。比如当A线程访问getinstance()方法，在//1出instance == null 返回true，获得锁进入同步代码块，此时线程B也访问getInstance()方法，线程B在//1处instance==null可能会返回false，但是此时instance并未完全初始化完成，线程B得到一个完全初始化的instance，线程B在调用//6时可能不能拿到age=18的结果，此时DCL的问题就出来了。问题就出在指令重排序的问题。 问题出现的原因instance = new Singleton()这一句话不是原子操作，它的操作可以分为如下三个部分： 分配内存空间 实例化对象instance 把instance引用指向的已分配的内存空间，此时instance有了内存地址，不再是null了 java允许对指令进行重排序，那么以上3步的执行顺序就可能是1-3-2，在这种情况下如果线程A执行完1-3后被阻塞了，此时线程B进来获得了instance的引用，因此此时instance不为空，直接到//1就返回了获得了没有实例完全的对象。 使用volatile可以避免这个问题，因为volatile的对象保证不会被指令重拍序，在操作volatile对象之前的代码一定是执行完毕并且可见，在变量操作之后的代码一定是还没有被执行的。所以当instance被定义成volatile时，保证创建的顺序一定是1-2-3，instance一定是null或者完全初始化完成的对象。其实可以创建成一个static类并获取对象，因为虚拟机会自动保证静态变量的并发。synchonorized不会对分配内存的操作防止指令重拍序，它只能保证在它离开同步代码块前把变化的变量都刷新回主内存。所以会存在instance不为null，但是对象还没有构造完成。 12345678910111213141516171819202122232425public class Singleton &#123; private volatile static Singleton instance = null; private int age; public static Singleton getInstance() &#123; if(instance == null) &#123; //1 synchonorized(Singleton.class) &#123; //2 if(instance == null) &#123; //3 instance = new Singleton(); //4 &#125; &#125; &#125; return instance; //5 &#125; public Singleton() &#123; this.age = 18; &#125; public int getAge() &#123; //6 return age; &#125;&#125; volatile和synchonorized的区别 volatile和synchonorized都保证了可见性，volatile是通过强制刷新到主内存保证，synchonorized是对一个变量进行unlock时必须先同步到主内存中。 volatile防止了指令重拍序，synchonorized保证了两个线程进入同步代码块的先后性保证了有序性，两者的原理有本质的区别。 volatile变量在并发下不安全volatile变量规定对所有线程都是立即可见的，对volatile的所有写操作都是可以立刻反应到其他的线程中。虽然volatile变量不存在一致性问题，但是java运算操作不是原子性的，所以volatile变量的运算不是安全的。还volatile变量禁止指令重排序。比如自加操作。race++这个过程需要有多个步骤，将race的值取到栈顶，这个过程是正确的，但是接下来的自加操作中如果有其他的线程往主内存写数据就会使数据写回出错。写回去的值可能会比理论值小。什么情况下可以使用volatile变量 运算结果不依赖当前值，或者确保只能一个线程可以修改变量的值2。 变量不需要其他的状态变量共同参与不变约束。 ##原子性，可见性，有序性java的内存模型都是围绕着在并发过程中如何处理原子性，可见性，有序性三个特征建立的 原子性 &nbsp;&nbsp;&nbsp;&nbsp;java内存模型直接保证8个基本操作是原子性的，如果要在大范围内保证原子性，必须使用monitorenter和monitorexit来隐式使用，这个反映到java代码就是同步代码块synchonorized关键字，即synchonorized的代码是原子性的。 可见性 &nbsp;&nbsp;&nbsp;&nbsp;一个线程修改了变量的值，其他的线程能立刻得到这个新的值。如volatile变量，除了这个变量，synchronized和final也可以完成可见性。final字段初始化后就能立刻被其他线程访问。 有序性 &nbsp;&nbsp;&nbsp;&nbsp;线程内表现为串行的操作，在其他的线程看来是无序的。包括指令重排序和主内存同步延迟现象。 对于可见性，violatile保证可见性，synchonorized和final也能保证可见性。synchonorized同步快的可见性是“对一个对象执行unlock前必须将变量同步到主内存(执行store，write)中”保证，我理解同步块是保证了在同步代码块中变化的变量都必须刷新到主内存中才会释放锁。final关键字的可见性是被final修饰的字段在构造器中一旦被初始化完成，并且构造器没有把“this”引用传递出去，那么其他线程就能得到正确的值。this指针逃逸是一件危险的事情，其他线程可能访问到初始化了一半的对象。对于有序性，violatile和synchonorized都能保证有序性，violatile是防止指令重排序，synchonorized是由一个变量在同一时刻只能一个线程对其lock操作的这个规则获得的==。则决定了同一个锁的两个同步快只能串行的进入。ReentrantLock是使用CAS来保证同步性，也能保证原子性，可见性，有序性。通过内置的volatile state来保证。因为volatile会保证先行发生原则。也可以理解为读取volatile前将其之前的变量都刷新到主内存中，并使其他的缓存失效 ###先行发生原则虚拟机可以对不满足先行原则的指令进行任意顺序的重排序。满足先行发生原则的规则如下： 程序次序原则&nbsp;&nbsp;&nbsp;&nbsp;在一个线程内，代码按照顺序执行 管程锁定规则&nbsp;&nbsp;&nbsp;&nbsp;对同一个锁，unlock操作时间上先行发生于后面的lock操作 volatile变量规则&nbsp;&nbsp;&nbsp;&nbsp;对一个volatile变量的写操作先于度操作 线程启动原则&nbsp;&nbsp;&nbsp;&nbsp; Thread的start()先于该线程的任何操作 线程终止原则&nbsp;&nbsp;&nbsp;&nbsp;Thread的所有操作都先于线程的终止检测。可以通过Thread.join()和Thread.isAlive()的返回值检测线程是否已终止 线程终端规则 线程的interrupt()方法先于中断线程检测到中断事件的发生，即可以使用interrupted()方法检测到线程是否被中断了。 对象终结原则 对象构造函数执行完毕先于finilized()方法 传递性 A先于B，B先于C。保证A先于C java和线程线程是比进程轻量级的调度单位。各个线程可以共享进程的资源(内存地址，文件I/O)等，又可以独立调度。线程是CPU调度的基本单位实现线程一般有3种实现方式，内核线程实现，用户线程实现，用户线程加轻量级进程混合实现。 内核线程&nbsp;&nbsp;&nbsp;&nbsp;内核线程(Kernal-Level Thread KLT) 由操作系统内核支持的线程，这种线程由内核来完成线程切换，内核通过调度器对线程进行调度，支持多线程的内核叫做多线程内核。程序一般会使用内核线程的一种高级接口–轻量级进程(Light Weight Process LWP)轻量级进程就是通常意义的线程，每个轻量级进程都是由一个内核线程支持，因此先有内核线程，才能有轻量级进程。之间的数量关系为1：1。==内核线程耗时好资源，无法创建大规模的内核线程，并发数量低。== 用户线程&nbsp;&nbsp;&nbsp;&nbsp;系统内核感知不到用户线程的存在。线程的创建，同步，销毁，调度都由用户态完成。优点：快速低耗，可以支持更大规模的线程数量。缺点：很难实现线程的调度。==因为CPU只会调度内核线程，用户线程没有内核线程的支持无法处理切换和调度。这个部分都需要用户自己去实现，比如当一个线程死循环不放弃CPU资源，其他线程将用户无法得到执行。== 用户线程加上轻量级进程混合实现&nbsp;&nbsp;&nbsp;&nbsp;该方法使用户线程的创建，切换，调度方便，支持大规模的用户线程并发，并且操作系统提供了轻量级进程作为用户线程和内核线程的桥梁，使用内核的调度功能，即用轻量级进程来调度用户线程，用户线程和轻量级进程的数量比例为N:M。 java线程调度 协同式线程调度 &nbsp;&nbsp;&nbsp;&nbsp;线程的执行时间由线程控制，线程完成工作后通知系统切换到另一个线程。优点:实现简单，不存在线程同步的问题。缺点：一个进程不退出cpu时间就会爆炸 抢占式线程调度&nbsp;&nbsp;&nbsp;&nbsp;java使用该方法来调度。线程的执行时间由系统来决定。 ##java线程的6种状态 新建（New）:创建后尚未启动 运行（Runable）：包括running和ready两个状态 状态可能是正在运行或者等待时间片 无限期等待（Waiting）：线程无法获得CPU时间片，必须等待其他线程显示唤醒。 没有设置时间的Object.wait()，Thread.join()方法,LockSupport.park() 限期等待(Timed Waiting) 线程不会被分配CPU时间片也无需被其他线程显示唤醒，到时间自动唤醒。Thread.sleep()方法，设置等待时间的Object.wait()，Thread.join()方法，LockSupport.parkNanos()方法，LockSupport.parkUntil()方法 阻塞(Blocked) 阻塞状态和等待状态的区别是阻塞是等待获取一个排他锁，等待状态是等待唤醒动作的发生，这个过程在线程等待进入同步区域的时候，线程会进入这个状态 结束(Terminated)：线程被终止]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>java内存模型</tag>
        <tag>线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机 第6章 类文件结构]]></title>
    <url>%2F2018%2F07%2F27%2FJVM-6%2F</url>
    <content type="text"><![CDATA[深入理解Java虚拟机 第六章 类文件结构class类文件的结构 123456789101112131415161718ClassFile &#123; u4 magic; u2 minor_version; u2 major_version; u2 constant_pool_count; cp_info constant_pool[constant_pool_count-1]; //常量池，字面量和符号引用 u2 access_flags; //访问标志1 u2 this_class; //全限定名 u2 super_class; //父类全限定名 u2 interfaces_count; //接口数量 u2 interfaces[interfaces_count]; //接口的全限定名 u2 fields_count; field_info fields[fields_count]; //类或接口的字段 u2 methods_count; method_info methods[methods_count]; //方法表 u2 attributes_count; attribute_info attributes[attributes_count]; //属性表，code，exception等&#125; class文件是以8字节为基础的二进制流，各个数据都是按一定的顺序排列，如果需要占用8字节以上的空间数据，按照高位在前分割存储 class文件的存储结构只有2种，无符号数和表 无符号数 基本的数据类型，u1,u2,u4,u8类表示1，2，4，8个字节的无符号数，可以描述数字，索引引用，数字量，按UTF-8编码的字符串。 表 是由多个无符号数组成的复合数据类型，所有表以_info结尾，整个class就是一张表 6.2 魔数Class文件的头4个字节，作用：确定这个文件是否为一个能被虚拟机接受的Class文件。值为：0xCAFEBABE(咖啡宝宝) 6.3 版本号紧接着魔数的4个字节。第5，6字节是次版本号，第7，8字节是主版本号 6.4 常量池常量池可以理解为class文件的资源仓库。主要存放了两大类常量：字面量和符号引用。 字面量 string类型的字面量和final类型常量符号引用 包括3中类常量 1.类和接口的全限定名 2.字段的名称和描述符 3.方法的名称和描述符 java在虚拟机加载class文件时才会动态链接，class文件中不会保存各个方法，字段的最终布局，这些字段，方法的符号引用需要在运行时的转换才能得到真正的内存入口。在虚拟机运行时会从常量池中得到对应的符号引用，在类创建时解析。常量池的14中常量结构 比如CONSTANT_CLASS_info,代表类或接口的符号引用，表中的name_index指向CONSTANT_UTF8_info类型的数据，这个存放着我们类的全限定名。 6.5访问标志常量池结束后的两个字节是表示访问标志，用于识别类或者接口的访问信息，比如是类还是接口，访问类型，是否final等等。 6.6类索引，父类索引，接口索引集合class文件由这三个数据来确定类的继承关系。类索引(this_class)和父类索引(super_class)是u2类型的数据，接口索引集合是u2类型的数据集合。 类索引可以确定类的全限定名，父类索引可以确定类的父类全限定名，除了Object类，其他类都有1个父类。接口索引集合按照implements顺序从左到右排列在集合索引中 6.7字段表集合字段表描述类或者接口中申明的变量。字段包括类变量和实例变量，不包括方法内部的局部变量。字段表的格式如下所示，access_flags是字段的访问标志，public，可变性final，并发性violatile等等。其中name_index和descriptor_index是对常量池的引用，代表字段的简单名称和方法的描述符。 全限定名，简单名称，描述符的区别 全限定名是org/fenixsoft/clazz/TestClass是类的全限定名 简单名称 指没有类型和参数修饰符的方法或者字段名称 inc()方法和m字段的简单名称为inc 和m 字段和方法的描述符的解释如下 字段的描述符如下所示对于数组类型，每一维度用[表示，比如java.lang.string[][]的描述符为[[Ljava/lang/String, int[]的描述符为[I描述符描述方法时按照先参数列表再返回值，比如void inc() 表示为()V 方法java.lang.String toString() 表示为 （）Ljava/lang/String ， 方法int indexOf(char[]source, int sourceOffset)可以表示为([CI)I。 6.8方法表集合方法表和字段表类似，结构也是访问标志，名称索引，描述符索引，属性表集合等。 方法的定义在可以通过方法的访问标志，名称索引，描述符索引表达清楚，方法内部的代码是经过java的编译器编译成字节码后存放在方法属性集合中的名为“code”的属性中 在java语言中，重载(override)一个方法，除了和原方法的简单名称一样，还需要和原方法有一个不同的特征签名,特征签名是一个方法中不同参数在常量池中的字段符号引用的合集，所以返回值不会包含在特征签名中，所以无法通过返回值来重载方法 6.9 属性表 code属性java代码经过javac编译后会变成字节码指令存储在code属性中。code属性存放在方法表的属性中，但是不是所有的方法表中都存在code属性，比如接口和抽象类的方法就不存在code属性 max_stack是操作数栈深度的最大值max_locals是局部变量所需的空间 max_locals的单位值slot，slot是虚拟机为局部变量分配内存的最小单位，除了double和long两者是需要2个slot存放，其他的都是1个slot来存放方法参数包括this，异常处理的参数，即try catch中定义的异常，方法体中的局部变量都是用slot来存放。slot可以被复用，只要保证正确性。 code_length和code是存储的字节码exception是方法中可能抛出的受查异常，也就是throws的异常ConstantValue属性是为静态变量赋值 异常表编译器是采用异常表而不是简单的跳转命令来实现java的异常和finally处理机制看出0-9行是正常返回，10-20是exception型的异常返回，21-25是非exception得异常返回。3中路径都有finally中的代码，finally的代码是会嵌套在3种路径的代码之后在return之前。结果是没有异常，返回1，出现exception异常，返回是2，出现exception以外的异常，方法没有返回值。 字节码指令简介 加载和存储指令加载和存储指令将数据在栈帧的局部变量表和操作数栈之间传输 运算指令将连个操作数栈的值进行运算，再将结果存回操作数栈顶 类型转换转换类型，虚拟机直接支持从小范围类型向大范围类型的安全转换，大数到小数就要使用转换指令 对象创建和访问指令new，newarray，访问类字段 getstatic 访问非类字段 getfield 方法调用指令 invokevirtual 调用方法的虚方法，根据方法的实际类型进行分派invokeinterface 调用接口的方法，搜索实现接口方法的实例对象并找出最合适的方法调用invokespecial 调用特殊的方法，比如实力初始化方法和私有方法和父类方法invokespecial 类方法staticinvokedynamic 运行时动态解析出引用的方法。 同步指令java虚拟机支持方法级的同步和方法内部指令的同步，两种的同步结构都是使用管程(Monitor)来支持。比如synchronize的语句实现是monitorenter和monitorexit来实现，执行的线程必须先成功持有管程，然后才能执行方法，方法最后成功或者非正常完成都会释放管程。同步方法在执行时跑出异常，在内部无法处理异常，同步方法持有的管程在异常被抛到同步方法之外时也被自动释放。]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>类文件结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM虚拟机 第7章 虚拟机的类加载机制]]></title>
    <url>%2F2018%2F07%2F12%2FJVM-7%2F</url>
    <content type="text"><![CDATA[虚拟机类加载机制 虚拟机类加载机制虚拟机把描述类的数据从class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型。Java语言里，类型的加载和连接过程是在程序运行期间完成的。 类加载的时机 类加载的生命周期： 加载 验证 准备 解析 初始化 使用 卸载加载，验证，准备，初始化，卸载的顺序是确定的，为了支持java的动态绑定，解析过程可以在初始化之后调用，即动态绑定或者称为晚期绑定4种必须对类进行“初始化”的情况 new，getstatic，putstatic，invokestatic这4个字节码，对类没有初始化必须先对类进行初始化，即使用new生成对象，读取或者设置类的static变量，final修饰的static变量在编译器把结果放在常量池了除外，调用类的static方法 使用java.lang.reflect包的方法对类进行反射调用 初始化一个类时，其父类未初始化，先触发父类的初始化过程 main方法包含的类要先初始化 被动引用: 通过子类调用父类的静态字段不会导致子类的初始化(对于静态字段，只有直接定义这个字段的类才会被初始化) 通过数组定义应用类 classA[] array = new classA[10]；不会初始化classA，只有该数组去访问classA对象的成员时才会加载类 常量会在编译期间存入调用类的常量池 final字段 123456789101112131415161718192021222324252627//对于static字段，只有直接定义这个字段的类会被加载class A ｛ public static int i = 2;｝class B extends A&#123; public static void main(String[] args) &#123; System.out.println(B.i); &#125; &#125;//数组不会触发类的加载,只有访问i才会加载class A ｛ public static int i = 2;｝class B &#123; public static void main(String[] args) &#123; A[] a = new A[10]; &#125;&#125;//final字段是不会触发A类的加载，会触发B的加载，因为i会被转化成B对自身常量池的引用class A ｛ public static final int i = 2;｝class B &#123; public static void main(String[] args) &#123; System.out.println(A.i); &#125; &#125; java方法的绑定java方法的调用需要先将方法和调用方法的类绑定起来，绑定分为静态绑定和动态绑定： 静态绑定：即前期绑定。在程序执行前方法已经被绑定，此时由编译器或其它连接程序实现。针对java，简单的可以理解为程序编译期的绑定。java当中的方法只有final，static，private和构造方法是前期绑定的。 动态绑定：即晚期绑定，也叫运行时绑定。在运行时根据具体对象的类型进行绑定。在java中，几乎所有的方法都是后期绑定的。 加载加载是“类加载”的一个过程。加载过程主要完成3件事情： 通过类的全限定名来获取定义类的二进制字节流 将字节流表示的静态存储结果转化成方法区中的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据结构的访问入口 类加载器对任何一个类，需要由它的类加载器和本身的class文件来确定在虚拟机中的唯一性。即一个class文件用两个类加载器加载出来的类是不想等的。equals()，isInstance 等方法的返回结果不同,使用instanceof的返回结果也不同。 12345678910111213141516171819202122232425262728public class Main &#123; public static void main(String[] args) throws ClassNotFoundException, IllegalAccessException, InstantiationException &#123; ClassLoader myLoader = new ClassLoader() &#123; @Override public Class&lt;?&gt; loadClass(String name) throws ClassNotFoundException &#123; try &#123; String fileName = name.substring(name.lastIndexOf(".") + 1)+ ".class"; InputStream is = getClass().getResourceAsStream(fileName); if (is == null) return super.loadClass(name); byte[] b = new byte[is.available()]; is.read(b); return defineClass(name, b, 0, b.length); &#125; catch (IOException e) &#123; throw new ClassNotFoundException(name); &#125; &#125; &#125;; Object obj = myLoader.loadClass("Main").newInstance(); System.out.println(obj.getClass()); //class Main System.out.println(obj instanceof Main); //false Main main = Main.class.newInstance(); System.out.println(main.getClass().isInstance(obj)); //false &#125;&#125; 上述的两个对象一个是使用应用程序类加载器加载的，一个是自定义的类加载器加载，虽然来自同一个clas文件，但是属于两个不同的类。 双亲委派模型 类加载器的层次图如图所示 ,称为类加载器的双亲委派模型, 双亲委派模型要求顶层的启动类加载器外，其余的类均要有自己的父类加载器，而类加载器不是以继承关系实现，而是使用组合的方式来加载父加载器。 123456789101112131415161718192021222324252627@CallerSensitivepublic ClassLoader getClassLoader() &#123; ClassLoader cl = getClassLoader0(); //获取自身classloader if (cl == null) return null; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; // caller can be null if the VM is requesting it ClassLoader ccl = getClassLoader(caller); //isAncestor方法将类加载器派给了引导类加载器 if(cc1 != null &amp;&amp; cc1 != c1 &amp;&amp; !c1.iaAncestor(cc1)) &#123; sm.checkPermission(SecurityConstants.GET_CLASSLOADER_PERMISSION); &#125; &#125; return cl;&#125;//判断c1是不是this的父类加载器 同时c1的引用也会改变，变成c1的parentboolean isAncestor(ClassLoader cl) &#123; ClassLoader acl = this; do &#123; acl = acl.parent; if (cl == acl) &#123; return true; &#125; &#125; while (acl != null); return false;&#125; 启动类加载器 BootStrap ClassLoader用c++编写，该加载器加载java_home/lib的库文件，将库类加载器到虚拟机内存中。启动类加载器无法被java程序使用 扩展类加载器 extension classLoader 该加载器由sun.misc.Launcher$ExtClassLoader实现，它负责加载JDK\jre\lib\ext目录中，或者由java.ext.dirs系统变量指定的路径中的所有类库（如javax.*开头的类），开发者可以直接使用扩展类加载器。 应用程序类加载器：Application ClassLoader， 该类加载器由sun.misc.Launcher$AppClassLoader来实现，它负责加载用户类路径（ClassPath）所指定的类，开发者可以直接使用该类加载器，如果应用程序中没有自定义过自己的类加载器，一般情况下这个就是程序中默认的类加载器。 应用程序由这三种类加载器配合加载，我们也可以自定义类加载器。因为JVM自带的类加载器只是从本地的文件系统中加载标准的java class文件，使用自己编写的classLoader，可以 执行非致信代码前，自动检验数字签名 动态创建自定义的类 从特定的场所取得java class，比如数据库和网络IO中 双亲委派模型的工作流程一个类加载器收到类加载的请求，不会自己先尝试加载这个类，而是将请求委托类父加载器区完成，所有的类加载器都会传递到顶层的启动类加载器区加载，当父加载器无法找到需要的类时，自加载器才会尝试自己去加载这个类。使用该模型去组织类加载器的好处是java类带有层次性，比如类java.lang.Object存放在JDK\jre\lib下的rt.jar，即(java_home\lib)路径下，最终都会使用启动类加载器区加载，保证了Object类在各个类及载器中都是同一个类。 类加载的验证阶段验证：确保Class文件的字节流中包含的信息符合当前虚拟机的要求，并且不会危害虚拟机自身的安全。在idea中的报错的东西都是在这个阶段检查的虚拟机规范：如果验证到输入的字节流不符合Class文件的存储格式，就抛出一个java.lang.VerifyError异常或其子类异常 类加载的准备阶段 准备阶段是正式为类变量分配内存并设置类变量初始值的阶段类变量是static变量，不包括实例变量，这些变量所使用的内存都在方法区中分配。初始值一般指零值 public static int value = 123 在准备阶段后value的值为0，而不是123，在类的初始化阶段才会赋值为123。 public static final int value = 123 final类型的变量在准备阶段就会初始化成指定的值，存在运行时常量池中。 注意点： 对于基本数据类型，static变量和成员变量没有显示赋值会使用默认值，但是局部变量在使用前必须显示赋值，否则编译不通过 static final 类型的变量在申明时必须显示赋值，否则编译不通过。final类型的变量在申明时赋值，或者类初始化后赋值，总之final类型的变量必须显示赋值。static类型的变量在准备阶段会赋零值 对于reference，数组引用，对象引用，没有显示赋值而直接使用，系统会赋null 数组中的元素没有赋值，会使用零值。 1234567891011public class main1 &#123; public static int i; public final int ii; //final可以在构造函数内初始化 public main1() &#123; ii = 1; &#125; public static final int iii; //必须显示初始化，因为static会在准备阶段赋零值 static &#123; iii = 1; //这里赋值也可以，因为都是在准备阶段执行 &#125;&#125; 类加载的解析阶段解析阶段可能在初始化之后，阶段不固定。解析阶段就是将加载的类中常量池里的符号引用转化成直接引用的过程。 符号引用符号引用是用符号来表示引用的对象，只要符号可以无歧义的定位到目标对象即可。目标对象可以在内存中还不存在。 直接引用直接引用时可以直接指向目标中的指针，相对偏移量或者能间接定位到目标的句柄。直接引用的目标在内存中必须存在。A.f1(),符号引用指的是方法区中的偏移量，直接引用指的是直接指向类的方法的入口地址，f1()具体的方法地址 类的解析当前的类为D，将一个符号引用N解析为类或接口C的直接引用，1 C N = new D() 如果C不是数组类型，那么会将N的权限定名给D，用D的类加载器去加载。2 C[] N = new D[100] C时数组类型，不会去启动D的类加载器去加载，但是虚拟机会生成一个表示这个数组的对象。 字段解析对字段表中的class_index的索引中的CONSTANT_Class_info符号引用进行解析，也就是字段所属的类或者接口的符号引用。比如在方法里调用了C.a 将字段所属的类定义为C如果C本身存在字段a，直接返回a的直接引用。如果C实现了借口，按照继承关系从下往上递归搜索各个接口和父接口，找到字段a的直接引用。如果C不是Object，则从下往上递归搜索父类中的字段，直到找到a都没有找到，抛出异常 类方法解析 C.a()解析先在类方法表中的索引的方法所属的类或者接口的符号引用。在C中找到a的直接引用。否则在C的父类中找到和这个方法的直接引用，查找结束。否则在C的接口中找到这个方法的引用，如果存在，说明C是抽象类，则查找结束，抛出异常。 接口方法解析 c.a() c是一个接口则先查c自身的接口，没有就查父接口 ，直到查到a的直接引用。类加载的初始化阶段类初始化阶段是类加载过程的最后一步，在准备阶段，变量已经赋过一次系统要求的初始值，而在初始化阶段，则根据程序员通过程序制定的主观计划去初始化类变量和其他资源。在初始化阶段实际是执行类构造器的方法&lt;clinit&gt;()方法， &lt;clinit&gt;()会由编译器自动收集类中的类变量的赋值动作和静态语句块(static{}块)语句合并，并且顺序由原文件的顺序决定。静态语句块中只能给访问到静态语句块之前的变量，在它之后的变量可以访问，但是不能赋值 1234567public class Test &#123; static &#123; i = 0; //给变量赋值可以正常编译通过 System.out.print(i); //编译器会提示“非法向前引用” &#125; static int i = 1;&#125; &lt;clinit&gt;()和类的实例构造器不同&lt;init&gt;()，它不需要显示调用父类的构造器，虚拟机会保证在子类初始化之前父类已经初始化完毕。因此虚拟机中第一个被执行&lt;init&gt;()一定是java.lang.Object类。 父类的static代码块一定会优先于子类的static代码块先执行。 &lt;clinit&gt;()方法对于类或接口来说并不是必须的，如果一个类中没有静态语句块，也没有对变量的赋值操作，那么编译器可以不为这个类生成&lt;clinit&gt;()方法。 接口中不能使用静态语句块，但仍然有变量初始化的操作，因此接口与类一样都会生成&lt;clinit&gt;()方法，但与类不同的是，执行接口的初始化方法之前，不需要先执行父接口的初始化方法。只有当父接口中定义的变量使用时，才会执行父接口的初始化方法。另外，接口的实现类在初始化时也一样不会执行接口的&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确的加锁、同步，如果多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的clinit()方法，其他线程都需要阻塞等待，直到活动线程执行类初始化方法完毕。 很简单，下面代码执行的结果为2，而不是1 12345678910111213static class Parent &#123; public static int A = 1; static &#123; A = 2; &#125; &#125;static class Sub extends Parent &#123; public static int B = A; &#125;public static void main(String[] args) &#123; System.out.println(Sub.B); &#125;]]></content>
      <categories>
        <category>JVM虚拟机原理</category>
      </categories>
      <tags>
        <tag>JVM原理</tag>
        <tag>虚拟机类加载机制</tag>
      </tags>
  </entry>
</search>
